<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pyapprox.expdesign.bayesian_oed &mdash; PyApprox 1.0.0 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../../index.html" class="icon icon-home"> PyApprox
            <img src="../../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Software Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_tutorials/index.html">Theoretical Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_reference_guide.html">User Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">PyApprox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>pyapprox.expdesign.bayesian_oed</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pyapprox.expdesign.bayesian_oed</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">cdist</span>
<span class="kn">from</span> <span class="nn">pyapprox.util.pya_numba</span> <span class="kn">import</span> <span class="n">njit</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>

<span class="kn">from</span> <span class="nn">pyapprox.util.sys_utilities</span> <span class="kn">import</span> <span class="n">trace_error_with_msg</span>
<span class="kn">from</span> <span class="nn">pyapprox.util.utilities</span> <span class="kn">import</span> <span class="n">get_tensor_product_quadrature_rule</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.risk</span> <span class="kn">import</span> <span class="n">conditional_value_at_risk</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.sampling</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">generate_independent_random_samples</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables.transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AffineTransform</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.interp.tensorprod</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_tensor_product_piecewise_polynomial_quadrature_rule</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.polychaos.gpc</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_univariate_quadrature_rules_from_variable</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates.interp.barycentric_interpolation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">compute_barycentric_weights_1d</span><span class="p">,</span>
    <span class="n">multivariate_barycentric_lagrange_interpolation</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun_broadcast</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Conmpute the log-likelihood values from a set of real and predicted</span>
<span class="sd">    observations</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    obs : np.ndarray (nsamples, nobs)</span>
<span class="sd">        The real observations repeated for each sample</span>

<span class="sd">    pred_obs : np.ndarray (nsamples, nobs)</span>
<span class="sd">        The observations predicited by the model for a set of samples</span>

<span class="sd">    noise_stdev : float or np.ndarray (nobs, 1)</span>
<span class="sd">        The standard deviation of Gaussian noise added to each observation</span>

<span class="sd">    active_indices : np.ndarray (nobs, 1)</span>
<span class="sd">        The subset of indices of the observations used to compute the</span>
<span class="sd">        likelihood</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    llike : np.ndaray (nsamples, 1)</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This can handle 1d, 2d, 3d arrays but is slower</span>
<span class="sd">    due to broadcasting when computing obs-pred_obs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">noise_stdev</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="ow">and</span>
            <span class="n">noise_stdev</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;noise must be provided for each observation&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_stdev</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_stdev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">noise_stdev</span>

    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># avoid copy if possible</span>
        <span class="c1"># using special indexing with array e.g array[:, I] where I is an array</span>
        <span class="c1"># makes a copy which is slow</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_stdev</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tmp</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
        <span class="n">llike</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">obs</span><span class="o">-</span><span class="n">pred_obs</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">tmp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_stdev</span><span class="p">[</span><span class="n">active_indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tmp</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
        <span class="n">llike</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="o">-</span><span class="p">(</span><span class="n">obs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">-</span><span class="n">pred_obs</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">tmp</span><span class="p">,</span>
            <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">llike</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="n">llike</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">llike</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sq_dists_numba_3d</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the scaled l2-norm distance between two sets of samples</span>
<span class="sd">    E.g. for one point</span>


<span class="sd">    a[ii]*(XX[ii]-YY[ii])+b</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    XX : np.ndarray (LL, 1, NN)</span>
<span class="sd">        The first set of samples</span>

<span class="sd">    YY : np.ndarray (LL, MM, NN)</span>
<span class="sd">        The second set of samples. The 3D arrays are useful when computing</span>
<span class="sd">        squared distances for multiple sets of samples</span>

<span class="sd">    a : float or np.ndarray (NN, 1)</span>
<span class="sd">        scalar multiplying l2 distance</span>

<span class="sd">    b : float</span>
<span class="sd">        scalar added to l2 distance</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ss : np.ndarray (LL, MM)</span>
<span class="sd">        The scaled distances</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Yshape</span> <span class="o">=</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">nactive_indices</span> <span class="o">=</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nactive_indices</span><span class="p">):</span>
                <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span><span class="o">*</span><span class="p">(</span>
                    <span class="n">XX</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span> <span class="o">-</span>
                    <span class="n">YY</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span><span class="o">+</span><span class="n">b</span>
    <span class="k">return</span> <span class="n">ss</span>


<span class="k">def</span> <span class="nf">sq_dists_3d</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pyapprox.cython.utilities</span> <span class="kn">import</span> <span class="n">sq_dists_3d_pyx</span>
        <span class="k">return</span> <span class="n">sq_dists_3d_pyx</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">except</span><span class="p">(</span><span class="ne">ImportError</span><span class="p">,</span> <span class="ne">ModuleNotFoundError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;sq_dists_3d extension failed&#39;</span>
        <span class="n">trace_error_with_msg</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sq_dists_numba_3d</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun_economial_3D</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pred_obs must be 3D&quot;</span><span class="p">)</span>
    <span class="c1"># cdist has a lot of overhead and cannot be used with active_indices</span>
    <span class="c1"># sq_dists = sq_dists_cdist_3d(obs, pred_obs)</span>

    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_stdev</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_stdev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">noise_stdev</span>

    <span class="n">tmp1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_stdev</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">tmp1</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">tmp2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">tmp1</span><span class="p">[</span><span class="n">active_indices</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
    <span class="n">llike</span> <span class="o">=</span> <span class="n">sq_dists_3d</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">tmp1</span><span class="p">,</span> <span class="n">tmp2</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">llike</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="n">llike</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">llike</span>


<span class="nd">@njit</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sq_dists_numba_3d_XX_prereduced</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the scaled l2-norm distance between two sets of samples</span>
<span class="sd">    E.g. for one point</span>


<span class="sd">    a[ii]*(XX[ii]-YY[ii])+b</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    XX : np.ndarray (LL, 1, NN)</span>
<span class="sd">        The first set of samples</span>

<span class="sd">    YY : np.ndarray (LL, MM, NN)</span>
<span class="sd">        The second set of samples. The 3D arrays are useful when computing</span>
<span class="sd">        squared distances for multiple sets of samples</span>

<span class="sd">    a : float or np.ndarray (NN, 1)</span>
<span class="sd">        scalar multiplying l2 distance</span>

<span class="sd">    b : float</span>
<span class="sd">        scalar added to l2 distance</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ss : np.ndarray (LL, MM)</span>
<span class="sd">        The scaled distances</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Yshape</span> <span class="o">=</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">nactive_indices</span> <span class="o">=</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">jj</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Yshape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">kk</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nactive_indices</span><span class="p">):</span>
                <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span><span class="p">[</span><span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]]</span><span class="o">*</span><span class="p">(</span>
                    <span class="n">XX</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">kk</span><span class="p">]</span> <span class="o">-</span> <span class="n">YY</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">kk</span><span class="p">]])</span><span class="o">**</span><span class="mi">2</span>
            <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span> <span class="o">=</span> <span class="n">ss</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">jj</span><span class="p">]</span><span class="o">+</span><span class="n">b</span>
    <span class="k">return</span> <span class="n">ss</span>


<span class="k">def</span> <span class="nf">sq_dists_3d_prereduced</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">YY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pyapprox.cython.utilities</span> <span class="kn">import</span> <span class="n">sq_dists_3d_prereduced_pyx</span>
        <span class="k">return</span> <span class="n">sq_dists_3d_prereduced_pyx</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">except</span><span class="p">(</span><span class="ne">ImportError</span><span class="p">,</span> <span class="ne">ModuleNotFoundError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;sq_dists_3d_prereduced extension failed&#39;</span>
        <span class="n">trace_error_with_msg</span><span class="p">(</span><span class="n">msg</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">sq_dists_numba_3d_XX_prereduced</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun_3d_prereduced</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_stdev</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_stdev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">noise_stdev</span>

    <span class="n">tmp1</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">noise_stdev</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">tmp2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="o">-</span><span class="n">tmp1</span><span class="p">[</span><span class="n">active_indices</span><span class="p">]</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span>
    <span class="n">llike</span> <span class="o">=</span> <span class="n">sq_dists_numba_3d_XX_prereduced</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">tmp1</span><span class="p">,</span> <span class="n">tmp2</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">llike</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="n">llike</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">llike</span>


<span class="k">def</span> <span class="nf">compute_weighted_sqeuclidian_distance</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span>
                                          <span class="n">active_indices</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span> <span class="ow">or</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;obs and pred_obs must be 2D arrays&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_stdev</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="ow">or</span> <span class="n">noise_stdev</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;noise_stdev must be a 2d np.ndarray with one column&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">noise_stdev</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
        <span class="c1"># avoid copy is possible</span>
        <span class="c1"># using special indexing with array makes a copy which is slow</span>
        <span class="n">weighted_obs</span> <span class="o">=</span> <span class="n">obs</span><span class="o">*</span><span class="n">weights</span>
        <span class="n">weighted_pred_obs</span> <span class="o">=</span> <span class="n">pred_obs</span><span class="o">*</span><span class="n">weights</span>
        <span class="n">sq_dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">weighted_obs</span><span class="p">,</span> <span class="n">weighted_pred_obs</span><span class="p">,</span> <span class="s2">&quot;sqeuclidean&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sq_dists</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">*</span><span class="n">noise_stdev</span><span class="p">[</span><span class="n">active_indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">weighted_obs</span> <span class="o">=</span> <span class="n">obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span>
    <span class="n">weighted_pred_obs</span> <span class="o">=</span> <span class="n">pred_obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span>
    <span class="n">sq_dists</span> <span class="o">=</span> <span class="n">cdist</span><span class="p">(</span><span class="n">weighted_obs</span><span class="p">,</span> <span class="n">weighted_pred_obs</span><span class="p">,</span> <span class="s2">&quot;sqeuclidean&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">sq_dists</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun_economial_2D</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_stdev</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_stdev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span><span class="o">*</span><span class="n">noise_stdev</span>
    <span class="n">sq_dists</span> <span class="o">=</span> <span class="n">compute_weighted_sqeuclidian_distance</span><span class="p">(</span>
        <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">noise_stdev</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span> <span class="o">-</span>
                 <span class="n">sq_dists</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">noise_stdev</span><span class="p">[</span><span class="n">active_indices</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span> <span class="o">-</span>
                 <span class="n">sq_dists</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>

    <span class="k">if</span> <span class="n">llike</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">llike</span> <span class="o">=</span> <span class="n">llike</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">llike</span>


<span class="k">def</span> <span class="nf">gaussian_loglike_fun</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span> <span class="ow">and</span> <span class="n">obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun_economial_3D</span><span class="p">(</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun_economial_2D</span><span class="p">(</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun_broadcast</span><span class="p">(</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">__compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
        <span class="n">log_likelihood_fun</span><span class="p">,</span> <span class="n">outer_loop_pred_obs</span><span class="p">,</span>
        <span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_weights</span><span class="p">,</span>
        <span class="n">active_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">):</span>

    <span class="n">nouter_loop_samples</span> <span class="o">=</span> <span class="n">outer_loop_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
        <span class="n">inner_loop_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="n">nouter_loop_samples</span><span class="p">)</span>

    <span class="n">outer_log_likelihood_vals</span> <span class="o">=</span> <span class="n">log_likelihood_fun</span><span class="p">(</span>
        <span class="n">outer_loop_pred_obs</span><span class="p">,</span> <span class="n">outer_loop_pred_obs</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="n">nobs</span> <span class="o">=</span> <span class="n">outer_loop_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">inner_loop_pred_obs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">nobs</span><span class="p">)</span>
    <span class="n">inner_log_likelihood_vals</span> <span class="o">=</span> <span class="n">log_likelihood_fun</span><span class="p">(</span>
        <span class="n">outer_loop_pred_obs</span><span class="p">,</span> <span class="n">tmp</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>

    <span class="c1"># above is a faster version of loop below</span>
    <span class="c1"># outer_log_likelihood_vals = np.empty((nouter_loop_samples, 1))</span>
    <span class="c1"># inner_log_likelihood_vals = np.empty(</span>
    <span class="c1">#     (nouter_loop_samples, ninner_loop_samples))</span>
    <span class="c1"># idx1 = 0</span>
    <span class="c1"># for ii in range(nouter_loop_samples):</span>
    <span class="c1">#     outer_log_likelihood_vals[ii] = log_likelihood_fun(</span>
    <span class="c1">#         outer_loop_obs[ii:ii+1, :], outer_loop_pred_obs[ii:ii+1, :])</span>
    <span class="c1">#     idx2 = idx1 + ninner_loop_samples</span>
    <span class="c1">#     inner_log_likelihood_vals[ii, :] = log_likelihood_fun(</span>
    <span class="c1">#         outer_loop_obs[ii:ii+1, :], inner_loop_pred_obs[idx1:idx2, :])</span>
    <span class="c1">#     idx1 = idx2</span>

    <span class="n">evidences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ij,ij-&gt;i&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">inner_log_likelihood_vals</span><span class="p">),</span>
        <span class="n">inner_loop_weights</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">utility_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">outer_log_likelihood_vals</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">evidences</span><span class="p">))</span> <span class="o">*</span>
                         <span class="n">outer_loop_weights</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;utility_val&quot;</span><span class="p">:</span> <span class="n">utility_val</span><span class="p">}</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">inner_log_likelihood_vals</span><span class="p">)</span><span class="o">*</span><span class="n">inner_loop_weights</span><span class="o">/</span><span class="n">evidences</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;utility_val&quot;</span><span class="p">:</span> <span class="n">utility_val</span><span class="p">,</span> <span class="s2">&quot;evidences&quot;</span><span class="p">:</span> <span class="n">evidences</span><span class="p">,</span>
              <span class="s2">&quot;weights&quot;</span><span class="p">:</span> <span class="n">weights</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">precompute_expected_kl_utility_data</span><span class="p">(</span>
        <span class="n">generate_outer_prior_samples</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span>
        <span class="n">noise_fun</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">econ</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    generate_outer_prior_samples : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `generate_outer_prior_samples(nsamples) -&gt; np.ndarray(nvars, nsamples)`</span>

<span class="sd">        That returns a set of random samples randomly drawn from the prior</span>
<span class="sd">        These samples are used to draw condition samples of the obsevations</span>
<span class="sd">        which are used to take an expectation with respect to the data space</span>
<span class="sd">        in the outer loop</span>

<span class="sd">    nouter_loop_samples : integer</span>
<span class="sd">        The number of Monte Carlo samples used to compute the outer integral</span>
<span class="sd">        over all possible observations</span>

<span class="sd">    obs_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">        That returns noiseless evaluations of the forward model.</span>

<span class="sd">    noise_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `noise_fun(samples) -&gt; np.ndarray(nsamples)`</span>

<span class="sd">        That returns the noise of observations</span>

<span class="sd">    ninner_loop_samples : integer</span>
<span class="sd">        The number of quadrature samples used for the inner integral that</span>
<span class="sd">        computes the evidence for each realiaztion of the predicted</span>
<span class="sd">        observations</span>

<span class="sd">    generate_inner_prior_samples : callable</span>
<span class="sd">       Function with the signature</span>

<span class="sd">        `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">        Generate samples and associated weights used to evaluate</span>
<span class="sd">        the evidence computed by the inner loop</span>
<span class="sd">        If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">        weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">        wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">    econ : boolean</span>
<span class="sd">        Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">        This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">        this common data is copied and repeated for each outer loop sample</span>
<span class="sd">        so the rest of the code can remain the same. Eventually the data has</span>
<span class="sd">        to be tiled anyway when computing exepcted utility so this is not a big</span>
<span class="sd">        deal.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>

<span class="sd">    outer_loop_pred_obs : np.ndarray (nouter_loop_samples, ncandidates)</span>
<span class="sd">        The noiseless values of outer_loop_obs with noise removed</span>

<span class="sd">    inner_loop_pred_obs : np.ndarray (nouter_loop_samples*ninner_loop_samples, ncandidates)</span>
<span class="sd">        The noiseless values of obs_fun at all sets of innerloop samples</span>
<span class="sd">        used for each outerloop iteration. The values are stacked such</span>
<span class="sd">        that np.vstack((inner_loop1_vals, inner_loop2_vals, ...))</span>

<span class="sd">    inner_loop_weights  : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>
<span class="sd">        The quadrature weights associated with each inner_loop_pred_obs set</span>
<span class="sd">        used to compute the inner integral.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># generate samples and values for the outer loop</span>
    <span class="n">outer_loop_prior_samples</span> <span class="o">=</span> <span class="n">generate_outer_prior_samples</span><span class="p">(</span>
        <span class="n">nouter_loop_samples</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running </span><span class="si">{</span><span class="n">outer_loop_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> model evaluations&quot;</span><span class="p">)</span>
    <span class="n">outer_loop_pred_obs</span> <span class="o">=</span> <span class="n">obs_fun</span><span class="p">(</span><span class="n">outer_loop_prior_samples</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">outer_loop_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">outer_loop_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;obs_fun is not returning an array with the correct shape&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="c1"># generate samples and values for all inner loops</span>
    <span class="k">if</span> <span class="n">generate_inner_prior_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">generate_inner_prior_samples</span> <span class="o">=</span> <span class="n">generate_outer_prior_samples</span>

    <span class="n">inner_loop_prior_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
        <span class="p">(</span><span class="n">outer_loop_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
         <span class="n">ninner_loop_samples</span><span class="o">*</span><span class="n">nouter_loop_samples</span><span class="p">))</span>
    <span class="n">inner_loop_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
        <span class="p">(</span><span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">))</span>
    <span class="n">idx1</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nouter_loop_samples</span><span class="p">):</span>
        <span class="n">idx2</span> <span class="o">=</span> <span class="n">idx1</span> <span class="o">+</span> <span class="n">ninner_loop_samples</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">econ</span> <span class="ow">or</span> <span class="n">ii</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># when econ is True use samples from ii == 0 for all ii</span>
            <span class="n">in_samples</span><span class="p">,</span> <span class="n">in_weights</span> <span class="o">=</span> <span class="n">generate_inner_prior_samples</span><span class="p">(</span>
                <span class="n">ninner_loop_samples</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">in_samples</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Generate_inner_prior_samples must return 2d np.ndarray&quot;</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">inner_loop_prior_samples</span><span class="p">[:,</span> <span class="n">idx1</span><span class="p">:</span><span class="n">idx2</span><span class="p">]</span> <span class="o">=</span> <span class="n">in_samples</span>
        <span class="n">inner_loop_weights</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">in_weights</span>
        <span class="n">idx1</span> <span class="o">=</span> <span class="n">idx2</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">econ</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running </span><span class="si">{</span><span class="n">inner_loop_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> model evaluations&quot;</span><span class="p">)</span>
        <span class="n">inner_loop_pred_obs</span> <span class="o">=</span> <span class="n">obs_fun</span><span class="p">(</span><span class="n">inner_loop_prior_samples</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Running </span><span class="si">{</span><span class="n">in_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> model evaluations&quot;</span><span class="p">)</span>
        <span class="n">shared_inner_loop_pred_obs</span> <span class="o">=</span> <span class="n">obs_fun</span><span class="p">(</span><span class="n">in_samples</span><span class="p">)</span>
        <span class="n">inner_loop_pred_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">shared_inner_loop_pred_obs</span><span class="p">,</span> <span class="p">(</span><span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_pred_obs</span><span class="p">,</span>
            <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_prior_samples</span><span class="p">,</span>
            <span class="n">inner_loop_prior_samples</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">precompute_expected_deviation_data</span><span class="p">(</span>
        <span class="n">generate_outer_prior_samples</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span>
        <span class="n">noise_fun</span><span class="p">,</span> <span class="n">qoi_fun</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span>
        <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="p">(</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_pred_obs</span><span class="p">,</span>
     <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_prior_samples</span><span class="p">,</span>
     <span class="n">inner_loop_prior_samples</span><span class="p">)</span> <span class="o">=</span> <span class="n">precompute_expected_kl_utility_data</span><span class="p">(</span>
             <span class="n">generate_outer_prior_samples</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span>
             <span class="n">noise_fun</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">generate_inner_prior_samples</span><span class="p">,</span>
             <span class="n">econ</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">econ</span><span class="p">:</span>
        <span class="n">inner_loop_pred_qois</span> <span class="o">=</span> <span class="n">qoi_fun</span><span class="p">(</span><span class="n">inner_loop_prior_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">inner_loop_pred_qois</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">inner_loop_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;qoi_fun is not returning an array with the correct shape. &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;expected nrows to be </span><span class="si">{</span><span class="n">inner_loop_prior_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot; but got </span><span class="si">{</span><span class="n">inner_loop_pred_qois</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">in_samples</span> <span class="o">=</span> <span class="n">inner_loop_prior_samples</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ninner_loop_samples</span><span class="p">]</span>
        <span class="n">shared_inner_loop_pred_qois</span> <span class="o">=</span> <span class="n">qoi_fun</span><span class="p">(</span><span class="n">in_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">shared_inner_loop_pred_qois</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">in_samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;qoi_fun is not returning an array with the correct shape&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">inner_loop_pred_qois</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">shared_inner_loop_pred_qois</span><span class="p">,</span> <span class="p">(</span><span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">nqois</span> <span class="o">=</span> <span class="n">inner_loop_pred_qois</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># print(nqois, [nouter_loop_samples, ninner_loop_samples, nqois],</span>
    <span class="c1">#       np.prod([nouter_loop_samples, ninner_loop_samples, nqois]))</span>
    <span class="c1"># tmp = np.empty((nouter_loop_samples, ninner_loop_samples, nqois))</span>
    <span class="c1"># for kk in range(nqois):</span>
    <span class="c1">#     tmp[:, :, kk] = inner_loop_pred_qois[:, kk].reshape(</span>
    <span class="c1">#         (nouter_loop_samples, ninner_loop_samples))</span>
    <span class="c1"># inner_loop_pred_qois = tmp</span>
    <span class="n">inner_loop_pred_qois</span> <span class="o">=</span> <span class="n">inner_loop_pred_qois</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
            <span class="p">(</span><span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">nqois</span><span class="p">))</span>
    <span class="c1"># assert np.allclose(tmp, inner_loop_pred_qois.reshape(</span>
    <span class="c1">#         (nouter_loop_samples, ninner_loop_samples, nqois)))</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_pred_obs</span><span class="p">,</span>
            <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_prior_samples</span><span class="p">,</span>
            <span class="n">inner_loop_prior_samples</span><span class="p">,</span> <span class="n">inner_loop_pred_qois</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
        <span class="n">log_likelihood_fun</span><span class="p">,</span> <span class="n">outer_loop_pred_obs</span><span class="p">,</span>
        <span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_weights</span><span class="p">,</span>
        <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">,</span>
        <span class="n">return_all</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the expected KullbackLeibler (KL) divergence.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    log_likelihood_fun : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        `log_likelihood_fun(obs, pred_obs) -&gt; np.ndarray (nsamples, 1)`</span>

<span class="sd">        That returns the log likelihood for a set of observations and</span>
<span class="sd">        predictions.</span>
<span class="sd">        obs : np.ndarray(nsamples, nobs+nnew_obs)</span>
<span class="sd">        pred_obs : np.ndarray(nsamples, nobs+nnew_obs)</span>

<span class="sd">    outer_loop_pred_obs : np.ndarray (nouter_loop_samples, ncandidates)</span>
<span class="sd">        The noiseless values of outer_loop_obs with noise removed</span>

<span class="sd">    inner_loop_pred_obs : np.ndarray (nouter_loop_samples*ninner_loop_samples, ncandidates)</span>
<span class="sd">        The noiseless values of obs_fun at all sets of innerloop samples</span>
<span class="sd">        used for each outerloop iteration. The values are stacked such</span>
<span class="sd">        that np.vstack((inner_loop1_vals, inner_loop2_vals, ...))</span>

<span class="sd">    inner_loop_weights  : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>
<span class="sd">        The quadrature weights associated with each inner_loop_pred_obs set</span>
<span class="sd">        used to compute the inner integral.</span>

<span class="sd">    outer_loop_weights  : np.ndarray (nouter_loop_samples, 1)</span>
<span class="sd">        The quadrature weights associated with each outer_loop_pred_obs set</span>
<span class="sd">        used to compute the outer integral.</span>

<span class="sd">    collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">        The indices into the qoi vector associated with the</span>
<span class="sd">        collected observations</span>

<span class="sd">    new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">        The indices into the qoi vector associated with new design locations</span>
<span class="sd">        under consideration</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    utility : float</span>
<span class="sd">        The expected utility</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">collected_design_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># assume the observations at the collected_design_indices are already</span>
        <span class="c1"># incorporated into the inner and outer loop weights</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">new_design_indices</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">__compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
        <span class="n">log_likelihood_fun</span><span class="p">,</span> <span class="n">outer_loop_pred_obs</span><span class="p">,</span>
        <span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_weights</span><span class="p">,</span>
        <span class="n">active_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">__compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
        <span class="n">log_likelihood_fun</span><span class="p">,</span> <span class="n">outer_loop_pred_obs</span><span class="p">,</span>
        <span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_weights</span><span class="p">,</span>
        <span class="n">inner_loop_pred_qois</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span>
        <span class="n">return_all</span><span class="p">,</span> <span class="n">data_risk_fun</span><span class="p">):</span>
    <span class="n">nouter_loop_samples</span> <span class="o">=</span> <span class="n">outer_loop_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span>
        <span class="n">inner_loop_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="n">nouter_loop_samples</span><span class="p">)</span>

    <span class="n">nobs</span> <span class="o">=</span> <span class="n">outer_loop_pred_obs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">inner_loop_pred_obs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
        <span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">nobs</span><span class="p">)</span>

    <span class="n">inner_log_likelihood_vals</span> <span class="o">=</span> <span class="n">log_likelihood_fun</span><span class="p">(</span>
        <span class="n">outer_loop_pred_obs</span><span class="p">,</span> <span class="n">tmp</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
    <span class="n">inner_likelihood_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">inner_log_likelihood_vals</span><span class="p">)</span>
    <span class="n">evidences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ij,ij-&gt;i&quot;</span><span class="p">,</span> <span class="n">inner_likelihood_vals</span><span class="p">,</span> <span class="n">inner_loop_weights</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

    <span class="n">weights</span> <span class="o">=</span> <span class="n">inner_likelihood_vals</span><span class="o">*</span><span class="n">inner_loop_weights</span><span class="o">/</span><span class="n">evidences</span>

    <span class="c1"># make deviation_fun operate on columns of samples</span>
    <span class="c1"># so that it returns a vector of deviations one for each column</span>
    <span class="n">deviations</span> <span class="o">=</span> <span class="n">deviation_fun</span><span class="p">(</span><span class="n">inner_loop_pred_qois</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

    <span class="c1"># expectation taken with respect to observations</span>
    <span class="c1"># assume always want deviation here, but this can be changed</span>
    <span class="c1"># expected_obs_deviations = np.sum(deviations*outer_loop_weights, axis=0)</span>
    <span class="c1"># use einsum because it does not create intermediate arrays</span>
    <span class="c1"># expected_obs_deviations = np.einsum(</span>
    <span class="c1">#    &quot;ij,i-&gt;j&quot;, deviations, outer_loop_weights[:, 0])</span>
    <span class="n">expected_obs_deviations</span> <span class="o">=</span> <span class="n">data_risk_fun</span><span class="p">(</span><span class="n">deviations</span><span class="p">,</span> <span class="n">outer_loop_weights</span><span class="p">)</span>

    <span class="n">disutility_val</span> <span class="o">=</span> <span class="n">pred_risk_fun</span><span class="p">(</span><span class="n">expected_obs_deviations</span><span class="p">)</span>

    <span class="n">utility_val</span> <span class="o">=</span> <span class="o">-</span><span class="n">disutility_val</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;utility_val&#39;</span><span class="p">:</span> <span class="n">utility_val</span><span class="p">}</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;utility_val&#39;</span><span class="p">:</span> <span class="n">utility_val</span><span class="p">,</span> <span class="s1">&#39;evidences&#39;</span><span class="p">:</span> <span class="n">evidences</span><span class="p">,</span>
        <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="n">weights</span><span class="p">,</span> <span class="s1">&#39;deviations&#39;</span><span class="p">:</span> <span class="n">deviations</span><span class="p">,</span>
        <span class="s1">&#39;expected_deviations&#39;</span><span class="p">:</span> <span class="n">expected_obs_deviations</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
        <span class="n">log_likelihood_fun</span><span class="p">,</span> <span class="n">outer_loop_pred_obs</span><span class="p">,</span>
        <span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_weights</span><span class="p">,</span>
        <span class="n">inner_loop_pred_qois</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
        <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">return_all</span><span class="p">,</span> <span class="n">data_risk_fun</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">collected_design_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># assume the observations at the collected_design_indices are already</span>
        <span class="c1"># incorporated into the inner and outer loop weights</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">new_design_indices</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">__compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
        <span class="n">log_likelihood_fun</span><span class="p">,</span> <span class="n">outer_loop_pred_obs</span><span class="p">,</span>
        <span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="n">inner_loop_weights</span><span class="p">,</span> <span class="n">outer_loop_weights</span><span class="p">,</span>
        <span class="n">inner_loop_pred_qois</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span>
        <span class="n">return_all</span><span class="p">,</span> <span class="n">data_risk_fun</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">select_design</span><span class="p">(</span><span class="n">design_candidates</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                  <span class="n">compute_expected_utility</span><span class="p">,</span> <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rounding_decimals</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Update an experimental design.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">        The location of all design sample candidates</span>

<span class="sd">    collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">        The indices into the qoi vector associated with the</span>
<span class="sd">        collected observations</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    utility_vals : np.ndarray (ncandidates)</span>
<span class="sd">        The utility vals at the candidate design samples. If the candidate</span>
<span class="sd">        sample is already in collected design then the utility value will</span>
<span class="sd">        be set to -np.inf</span>

<span class="sd">    selected_index : integer</span>
<span class="sd">        The index of the best design, i.e. the largest utility</span>

<span class="sd">    results : dict</span>
<span class="sd">        Dictionary of useful data used to compute expected utility</span>
<span class="sd">        At a minimum it has the keys [&quot;utilties&quot;, &quot;evidences&quot;, &quot;weights&quot;]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ncandidates</span> <span class="o">=</span> <span class="n">design_candidates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">max_eval_concurrency</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">pool</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">max_eval_concurrency</span><span class="p">)</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
            <span class="n">partial</span><span class="p">(</span><span class="n">compute_expected_utility</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                    <span class="n">return_all</span><span class="o">=</span><span class="n">return_all</span><span class="p">),</span>
            <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ii</span><span class="p">])</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ncandidates</span><span class="p">)])</span>
        <span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">utility_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="p">[</span><span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="s1">&#39;utility_val&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ncandidates</span><span class="p">)])</span>
        <span class="c1"># utility_vals = -np.ones(ncandidates)*np.inf</span>
        <span class="c1"># results = [None for ii in range(ncandidates)]</span>
        <span class="c1"># cnt = 0</span>
        <span class="c1"># for ii in range(ncandidates):</span>
        <span class="c1">#     if ii not in collected_design_indices:</span>
        <span class="c1">#         utility_vals[ii] = pool_results[cnt][&#39;utility_val&#39;]</span>
        <span class="c1">#         results[ii] = pool_results[cnt]</span>
        <span class="c1">#         cnt += 1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">utility_vals</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">ncandidates</span><span class="p">)</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ncandidates</span><span class="p">)]</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ncandidates</span><span class="p">):</span>
            <span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">compute_expected_utility</span><span class="p">(</span>
                <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ii</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
                <span class="n">return_all</span><span class="o">=</span><span class="n">return_all</span><span class="p">)</span>
            <span class="n">utility_vals</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="s2">&quot;utility_val&quot;</span><span class="p">]</span>
            <span class="c1"># print(f&#39;Candidate {ii}:&#39;, utility_vals[ii])</span>

    <span class="n">selected_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">utility_vals</span><span class="p">,</span> <span class="n">rounding_decimals</span><span class="p">))</span>
    <span class="c1"># print(np.round(utility_vals, rounding_decimals))</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_all</span><span class="p">:</span>
        <span class="n">results</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">selected_index</span><span class="p">,</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">update_observations</span><span class="p">(</span><span class="n">design_candidates</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                        <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">obs_process</span><span class="p">,</span>
                        <span class="n">collected_obs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updated the real collected data with obsevations at the new selected</span>
<span class="sd">    candidate locations.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ---------</span>
<span class="sd">    design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">        The location of all design sample candidates</span>

<span class="sd">    collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">        The indices into the qoi vector associated with the</span>
<span class="sd">        collected observations</span>

<span class="sd">    new_design_indices : np.ndarray (nnew_design_samples)</span>
<span class="sd">        The indices into the design_candidates array of the new selected</span>
<span class="sd">        design samples</span>

<span class="sd">    obs_process : callable</span>
<span class="sd">        The true data generation model with the signature</span>

<span class="sd">        `obs_process(design_indices) -&gt; np.ndarray (1, ndesign_indices)`</span>

<span class="sd">        where design_samples is np.ndarary (nvars, ndesign_indices)</span>

<span class="sd">    collected_obs : np.ndarray (1, nobs)</span>
<span class="sd">        The observations at the previously selected design samples</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    updated_collected_obs : np.ndarray (1, nobs+nnew_design_samples)</span>
<span class="sd">        The updated collected observations with the new observations</span>
<span class="sd">        appended to the previous observations</span>

<span class="sd">    updated_collected_design_indices : np.ndarray (1, nobs+nnew_design_samples)</span>
<span class="sd">        The updated indices associated with all the collected observations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">new_obs</span> <span class="o">=</span> <span class="n">obs_process</span><span class="p">(</span><span class="n">new_design_indices</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">collected_obs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">new_obs</span><span class="p">,</span> <span class="n">new_design_indices</span>

    <span class="n">updated_collected_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">collected_obs</span><span class="p">,</span> <span class="n">new_obs</span><span class="p">))</span>
    <span class="n">updated_collected_design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
        <span class="p">(</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">updated_collected_obs</span><span class="p">,</span> <span class="n">updated_collected_design_indices</span>


<span class="k">def</span> <span class="nf">d_optimal_utility</span><span class="p">(</span><span class="n">Amat</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the d-optimality criterion for a linear model f(x) = Amat.dot(x)</span>

<span class="sd">    Assume R = sigma^2 I</span>

<span class="sd">    Posterior covaiance</span>
<span class="sd">    sigma^2 inv(A^TA+R)</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Alen Alexanderian and Arvind K. Saibaba</span>
<span class="sd">    Efficient D-Optimal Design of Experiments for</span>
<span class="sd">    Infinite-Dimensional Bayesian Linear Inverse Problems</span>
<span class="sd">    SIAM Journal on Scientific Computing 2018 40:5, A2956-A2985</span>
<span class="sd">    https://doi.org/10.1137/17M115712X</span>
<span class="sd">    Theorem 1</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="n">Amat</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">hess_misfit</span> <span class="o">=</span> <span class="n">Amat</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Amat</span><span class="p">)</span><span class="o">/</span><span class="n">noise_std</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">ident</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">nvars</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="n">hess_misfit</span><span class="o">+</span><span class="n">ident</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>


<div class="viewcode-block" id="AbstractBayesianOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED">[docs]</a><span class="k">class</span> <span class="nc">AbstractBayesianOED</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Base Bayesian OED class&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                 <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">ninner_loop_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">econ</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">            The location of all design sample candidates</span>

<span class="sd">        obs_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns noiseless evaluations of the forward model.</span>

<span class="sd">        noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">            The standard deviation of the mean zero Gaussian noise added to</span>
<span class="sd">            each observation</span>

<span class="sd">        prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">            The prior variable consisting of independent univariate random</span>
<span class="sd">            variables</span>

<span class="sd">        generate_inner_prior_samples : callable</span>
<span class="sd">           Function with the signature</span>

<span class="sd">            `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(</span>
<span class="sd">             nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">            Generate samples and associated weights used to evaluate</span>
<span class="sd">            the evidence computed by the inner loop</span>
<span class="sd">            If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">            weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">            wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">        ninner_loop_samples : integer</span>
<span class="sd">            The number of quadrature samples used for the inner integral that</span>
<span class="sd">            computes the evidence for each realiaztion of the predicted</span>
<span class="sd">            observations</span>

<span class="sd">        nouter_loop_samples : integer</span>
<span class="sd">            The number of Monte Carlo samples used to compute the outer</span>
<span class="sd">            integral over all possible observations</span>

<span class="sd">        quad_method : string</span>
<span class="sd">            The method used to compute the inner loop integral needed to</span>
<span class="sd">            evaluate the evidence for an outer loop sample. Options are</span>
<span class="sd">            [&quot;linear&quot;, &quot;quadratic&quot;, &quot;gaussian&quot;, &quot;monte_carlo&quot;]</span>
<span class="sd">            The first 3 construct tensor product quadrature rules from</span>
<span class="sd">            univariate rules that are respectively piecewise linear,</span>
<span class="sd">            piecewise quadratic or Gauss-quadrature.</span>

<span class="sd">        pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        econ : boolean</span>
<span class="sd">            Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">            This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">            this common data is copied and repeated for each outer loop sample</span>
<span class="sd">            so the rest of the code can remain the same. Eventually the data</span>
<span class="sd">            has to be tiled anyway when computing exepcted utility so this is</span>
<span class="sd">            not a big deal.</span>

<span class="sd">        max_eval_concurrency : integer</span>
<span class="sd">            The number of threads used to compute OED design. Warning:</span>
<span class="sd">            this uses multiprocessing.Pool and seems to provide very little</span>
<span class="sd">            benefit and in many cases increases the CPU time.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">design_candidates</span> <span class="o">=</span> <span class="n">design_candidates</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">obs_fun</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;obs_fun must be a callable function&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs_fun</span> <span class="o">=</span> <span class="n">obs_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span> <span class="o">=</span> <span class="n">noise_std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_variable</span> <span class="o">=</span> <span class="n">prior_variable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nouter_loop_samples</span> <span class="o">=</span> <span class="n">nouter_loop_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="n">ninner_loop_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">generate_inner_prior_samples</span> <span class="o">=</span> <span class="n">generate_inner_prior_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">econ</span> <span class="o">=</span> <span class="n">econ</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_prior_samples</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_realizations</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_eval_concurrency</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_max_eval_concurrency</span><span class="p">(</span><span class="n">max_eval_concurrency</span><span class="p">)</span>

<div class="viewcode-block" id="AbstractBayesianOED.set_max_eval_concurrency"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.set_max_eval_concurrency">[docs]</a>    <span class="k">def</span> <span class="nf">set_max_eval_concurrency</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_eval_concurrency</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_eval_concurrency</span> <span class="o">=</span> <span class="n">max_eval_concurrency</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">max_eval_concurrency</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span>
                <span class="s1">&#39;OMP_NUM_THREADS&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span> <span class="ow">or</span>
                <span class="ow">not</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;OMP_NUM_THREADS&#39;</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s1">&#39;User set assert_omp=True but OMP_NUM_THREADS has not been &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;set to 1. Run script with &#39;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="s1">&#39;OMP_NUM_THREADS=1 python script.py&#39;</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.noise_fun"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.noise_fun">[docs]</a>    <span class="k">def</span> <span class="nf">noise_fun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gaussian_noise_fun</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.reproducible_noise_fun"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.reproducible_noise_fun">[docs]</a>    <span class="k">def</span> <span class="nf">reproducible_noise_fun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
        <span class="n">active_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">active_indices</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">nouter_loop_samples</span>
        <span class="n">nunique_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
            <span class="n">active_indices</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_realizations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># make noise the same each time this funciton is called</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_realizations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_fun</span><span class="p">(</span><span class="n">values</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_realizations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">nunique_indices</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">noise_realizations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">noise_realizations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_fun</span><span class="p">(</span><span class="n">values</span><span class="p">)[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]))</span>
        <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">idx</span> <span class="o">=</span> <span class="n">active_indices</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span>
            <span class="n">noise</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_realizations</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">counts</span><span class="p">[</span><span class="n">idx</span><span class="p">]]</span>
            <span class="n">counts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">noise</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.generate_prior_samples"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.generate_prior_samples">[docs]</a>    <span class="k">def</span> <span class="nf">generate_prior_samples</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">generate_independent_random_samples</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">prior_variable</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span><span class="o">/</span><span class="n">nsamples</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.loglike_fun"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.loglike_fun">[docs]</a>    <span class="k">def</span> <span class="nf">loglike_fun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gaussian_loglike_fun</span><span class="p">(</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span></div>

    <span class="k">def</span> <span class="nf">__get_outer_loop_obs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noiseless_obs</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reproducible_noise_fun</span><span class="p">(</span><span class="n">noiseless_obs</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">noiseless_obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">]</span> <span class="o">+</span> <span class="n">noise</span>

<div class="viewcode-block" id="AbstractBayesianOED.get_outer_loop_obs"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.get_outer_loop_obs">[docs]</a>    <span class="k">def</span> <span class="nf">get_outer_loop_obs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_outer_loop_obs</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.loglike_fun_from_noiseless_obs"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.loglike_fun_from_noiseless_obs">[docs]</a>    <span class="k">def</span> <span class="nf">loglike_fun_from_noiseless_obs</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">noiseless_obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">):</span>
        <span class="c1"># special indexing with active_indices causes a copy</span>
        <span class="c1"># this is ok for small 2D noiseless_obs array but is too expensive</span>
        <span class="c1"># for 3D pred_obs array so use loglike function that takes reduced</span>
        <span class="c1"># 2D array and full 3D array and applied active_indices to 3D array</span>
        <span class="c1"># internally. This wierdness is causd by the fact that when there</span>
        <span class="c1"># are repeat entries in active_indices we need to generate different</span>
        <span class="c1"># noise realization for the same noiseless obs. This is not possible</span>
        <span class="c1"># with special indexing as it will just copy the same value twice.</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__get_outer_loop_obs</span><span class="p">(</span><span class="n">noiseless_obs</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">pred_obs</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">gaussian_loglike_fun_3d_prereduced</span><span class="p">(</span>
                <span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="n">active_indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike_fun</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">pred_obs</span><span class="p">[:,</span> <span class="n">active_indices</span><span class="p">])</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.populate"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.populate">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">populate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.update_design"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.update_design">[docs]</a>    <span class="k">def</span> <span class="nf">update_design</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">rounding_decimals</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;outer_loop_pred_obs&quot;</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Must call self.populate before creating designs&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">utility_vals</span><span class="p">,</span> <span class="n">selected_index</span><span class="p">,</span> <span class="n">results</span> <span class="o">=</span> <span class="n">select_design</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">design_candidates</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">compute_expected_utility</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_eval_concurrency</span><span class="p">,</span>
            <span class="n">return_all</span><span class="p">,</span> <span class="n">rounding_decimals</span><span class="p">)</span>

        <span class="n">new_design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">selected_index</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">return_all</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">return</span> <span class="n">utility_vals</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">results</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.set_collected_design_indices"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.set_collected_design_indices">[docs]</a>    <span class="k">def</span> <span class="nf">set_collected_design_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span></div>

<div class="viewcode-block" id="AbstractBayesianOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.AbstractBayesianOED.html#pyapprox.expdesign.AbstractBayesianOED.compute_expected_utility">[docs]</a>    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span></div></div>


<div class="viewcode-block" id="BayesianBatchKLOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchKLOED.html#pyapprox.expdesign.BayesianBatchKLOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianBatchKLOED</span><span class="p">(</span><span class="n">AbstractBayesianOED</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute open-loop OED my maximizing KL divergence between the prior and</span>
<span class="sd">    posterior.</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BayesianBatchKLOED.populate"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchKLOED.html#pyapprox.expdesign.BayesianBatchKLOED.populate">[docs]</a>    <span class="k">def</span> <span class="nf">populate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_prior_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_prior_samples</span><span class="p">)</span> <span class="o">=</span> \
             <span class="n">precompute_expected_kl_utility_data</span><span class="p">(</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">generate_prior_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nouter_loop_samples</span><span class="p">,</span>
                 <span class="bp">self</span><span class="o">.</span><span class="n">obs_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ninner_loop_samples</span><span class="p">,</span>
                 <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_inner_prior_samples</span><span class="p">,</span>
                 <span class="n">econ</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">econ</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span></div>

<div class="viewcode-block" id="BayesianBatchKLOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchKLOED.html#pyapprox.expdesign.BayesianBatchKLOED.compute_expected_utility">[docs]</a>    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        return_all true used for debugging returns more than just utilities</span>
<span class="sd">        and also returns itermediate data useful for testing</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># unlike open loop design (closed loop batch design)</span>
        <span class="c1"># we do not update inner and outer loop weights but rather</span>
        <span class="c1"># just compute likelihood for all collected and new design indices</span>
        <span class="c1"># If want to update weights then we must have a different set of</span>
        <span class="c1"># weights for each inner iteration of the inner loop that is</span>
        <span class="c1"># computed using</span>
        <span class="c1"># the associated outerloop data</span>
        <span class="k">return</span> <span class="n">compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loglike_fun_from_noiseless_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
            <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">oed_prediction_average</span><span class="p">(</span><span class="n">qoi_vals</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">qoi_vals</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">qoi_vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">qoi_vals</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="k">assert</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">qoi_vals</span><span class="o">*</span><span class="n">weights</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">oed_variance_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the variance deviation for each outer loop sample using the</span>
<span class="sd">    corresponding inner loop samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : np.ndarray (nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>
<span class="sd">        Weights associated with each innner loop sample</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_vals : np.ndarray (nouter_loop_samples, nqois)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For large arrays variance_3D_pyx is the same speed as einsum</span>
    <span class="c1"># implementation below</span>
    <span class="c1"># try:</span>
    <span class="c1">#     from pyapprox.cython.utilities import variance_3D_pyx</span>
    <span class="c1">#     return variance_3D_pyx(samples, weights)</span>
    <span class="c1"># except:</span>
    <span class="c1">#     pass</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
         <span class="s2">&quot;ijk,ij-&gt;ik&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ijk,ij-&gt;ik&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span><span class="o">-</span><span class="n">means</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">variances</span>


<span class="k">def</span> <span class="nf">oed_entropic_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the entropic risk deviation for each outer loop sample using the</span>
<span class="sd">    corresponding inner loop samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : np.ndarray (nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>
<span class="sd">        Weights associated with each innner loop sample</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_vals : np.ndarray (nouter_loop_samples, nqois)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ijk,ij-&gt;ik&quot;</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="n">risks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ijk,ij-&gt;ik&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">samples</span><span class="p">),</span> <span class="n">weights</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">risks</span><span class="o">-</span><span class="n">means</span>


<span class="k">def</span> <span class="nf">oed_data_expectation</span><span class="p">(</span><span class="n">deviations</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the expected deviation for each outer loop sample</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deviations : np.ndarray (nouter_loop_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nouter_loop_samples, 1)</span>
<span class="sd">        Weights associated with each innner loop sample</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    expected_obs_deviations : np.ndarray (nqois, 1)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">expected_obs_deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
        <span class="s2">&quot;ij,i-&gt;j&quot;</span><span class="p">,</span> <span class="n">deviations</span><span class="p">,</span> <span class="n">weights</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">expected_obs_deviations</span>


<span class="k">def</span> <span class="nf">oed_data_cvar</span><span class="p">(</span><span class="n">deviations</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the conditional value of risk of the deviations</span>
<span class="sd">    for each outer loop sample</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    deviations : np.ndarray (nouter_loop_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nouter_loop_samples, 1)</span>
<span class="sd">        Weights associated with each innner loop sample</span>

<span class="sd">    quantile : float</span>
<span class="sd">        The quantile used to compute of the conditional value at risk</span>
<span class="sd">        of the deviations for each outerloop obsevation</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    cvar_obs_deviations : np.ndarray (nqois, 1)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">quantile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">cvar_obs_deviations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">deviations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">qq</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">deviations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">cvar_obs_deviations</span><span class="p">[</span><span class="n">qq</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">conditional_value_at_risk</span><span class="p">(</span>
            <span class="n">deviations</span><span class="p">[:,</span> <span class="n">qq</span><span class="p">],</span> <span class="n">quantile</span><span class="p">,</span> <span class="n">weights</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cvar_obs_deviations</span>


<span class="k">def</span> <span class="nf">oed_standard_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the standard deviation for each outer loop sample using the</span>
<span class="sd">    corresponding inner loop samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : np.ndarray (nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>
<span class="sd">        Weights associated with each innner loop sample</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_vals : np.ndarray (nouter_loop_samples, nqois)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">variance</span> <span class="o">=</span> <span class="n">oed_variance_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
    <span class="c1"># rouding error can cause slightly negative values</span>
    <span class="n">variance</span><span class="p">[</span><span class="n">variance</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">oed_conditional_value_at_risk_deviation</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">quantile</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                            <span class="n">samples_sorted</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the conditional value at risk deviation for each outer loop</span>
<span class="sd">    sample using the corresponding inner loop samples</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    samples : np.ndarray (nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">         The samples</span>

<span class="sd">    weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>
<span class="sd">        Weights associated with each innner loop sample</span>

<span class="sd">    quantile : float</span>
<span class="sd">        The quantile of the conditional value at risk used to</span>
<span class="sd">        compute the deviation</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_vals : np.ndarray (nouter_loop_samples, nqois)</span>
<span class="sd">        The deviation vals</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">quantile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">samples_sorted</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;samples cannot be sorted if nqoi &gt; 1&quot;</span><span class="p">)</span>
    <span class="n">cvars</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">qq</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]):</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:,</span> <span class="n">qq</span><span class="p">]</span><span class="o">*</span><span class="n">weights</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:])</span>
            <span class="n">cvars</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">qq</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">conditional_value_at_risk</span><span class="p">(</span>
                <span class="n">samples</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:,</span> <span class="n">qq</span><span class="p">],</span> <span class="n">quantile</span><span class="p">,</span> <span class="n">weights</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:],</span> <span class="n">samples_sorted</span><span class="p">)</span> <span class="o">-</span>
                             <span class="n">mean</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cvars</span>


<div class="viewcode-block" id="BayesianBatchDeviationOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchDeviationOED.html#pyapprox.expdesign.BayesianBatchDeviationOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianBatchDeviationOED</span><span class="p">(</span><span class="n">AbstractBayesianOED</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute open-loop OED by minimizing the deviation on the push forward</span>
<span class="sd">    of the posterior through a QoI model.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                 <span class="n">prior_variable</span><span class="p">,</span> <span class="n">qoi_fun</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">ninner_loop_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">econ</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="o">=</span><span class="n">oed_standard_deviation</span><span class="p">,</span>
                 <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">pred_risk_fun</span><span class="o">=</span><span class="n">oed_prediction_average</span><span class="p">,</span>
                 <span class="n">data_risk_fun</span><span class="o">=</span><span class="n">oed_data_expectation</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">            The location of all design sample candidates</span>

<span class="sd">        obs_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns noiseless evaluations of the forward model.</span>

<span class="sd">        noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">            The standard deviation of the mean zero Gaussian noise added to</span>
<span class="sd">            each observation</span>

<span class="sd">        prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">            The prior variable consisting of independent univariate random</span>
<span class="sd">            variables</span>

<span class="sd">        qoi_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `qoi_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns evaluations of the forward model. Observations are</span>
<span class="sd">            assumed to be :math:`f(z)+\epsilon` where :math:`\epsilon` is</span>
<span class="sd">            additive noise nsamples : np.ndarray (nvars, nsamples)</span>

<span class="sd">        generate_inner_prior_samples : callable</span>
<span class="sd">           Function with the signature</span>

<span class="sd">            `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(</span>
<span class="sd">             nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">            Generate samples and associated weights used to evaluate</span>
<span class="sd">            the evidence computed by the inner loop</span>
<span class="sd">            If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">            weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">            wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">        ninner_loop_samples : integer</span>
<span class="sd">            The number of quadrature samples used for the inner integral that</span>
<span class="sd">            computes the evidence for each realiaztion of the predicted</span>
<span class="sd">            observations</span>

<span class="sd">        nouter_loop_samples : integer</span>
<span class="sd">            The number of Monte Carlo samples used to compute the outer</span>
<span class="sd">            integral over all possible observations</span>

<span class="sd">        quad_method : string</span>
<span class="sd">            The method used to compute the inner loop integral needed to</span>
<span class="sd">            evaluate the evidence for an outer loop sample. Options are</span>
<span class="sd">            [&quot;linear&quot;, &quot;quadratic&quot;, &quot;gaussian&quot;, &quot;monte_carlo&quot;]</span>
<span class="sd">            The first 3 construct tensor product quadrature rules from</span>
<span class="sd">            univariate rules that are respectively piecewise linear,</span>
<span class="sd">            piecewise quadratic or Gauss-quadrature.</span>

<span class="sd">        pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        econ : boolean</span>
<span class="sd">            Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">            This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">            this common data is copied and repeated for each outer loop sample</span>
<span class="sd">            so the rest of the code can remain the same. Eventually the data</span>
<span class="sd">            has to be tiled anyway when computing exepcted utility so this is</span>
<span class="sd">            not a big deal.</span>

<span class="sd">         deviation_fun : callable</span>
<span class="sd">             Function with the signature</span>

<span class="sd">            `deviation_fun(inner_loop_pred_qois, weights) -&gt;</span>
<span class="sd">             np.ndarray(nouter_loop_samples, nqois)`</span>

<span class="sd">             where</span>

<span class="sd">             inner_loop_pred_qois : np.ndarray (</span>
<span class="sd">             nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">             weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>

<span class="sd">        max_eval_concurrency : integer</span>
<span class="sd">            The number of threads used to compute OED design. Warning:</span>
<span class="sd">            this uses multiprocessing.Pool and seems to provide very little</span>
<span class="sd">            benefit and in many cases increases the CPU time.</span>

<span class="sd">        pred_risk_fun : callable</span>
<span class="sd">            Function to compute risk over multiple qoi with the signature</span>

<span class="sd">             `pred_risk_fun(expected_deviations) -&gt; float`</span>

<span class="sd">            where expected_deviations : np.ndarray (nqois, 1)</span>

<span class="sd">        data_risk_fun : callable</span>
<span class="sd">            Function to compute risk of deviations over all outerloop samples</span>

<span class="sd">             `data_risk_fun(deviations) -&gt; np.ndarray (nqois, 1)`</span>

<span class="sd">            where deviations : np.ndarray (nouter_loop_samples, nqois)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                         <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="p">,</span>
                         <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">generate_inner_prior_samples</span><span class="p">,</span>
                         <span class="n">econ</span><span class="o">=</span><span class="n">econ</span><span class="p">,</span> <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="n">max_eval_concurrency</span><span class="p">)</span>
        <span class="c1"># qoi fun deafult is None so that same api can be used for KL based OED</span>
        <span class="c1"># which does not require qoi_fun</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">qoi_fun</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;qoi_fun must be a callable function&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">deviation_fun</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;deviation_fun must be a callable function&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qoi_fun</span> <span class="o">=</span> <span class="n">qoi_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">deviation_fun</span> <span class="o">=</span> <span class="n">deviation_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pred_risk_fun</span> <span class="o">=</span> <span class="n">pred_risk_fun</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span> <span class="o">=</span> <span class="n">data_risk_fun</span>

    <span class="k">def</span> <span class="nf">__populate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the data needed to initialize the OED algorithm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;nouter_loop_samples * ninner_loop_samples: &quot;</span><span class="p">,</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">ninner_loop_samples</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">nouter_loop_samples</span><span class="p">)</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_prior_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_prior_samples</span><span class="p">,</span>
         <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_qois</span>
         <span class="p">)</span> <span class="o">=</span> <span class="n">precompute_expected_deviation_data</span><span class="p">(</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">generate_prior_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nouter_loop_samples</span><span class="p">,</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">obs_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_fun</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">qoi_fun</span><span class="p">,</span>
             <span class="bp">self</span><span class="o">.</span><span class="n">ninner_loop_samples</span><span class="p">,</span>
             <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">generate_inner_prior_samples</span><span class="p">,</span>
             <span class="n">econ</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">econ</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
            <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__sort_qoi</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Sort inner_loop_pred_qois and use this order to sort</span>
        <span class="c1"># inner_loop_prior_samples so that cvar deviation does not have to</span>
        <span class="c1"># constantly sort samples</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_qois</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Sorting can only be used for a single QoI&quot;</span><span class="p">)</span>
        <span class="n">idx1</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nouter_loop_samples</span><span class="p">):</span>
            <span class="n">idx2</span> <span class="o">=</span> <span class="n">idx1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">ninner_loop_samples</span>
            <span class="n">qoi_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_qois</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_qois</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_qois</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">qoi_indices</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_prior_samples</span><span class="p">[:,</span> <span class="n">idx1</span><span class="p">:</span><span class="n">idx2</span><span class="p">]</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_prior_samples</span><span class="p">[:,</span> <span class="n">idx1</span><span class="p">:</span><span class="n">idx2</span><span class="p">][:,</span> <span class="n">qoi_indices</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">[</span><span class="n">idx1</span><span class="p">:</span><span class="n">idx2</span><span class="p">]</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">[</span><span class="n">idx1</span><span class="p">:</span><span class="n">idx2</span><span class="p">][</span><span class="n">qoi_indices</span><span class="p">,</span> <span class="p">:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="n">qoi_indices</span><span class="p">]</span>
            <span class="n">idx1</span> <span class="o">=</span> <span class="n">idx2</span>

<div class="viewcode-block" id="BayesianBatchDeviationOED.populate"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchDeviationOED.html#pyapprox.expdesign.BayesianBatchDeviationOED.populate">[docs]</a>    <span class="k">def</span> <span class="nf">populate</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the data needed to initialize the OED algorithm.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__populate</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_qois</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># speeds up calcualtion of avar</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">__sort_qoi</span><span class="p">()</span></div>

<div class="viewcode-block" id="BayesianBatchDeviationOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianBatchDeviationOED.html#pyapprox.expdesign.BayesianBatchDeviationOED.compute_expected_utility">[docs]</a>    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the negative expected deviation in predictions of QoI</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">            The indices into the qoi vector associated with new design</span>
<span class="sd">            locations under consideration</span>

<span class="sd">        return_all : boolean</span>
<span class="sd">             False - return the utilities</span>
<span class="sd">             True - used for debugging returns utilities</span>
<span class="sd">             and itermediate data useful for testing</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        utility : float</span>
<span class="sd">            The negative expected deviation</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># unlike open loop design (closed loop batch design)</span>
        <span class="c1"># we do not update inner and outer loop weights but rather</span>
        <span class="c1"># just compute likelihood for all collected and new design indices</span>
        <span class="c1"># If want to update weights then we must have a different set of</span>
        <span class="c1"># weights for each inner iteration of the inner loop that is</span>
        <span class="c1"># computed using</span>
        <span class="c1"># the associated outerloop data</span>
        <span class="k">return</span> <span class="n">compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loglike_fun_from_noiseless_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_qois</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">deviation_fun</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">return_all</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BayesianSequentialOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialOED.html#pyapprox.expdesign.BayesianSequentialOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianSequentialOED</span><span class="p">(</span><span class="n">AbstractBayesianOED</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute sequential optimal experimental designs that collect</span>
<span class="sd">    data and use this to inform the choice of subsequent design locations.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_process</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">callable</span><span class="p">(</span><span class="n">obs_process</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;obs_process must be a callable function&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs_process</span> <span class="o">=</span> <span class="n">obs_process</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_importance_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_importance_weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights_up</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights_up</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evidence</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">__compute_evidence</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the evidence associated with using the true collected data.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        This is a private function because calling by user will upset</span>
<span class="sd">        evidence calculation</span>

<span class="sd">        Always just use the first inner loop sample set to compute evidence.</span>
<span class="sd">        To avoid numerical precision problems recompute evidence with</span>
<span class="sd">        all data as opposed to updating evidence just using new data</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log_like_vals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loglike_fun</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">ninner_loop_samples</span><span class="p">,</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">])</span>
        <span class="c1"># compute evidence moving from initial prior to current posterior</span>
        <span class="n">evidence_from_prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_like_vals</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
        <span class="c1"># compute evidence moving from previous posterior to current posterior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evidence</span> <span class="o">=</span> <span class="n">evidence_from_prior</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span> <span class="o">=</span> <span class="n">evidence_from_prior</span>

<div class="viewcode-block" id="BayesianSequentialOED.compute_importance_weights"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialOED.html#pyapprox.expdesign.BayesianSequentialOED.compute_importance_weights">[docs]</a>    <span class="k">def</span> <span class="nf">compute_importance_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the importance weights used in the computation of the expected</span>
<span class="sd">        utility that acccount for the fact we want to use the current posterior</span>
<span class="sd">        as the prior in the utility formula.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_importance_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglike_fun</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span><span class="p">[</span>
                <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">]))</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span>
        <span class="n">nobs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">[</span>
            <span class="p">:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">nobs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inner_importance_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loglike_fun</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span><span class="p">,</span> <span class="n">tmp</span><span class="p">))</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">evidence_from_prior</span></div>

        <span class="c1"># # above is a faster version of loop below</span>

        <span class="c1"># outer_importance_weights = np.empty((self.nouter_loop_samples, 1))</span>
        <span class="c1"># inner_importance_weights = np.empty(</span>
        <span class="c1">#     (self.nouter_loop_samples, self.ninner_loop_samples))</span>

        <span class="c1"># idx1 = 0</span>
        <span class="c1"># for ii in range(self.nouter_loop_samples):</span>
        <span class="c1">#     outer_importance_weights[ii] = np.exp(self.loglike_fun(</span>
        <span class="c1">#         self.collected_obs,</span>
        <span class="c1">#         self.outer_loop_pred_obs[</span>
        <span class="c1">#             ii:ii+1, self.collected_design_indices]))/ \</span>
        <span class="c1">#             self.evidence_from_prior</span>

        <span class="c1">#     idx2 = idx1 + self.ninner_loop_samples</span>
        <span class="c1">#     inner_importance_weights[ii, :] = np.exp(self.loglike_fun(</span>
        <span class="c1">#         self.collected_obs,</span>
        <span class="c1">#         self.inner_loop_pred_obs[</span>
        <span class="c1">#             idx1:idx2, self.collected_design_indices]))[:, 0] / \</span>
        <span class="c1">#         self.evidence_from_prior</span>
        <span class="c1">#     idx1 = idx2</span>
        <span class="c1"># np.allclose(self.outer_importance_weights, outer_importance_weights)</span>
        <span class="c1"># np.allclose(self.inner_importance_weights, inner_importance_weights)</span>

<div class="viewcode-block" id="BayesianSequentialOED.update_observations"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialOED.html#pyapprox.expdesign.BayesianSequentialOED.update_observations">[docs]</a>    <span class="k">def</span> <span class="nf">update_observations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_obs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Store the newly collected obsevations which will dictate</span>
<span class="sd">        the next design point.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        new_obs : np.ndarray (1, nnew_obs)</span>
<span class="sd">            The new observations</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        self.inner_importance_weights contains likelihood vals/evidence</span>
<span class="sd">        at inner_loop_samples</span>
<span class="sd">        self.inner_loop_weights is the prior quadrature weights which</span>
<span class="sd">        for random samples drawn from</span>
<span class="sd">        prior is just 1/N and for Gauss Quadrature is the quadrature rule</span>
<span class="sd">        weights.</span>

<span class="sd">        Similarly for self.outer_importance_weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span> <span class="o">=</span> <span class="n">new_obs</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_obs</span><span class="p">,</span> <span class="n">new_obs</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__compute_evidence</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">compute_importance_weights</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights_up</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">outer_importance_weights</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights_up</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">inner_importance_weights</span></div>

<div class="viewcode-block" id="BayesianSequentialOED.set_collected_design_indices"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialOED.html#pyapprox.expdesign.BayesianSequentialOED.set_collected_design_indices">[docs]</a>    <span class="k">def</span> <span class="nf">set_collected_design_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the initial design indices and collect data at the</span>
<span class="sd">        corresponding design points.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        indices : np.ndarray (nindices, 1)</span>
<span class="sd">            The indices corresponding to an initial design</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">new_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_process</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">update_observations</span><span class="p">(</span><span class="n">new_obs</span><span class="p">)</span></div></div>

    <span class="c1"># def update_design(self, return_all=False, rounding_decimals=16):</span>
    <span class="c1">#     return super().update_design(return_all, rounding_decimals)</span>


<div class="viewcode-block" id="BayesianSequentialKLOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialKLOED.html#pyapprox.expdesign.BayesianSequentialKLOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianSequentialKLOED</span><span class="p">(</span><span class="n">BayesianSequentialOED</span><span class="p">,</span> <span class="n">BayesianBatchKLOED</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute closed-loop OED my maximizing KL divergence between the prior and</span>
<span class="sd">    posterior.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                 <span class="n">prior_variable</span><span class="p">,</span> <span class="n">obs_process</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">ninner_loop_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">econ</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">            The location of all design sample candidates</span>

<span class="sd">        obs_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns noiseless evaluations of the forward model.</span>

<span class="sd">        noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">            The standard deviation of the mean zero Gaussian noise added to</span>
<span class="sd">            each observation</span>

<span class="sd">        prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">            The prior variable consisting of independent univariate random</span>
<span class="sd">            variables</span>

<span class="sd">        obs_process : callable</span>
<span class="sd">            The true data generation model with the signature</span>

<span class="sd">            `obs_process(design_indices) -&gt; np.ndarray (1, ndesign_indices)`</span>

<span class="sd">            where design_samples is np.ndarary (nvars, ndesign_indices)</span>

<span class="sd">        generate_inner_prior_samples : callable</span>
<span class="sd">           Function with the signature</span>

<span class="sd">            `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(</span>
<span class="sd">             nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">            Generate samples and associated weights used to evaluate</span>
<span class="sd">            the evidence computed by the inner loop</span>
<span class="sd">            If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">            weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">            wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">        ninner_loop_samples : integer</span>
<span class="sd">            The number of quadrature samples used for the inner integral that</span>
<span class="sd">            computes the evidence for each realiaztion of the predicted</span>
<span class="sd">            observations</span>

<span class="sd">        nouter_loop_samples : integer</span>
<span class="sd">            The number of Monte Carlo samples used to compute the outer</span>
<span class="sd">            integral over all possible observations</span>

<span class="sd">        quad_method : string</span>
<span class="sd">            The method used to compute the inner loop integral needed to</span>
<span class="sd">            evaluate the evidence for an outer loop sample. Options are</span>
<span class="sd">            [&quot;linear&quot;, &quot;quadratic&quot;, &quot;gaussian&quot;, &quot;monte_carlo&quot;]</span>
<span class="sd">            The first 3 construct tensor product quadrature rules from</span>
<span class="sd">            univariate rules that are respectively piecewise linear,</span>
<span class="sd">            piecewise quadratic or Gauss-quadrature.</span>

<span class="sd">        pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        econ : boolean</span>
<span class="sd">            Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">            This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">            this common data is copied and repeated for each outer loop sample</span>
<span class="sd">            so the rest of the code can remain the same. Eventually the data</span>
<span class="sd">            has to be tiled anyway when computing exepcted utility so this is</span>
<span class="sd">            not a big deal.</span>

<span class="sd">        max_eval_concurrency : integer</span>
<span class="sd">            The number of threads used to compute OED design. Warning:</span>
<span class="sd">            this uses multiprocessing.Pool and seems to provide very little</span>
<span class="sd">            benefit and in many cases increases the CPU time.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># obs_process default is None so same API can be used as</span>
        <span class="c1"># open loop design</span>
        <span class="n">BayesianBatchKLOED</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span>
            <span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span>
            <span class="n">generate_inner_prior_samples</span><span class="p">,</span> <span class="n">econ</span><span class="p">,</span> <span class="n">max_eval_concurrency</span><span class="p">)</span>
        <span class="n">BayesianSequentialOED</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_process</span><span class="p">)</span>

<div class="viewcode-block" id="BayesianSequentialKLOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialKLOED.html#pyapprox.expdesign.BayesianSequentialKLOED.compute_expected_utility">[docs]</a>    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the expected utility. Using the current posterior as the new</span>
<span class="sd">        prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">            The indices into the qoi vector associated with new design</span>
<span class="sd">            locations under consideration</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Passing None for collected_design_indices will ensure</span>
<span class="sd">        only obs at new_design indices is used to evaluate likelihood</span>
<span class="sd">        the data at collected indices is incoroporated into the</span>
<span class="sd">        inner and outer loop weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">compute_expected_kl_utility_monte_carlo</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loglike_fun_from_noiseless_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights_up</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights_up</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="BayesianSequentialDeviationOED"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialDeviationOED.html#pyapprox.expdesign.BayesianSequentialDeviationOED">[docs]</a><span class="k">class</span> <span class="nc">BayesianSequentialDeviationOED</span><span class="p">(</span>
        <span class="n">BayesianSequentialOED</span><span class="p">,</span> <span class="n">BayesianBatchDeviationOED</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute closed-loop OED by minimizing the deviation on the push forward</span>
<span class="sd">    of the posterior through a QoI model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
                 <span class="n">prior_variable</span><span class="p">,</span> <span class="n">qoi_fun</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">obs_process</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">nouter_loop_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                 <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">deviation_fun</span><span class="o">=</span><span class="n">oed_standard_deviation</span><span class="p">,</span>
                 <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">pred_risk_fun</span><span class="o">=</span><span class="n">oed_prediction_average</span><span class="p">,</span>
                 <span class="n">data_risk_fun</span><span class="o">=</span><span class="n">oed_data_expectation</span><span class="p">):</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">            The location of all design sample candidates</span>

<span class="sd">        obs_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns noiseless evaluations of the forward model.</span>

<span class="sd">        noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">            The standard deviation of the mean zero Gaussian noise added to</span>
<span class="sd">            each observation</span>

<span class="sd">        prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">            The prior variable consisting of independent univariate random</span>
<span class="sd">            variables</span>

<span class="sd">        obs_process : callable</span>
<span class="sd">            The true data generation model with the signature</span>

<span class="sd">            `obs_process(design_indices) -&gt; np.ndarray (1, ndesign_indices)`</span>

<span class="sd">            where design_samples is np.ndarary (nvars, ndesign_indices)</span>

<span class="sd">        qoi_fun : callable</span>
<span class="sd">            Function with the signature</span>

<span class="sd">            `qoi_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">            That returns evaluations of the forward model. Observations are</span>
<span class="sd">            assumed to be :math:`f(z)+\epsilon` where :math:`\epsilon` is</span>
<span class="sd">            additive noise nsamples : np.ndarray (nvars, nsamples)</span>

<span class="sd">        generate_inner_prior_samples : callable</span>
<span class="sd">           Function with the signature</span>

<span class="sd">            `generate_inner_prior_samples(nsamples) -&gt; np.ndarray(</span>
<span class="sd">             nvars, nsamples), np.ndarray(nsamples, 1)`</span>

<span class="sd">            Generate samples and associated weights used to evaluate</span>
<span class="sd">            the evidence computed by the inner loop</span>
<span class="sd">            If None then the function generate_outer_prior_samples is used and</span>
<span class="sd">            weights are assumed to be 1/nsamples. This function is useful if</span>
<span class="sd">            wanting to use multivariate quadrature to evaluate the evidence</span>

<span class="sd">        ninner_loop_samples : integer</span>
<span class="sd">            The number of quadrature samples used for the inner integral that</span>
<span class="sd">            computes the evidence for each realiaztion of the predicted</span>
<span class="sd">            observations</span>

<span class="sd">        nouter_loop_samples : integer</span>
<span class="sd">            The number of Monte Carlo samples used to compute the outer</span>
<span class="sd">            integral over all possible observations</span>

<span class="sd">        quad_method : string</span>
<span class="sd">            The method used to compute the inner loop integral needed to</span>
<span class="sd">            evaluate the evidence for an outer loop sample. Options are</span>
<span class="sd">            [&quot;linear&quot;, &quot;quadratic&quot;, &quot;gaussian&quot;, &quot;monte_carlo&quot;]</span>
<span class="sd">            The first 3 construct tensor product quadrature rules from</span>
<span class="sd">            univariate rules that are respectively piecewise linear,</span>
<span class="sd">            piecewise quadratic or Gauss-quadrature.</span>

<span class="sd">        pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        econ : boolean</span>
<span class="sd">            Make all inner loop samples the same for all outer loop samples.</span>
<span class="sd">            This reduces number of evaluations of prediction model. Currently</span>
<span class="sd">            this common data is copied and repeated for each outer loop sample</span>
<span class="sd">            so the rest of the code can remain the same. Eventually the data</span>
<span class="sd">            has to be tiled anyway when computing exepcted utility so this is</span>
<span class="sd">            not a big deal.</span>

<span class="sd">         deviation_fun : callable</span>
<span class="sd">             Function with the signature</span>

<span class="sd">            `deviation_fun(inner_loop_pred_qois, weights) -&gt;</span>
<span class="sd">             np.ndarray(nouter_loop_samples, nqois)`</span>

<span class="sd">             where</span>

<span class="sd">             inner_loop_pred_qois : np.ndarray (</span>
<span class="sd">             nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">             weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>

<span class="sd">        max_eval_concurrency : integer</span>
<span class="sd">            The number of threads used to compute OED design. Warning:</span>
<span class="sd">            this uses multiprocessing.Pool and seems to provide very little</span>
<span class="sd">            benefit and in many cases increases the CPU time.</span>

<span class="sd">        pred_risk_fun : callable</span>
<span class="sd">            Function to compute risk over multiple qoi with the signature</span>

<span class="sd">             `pred_risk_fun(expected_deviations) -&gt; float`</span>

<span class="sd">            where expected_deviations : np.ndarray (nqois, 1)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># obs_process default is None so same API can be used as</span>
        <span class="c1"># open loop design</span>
        <span class="n">BayesianBatchDeviationOED</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
            <span class="n">prior_variable</span><span class="p">,</span> <span class="n">qoi_fun</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="p">,</span>
            <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">generate_inner_prior_samples</span><span class="p">,</span>
            <span class="n">econ</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span> <span class="n">max_eval_concurrency</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">data_risk_fun</span><span class="p">)</span>
        <span class="n">BayesianSequentialOED</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_process</span><span class="p">)</span>

<div class="viewcode-block" id="BayesianSequentialDeviationOED.compute_expected_utility"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.BayesianSequentialDeviationOED.html#pyapprox.expdesign.BayesianSequentialDeviationOED.compute_expected_utility">[docs]</a>    <span class="k">def</span> <span class="nf">compute_expected_utility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collected_design_indices</span><span class="p">,</span>
                                 <span class="n">new_design_indices</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the expected utility. Using the current posterior as the new</span>
<span class="sd">        prior.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">            The indices into the qoi vector associated with the</span>
<span class="sd">            collected observations</span>

<span class="sd">        new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">            The indices into the qoi vector associated with new design</span>
<span class="sd">            locations under consideration</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Passing None for collected_design_indices will ensure</span>
<span class="sd">        only obs at new_design indices is used to evaluate likelihood</span>
<span class="sd">        the data at collected indices is incoroporated into the</span>
<span class="sd">        inner and outer loop weights</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO pass in these weights so do not have to do so much</span>
        <span class="c1"># multiplications</span>
        <span class="k">return</span> <span class="n">compute_negative_expected_deviation_monte_carlo</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">loglike_fun_from_noiseless_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_pred_obs</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_obs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_weights_up</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outer_loop_weights_up</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner_loop_pred_qois</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">deviation_fun</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">return_all</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_risk_fun</span><span class="p">)</span></div></div>


<span class="k">def</span> <span class="nf">get_oed_inner_quadrature_rule</span><span class="p">(</span><span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span>
                                  <span class="n">quad_method</span><span class="o">=</span><span class="s1">&#39;gauss&#39;</span><span class="p">):</span>
    <span class="n">nrandom_vars</span> <span class="o">=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
    <span class="n">ninner_loop_samples_1d</span> <span class="o">=</span> <span class="n">ninner_loop_samples</span>
    <span class="k">if</span> <span class="n">quad_method</span> <span class="o">==</span> <span class="s2">&quot;gauss&quot;</span><span class="p">:</span>
        <span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">prior_variable</span><span class="p">)</span>
        <span class="n">univariate_quad_rules</span> <span class="o">=</span> \
            <span class="n">get_univariate_quadrature_rules_from_variable</span><span class="p">(</span>
                <span class="n">prior_variable</span><span class="p">,</span> <span class="p">[</span><span class="n">ninner_loop_samples_1d</span><span class="p">]</span><span class="o">*</span><span class="n">nrandom_vars</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span> <span class="o">=</span> <span class="n">get_tensor_product_quadrature_rule</span><span class="p">(</span>
            <span class="p">[</span><span class="n">ninner_loop_samples_1d</span><span class="p">]</span><span class="o">*</span><span class="n">nrandom_vars</span><span class="p">,</span> <span class="n">nrandom_vars</span><span class="p">,</span>
            <span class="n">univariate_quad_rules</span><span class="p">,</span> <span class="n">transform_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span>

    <span class="n">degree</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;linear&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;quadratic&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">}[</span><span class="n">quad_method</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">is_bounded_continuous_variable</span><span class="p">():</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="mf">1e-6</span>
    <span class="n">new_ranges</span> <span class="o">=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">get_statistics</span><span class="p">(</span>
        <span class="s2">&quot;interval&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span> <span class="o">=</span> \
        <span class="n">get_tensor_product_piecewise_polynomial_quadrature_rule</span><span class="p">(</span>
            <span class="n">ninner_loop_samples_1d</span><span class="p">,</span> <span class="n">new_ranges</span><span class="p">,</span> <span class="n">degree</span><span class="p">)</span>
    <span class="n">w_quad</span> <span class="o">*=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_quad</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span>


<span class="k">def</span> <span class="nf">get_posterior_vals_at_inner_loop_samples</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">):</span>
    <span class="c1"># plot posterior for one realization of the data</span>
    <span class="c1"># nn : number of data used to form posterior</span>
    <span class="c1"># outer_loop_idx : the outer loop iteration used to generate the data</span>
    <span class="k">assert</span> <span class="n">nn</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">oed</span><span class="o">.</span><span class="n">compute_expected_utility</span><span class="p">(</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">[:</span><span class="n">nn</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">[</span><span class="n">nn</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="n">nn</span><span class="p">],</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">get_posterior_vals_at_inner_loop_samples_base</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_posterior_vals_at_inner_loop_samples_from_oed_results</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">,</span> <span class="n">oed_results</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    oed_results : list(list(dict))</span>
<span class="sd">         axis 0: each experimental design step</span>
<span class="sd">         axis 1: each design candidate</span>
<span class="sd">         dict: the data structures returned by the compute expected utility</span>
<span class="sd">              function used. Assumes that weights is returned as the</span>
<span class="sd">              is a key, i.e. index [ii][jj][&quot;weights&quot;] exists</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">nn</span> <span class="o">&gt;</span> <span class="mi">0</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">oed_results</span><span class="p">[</span><span class="n">nn</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">oed</span><span class="o">.</span><span class="n">collected_design_indices</span><span class="p">[</span><span class="n">nn</span><span class="o">-</span><span class="mi">1</span><span class="p">]][</span><span class="s2">&quot;weights&quot;</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">get_posterior_vals_at_inner_loop_samples_base</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_posterior_vals_at_inner_loop_samples_base</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">vals</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">weights</span><span class="p">[</span><span class="n">outer_loop_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">/</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">inner_loop_weights</span><span class="p">[</span><span class="n">outer_loop_idx</span><span class="p">,</span> <span class="p">:])[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="c1"># multiply vals by prior.</span>
    <span class="n">vals</span> <span class="o">*=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">inner_loop_prior_samples</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ninner_loop_samples</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">vals</span>


<span class="k">def</span> <span class="nf">get_posterior_2d_interpolant_from_oed_data</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">,</span> <span class="n">quad_method</span><span class="p">,</span>
        <span class="n">oed_results</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># plot posterior for one realization of the data</span>
    <span class="c1"># nn : number of data used to form posterior</span>
    <span class="c1"># outer_loop_idx : the outer loop iteration used to generate the data</span>
    <span class="k">assert</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span>
    <span class="k">if</span> <span class="n">oed_results</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">get_posterior_vals_at_inner_loop_samples</span><span class="p">(</span>
            <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">vals</span> <span class="o">=</span> <span class="n">get_posterior_vals_at_inner_loop_samples_from_oed_results</span><span class="p">(</span>
            <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">,</span> <span class="n">oed_results</span><span class="p">)</span>
    <span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="n">vals</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">quad_method</span> <span class="o">==</span> <span class="s2">&quot;gauss&quot;</span><span class="p">:</span>
        <span class="c1"># interpolate posterior vals onto equidistant mesh for plotting</span>
        <span class="n">nvars</span> <span class="o">=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span>
        <span class="n">abscissa_1d</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">dd</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
            <span class="n">abscissa_1d</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span>
                    <span class="n">oed</span><span class="o">.</span><span class="n">inner_loop_prior_samples</span><span class="p">[</span><span class="n">dd</span><span class="p">,</span> <span class="p">:</span><span class="n">ninner_loop_samples</span><span class="p">]))</span>
        <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tensor_product_barycentric_interpolation</span><span class="p">,</span> <span class="n">abscissa_1d</span><span class="p">,</span>
                      <span class="n">vals</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fun</span>

    <span class="n">quad_methods</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;quadratic&#39;</span><span class="p">,</span> <span class="s1">&#39;gauss&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">quad_method</span> <span class="o">!=</span> <span class="s2">&quot;linear&quot;</span> <span class="ow">and</span> <span class="n">quad_method</span> <span class="o">!=</span> <span class="s2">&quot;quadratic&quot;</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;quad_method must be in </span><span class="si">{</span><span class="n">quad_methods</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># if using piecewise polynomial quadrature interpolate between using</span>
    <span class="c1"># piecewise linear method</span>
    <span class="kn">from</span> <span class="nn">scipy.interpolate</span> <span class="kn">import</span> <span class="n">griddata</span>
    <span class="n">x_quad</span> <span class="o">=</span> <span class="n">oed</span><span class="o">.</span><span class="n">inner_loop_prior_samples</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ninner_loop_samples</span><span class="p">]</span>
    <span class="k">def</span> <span class="nf">fun</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">griddata</span><span class="p">(</span><span class="n">x_quad</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">vals</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fun</span>


<span class="k">def</span> <span class="nf">plot_2d_posterior_from_oed_data</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">oed_results</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

    <span class="kn">from</span> <span class="nn">pyapprox</span> <span class="kn">import</span> <span class="n">plt</span><span class="p">,</span> <span class="n">get_meshgrid_function_data</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">is_bounded_continuous_variable</span><span class="p">():</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.99</span>
    <span class="n">plot_limits</span> <span class="o">=</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">get_statistics</span><span class="p">(</span>
        <span class="s2">&quot;interval&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

    <span class="n">fun</span> <span class="o">=</span> <span class="n">get_posterior_2d_interpolant_from_oed_data</span><span class="p">(</span>
        <span class="n">oed</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nn</span><span class="p">,</span> <span class="n">outer_loop_idx</span><span class="p">,</span> <span class="n">method</span><span class="p">,</span> <span class="n">oed_results</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span> <span class="o">=</span> <span class="n">get_meshgrid_function_data</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="n">plot_limits</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">Z</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">21</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">tensor_product_barycentric_interpolation</span><span class="p">(</span><span class="n">abscissa_1d</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
    <span class="n">nvars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">abscissa_1d</span><span class="p">)</span>
    <span class="n">barycentric_weights_1d</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">dd</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nvars</span><span class="p">):</span>
        <span class="n">interval_length</span> <span class="o">=</span> <span class="n">abscissa_1d</span><span class="p">[</span><span class="n">dd</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">-</span><span class="n">abscissa_1d</span><span class="p">[</span><span class="n">dd</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
        <span class="n">barycentric_weights_1d</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">compute_barycentric_weights_1d</span><span class="p">(</span>
                <span class="n">abscissa_1d</span><span class="p">[</span><span class="n">dd</span><span class="p">],</span> <span class="n">interval_length</span><span class="o">=</span><span class="n">interval_length</span><span class="p">))</span>
    <span class="n">poly_vals</span> <span class="o">=</span> <span class="n">multivariate_barycentric_lagrange_interpolation</span><span class="p">(</span>
        <span class="n">samples</span><span class="p">,</span> <span class="n">abscissa_1d</span><span class="p">,</span> <span class="n">barycentric_weights_1d</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nvars</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">poly_vals</span>


<span class="k">def</span> <span class="nf">generate_inner_prior_samples_fixed</span><span class="p">(</span><span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Wrapper that can be used with functools.partial to create a</span>
<span class="sd">    function with the signature generate_inner_samples(nsamples)</span>
<span class="sd">    that always returns the same quadrature rule. This function</span>
<span class="sd">    will be called many times and creating a quadrature each time</span>
<span class="sd">    can be computationally expensive.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">nsamples</span> <span class="o">==</span> <span class="n">x_quad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">x_quad</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span>


<span class="k">def</span> <span class="nf">run_bayesian_batch_deviation_oed_deprecated</span><span class="p">(</span>
        <span class="n">prior_variable</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">qoi_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
        <span class="n">design_candidates</span><span class="p">,</span> <span class="n">pre_collected_design_indices</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="p">,</span>
        <span class="n">pred_risk_fun</span><span class="p">,</span> <span class="n">nexperiments</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span>
        <span class="n">quad_method</span><span class="p">,</span> <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_all</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">rounding_decimals</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Deprecated. Use get_bayesian_oed_optimizer()</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    prior_variable : pya.IndependentMarginalsVariable</span>
<span class="sd">        The prior variable consisting of independent univariate random</span>
<span class="sd">        variables</span>

<span class="sd">    obs_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `obs_fun(samples) -&gt; np.ndarray(nsamples, nobs)`</span>

<span class="sd">        which returns evaluations of the noiseless observation model.</span>

<span class="sd">    qoi_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `qoi_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">        which returns evaluations of the prediction model.</span>

<span class="sd">    noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">        The standard deviation of the mean zero Gaussian noise added to each</span>
<span class="sd">        observation</span>

<span class="sd">    design_candidates : np.ndarray (ndesign_vars, nsamples)</span>
<span class="sd">        The location of all design sample candidates</span>

<span class="sd">    pre_collected_indices : array_like</span>
<span class="sd">        The indices of the experiments that must be in the final design</span>

<span class="sd">    deviation_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `deviation_fun(inner_loop_pred_qois, weights) -&gt;</span>
<span class="sd">         np.ndarray(nouter_loop_samples, nqois)`</span>

<span class="sd">         where</span>

<span class="sd">         inner_loop_pred_qois : np.ndarray (nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">         weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>

<span class="sd">    pred_risk_fun : callable</span>
<span class="sd">        Function to compute risk over multiple qoi with the signature</span>

<span class="sd">         `pred_risk_fun(expected_deviations) -&gt; float`</span>

<span class="sd">        where expected_deviations : np.ndarray (nqois, 1)</span>

<span class="sd">    nexperiments : integer</span>
<span class="sd">        The number of experiments to be collected</span>

<span class="sd">    nouter_loop_samples : integer</span>
<span class="sd">        The number of Monte Carlo samples used to compute the outer integral</span>
<span class="sd">        over all possible observations</span>

<span class="sd">    ninner_loop_samples : integer</span>
<span class="sd">        The number of quadrature samples used for the inner integral that</span>
<span class="sd">        computes the evidence for each realiaztion of the predicted</span>
<span class="sd">        observations. If quad_method is a tensor product rule</span>
<span class="sd">        then this parameter actually specifies the number of points in each</span>
<span class="sd">        univariate rule so the total number of inner loop samples is</span>
<span class="sd">        ninner_loop_samples**nvars</span>

<span class="sd">    quad_method : string</span>
<span class="sd">        The method used to compute the inner loop integral needed to</span>
<span class="sd">        evaluate the evidence for an outer loop sample. Options are</span>
<span class="sd">        [&quot;linear&quot;, &quot;quadratic&quot;, &quot;gaussian&quot;, &quot;monte_carlo&quot;]</span>
<span class="sd">        The first 3 construct tensor product quadrature rules from univariate</span>
<span class="sd">        rules that are respectively piecewise linear, piecewise quadratic</span>
<span class="sd">        or Gauss-quadrature.</span>

<span class="sd">    max_eval_concurrency : integer</span>
<span class="sd">        The number of threads used to compute OED design. Warning:</span>
<span class="sd">        this uses multiprocessing.Pool and seems to provide very little benefit</span>
<span class="sd">        and in many cases increases the CPU time.</span>

<span class="sd">    return_all : boolean</span>
<span class="sd">        Return intermediate quantities used to compute experimental design.</span>
<span class="sd">        This is primarily intended for testing purposes</span>

<span class="sd">    rounding_decimals : integer</span>
<span class="sd">        The number of decimal places to round utility_vals to when choosing</span>
<span class="sd">        the optimal design. This can be useful when comparing with</span>
<span class="sd">        numerical solutions where 2 designs are equivalent analytically</span>
<span class="sd">        but numerically there are slight differences that causes design to be</span>
<span class="sd">        different</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    oed : BayesianBatchDeviationOED</span>
<span class="sd">        OED object</span>

<span class="sd">    oed_results : list</span>
<span class="sd">        Contains the intermediate quantities used to compute experimental</span>
<span class="sd">        design at each design iteration. If not return_all then it is a list of</span>
<span class="sd">        None. If return_all then for each iteration entry is another list</span>
<span class="sd">        containing intermediate quantities for each design candidate.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Define OED options</span>
    <span class="k">if</span> <span class="n">quad_method</span> <span class="o">!=</span> <span class="s2">&quot;monte_carlo&quot;</span><span class="p">:</span>
        <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span> <span class="o">=</span> <span class="n">get_oed_inner_quadrature_rule</span><span class="p">(</span>
            <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">quad_method</span><span class="p">)</span>
        <span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="n">x_quad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">generate_inner_prior_samples</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">generate_inner_prior_samples_fixed</span><span class="p">,</span> <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span><span class="p">)</span>
        <span class="n">econ</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># use default Monte Carlo sampling</span>
        <span class="n">generate_inner_prior_samples</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">econ</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Setup OED problem</span>
    <span class="n">oed</span> <span class="o">=</span> <span class="n">BayesianBatchDeviationOED</span><span class="p">(</span>
        <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span>
        <span class="n">qoi_fun</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="p">,</span> <span class="n">ninner_loop_samples</span><span class="p">,</span>
        <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="n">generate_inner_prior_samples</span><span class="p">,</span>
        <span class="n">econ</span><span class="o">=</span><span class="n">econ</span><span class="p">,</span> <span class="n">deviation_fun</span><span class="o">=</span><span class="n">deviation_fun</span><span class="p">,</span> <span class="n">pred_risk_fun</span><span class="o">=</span><span class="n">pred_risk_fun</span><span class="p">,</span>
        <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="n">max_eval_concurrency</span><span class="p">)</span>
    <span class="n">oed</span><span class="o">.</span><span class="n">populate</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">pre_collected_design_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">set_collected_design_indices</span><span class="p">(</span><span class="n">pre_collected_design_indices</span><span class="p">)</span>

    <span class="c1"># Generate experimental design</span>
    <span class="k">if</span> <span class="n">pre_collected_design_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">npre_collected_design_indices</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">npre_collected_design_indices</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pre_collected_design_indices</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">npre_collected_design_indices</span><span class="p">,</span> <span class="n">nexperiments</span><span class="p">):</span>
        <span class="n">results_step</span> <span class="o">=</span> <span class="n">oed</span><span class="o">.</span><span class="n">update_design</span><span class="p">(</span><span class="n">return_all</span><span class="p">,</span> <span class="n">rounding_decimals</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results_step</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">oed</span><span class="p">,</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">get_deviation_fun</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="p">{}):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the deviation function used to compute the deviation of the</span>
<span class="sd">    posterior push-forward for a realization of the observational data</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : string</span>
<span class="sd">        Name of the deviation function.</span>
<span class="sd">        Must be one of [&quot;std&quot;, &quot;cvar&quot;, &quot;entropic&quot;]</span>

<span class="sd">    opts : dict</span>
<span class="sd">         Any options needed by the desired deviation function. cvar requires</span>
<span class="sd">         {&quot;quantile&quot;, p} where 0&lt;=p&lt;1. No options are needed for the other</span>
<span class="sd">         deviation functions</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `deviation_fun(inner_loop_pred_qois, weights) -&gt;</span>
<span class="sd">         np.ndarray(nouter_loop_samples, nqois)`</span>

<span class="sd">         where</span>

<span class="sd">         inner_loop_pred_qois : np.ndarray (nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">         weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">deviation_funs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;std&quot;</span><span class="p">:</span> <span class="n">oed_standard_deviation</span><span class="p">,</span>
        <span class="s2">&quot;cvar&quot;</span><span class="p">:</span> <span class="n">oed_conditional_value_at_risk_deviation</span><span class="p">,</span>
        <span class="s2">&quot;entropic&quot;</span><span class="p">:</span> <span class="n">oed_entropic_deviation</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">deviation_funs</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> not in </span><span class="si">{</span><span class="n">deviation_funs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">deviation_funs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="o">**</span><span class="n">opts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fun</span>


<span class="k">def</span> <span class="nf">get_data_risk_fun</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">opts</span><span class="o">=</span><span class="p">{}):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the risk function used to compute the risk of the deviation for all</span>
<span class="sd">    outerloop realizations of the observations</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : string</span>
<span class="sd">        Name of the deviation function.</span>
<span class="sd">        Must be one of [&quot;std&quot;, &quot;cvar&quot;, &quot;entropic&quot;]</span>

<span class="sd">    opts : dict</span>
<span class="sd">         Any options needed by the desired deviation function. cvar requires</span>
<span class="sd">         {&quot;quantile&quot;, p} where 0&lt;=p&lt;1. No options are needed for the other</span>
<span class="sd">         deviation functions</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    deviation_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `deviation_fun(inner_loop_pred_qois, weights) -&gt;</span>
<span class="sd">         np.ndarray(nouter_loop_samples, nqois)`</span>

<span class="sd">         where</span>

<span class="sd">         inner_loop_pred_qois : np.ndarray (nouter_loop_samples, ninner_loop_samples, nqois)</span>
<span class="sd">         weights : np.ndarray (nouter_loop_samples, ninner_loop_samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">risk_funs</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;mean&quot;</span><span class="p">:</span> <span class="n">oed_data_expectation</span><span class="p">,</span>
        <span class="s2">&quot;cvar&quot;</span><span class="p">:</span> <span class="n">oed_data_cvar</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">risk_funs</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> not in </span><span class="si">{</span><span class="n">risk_funs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="n">fun</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">risk_funs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="o">**</span><span class="n">opts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fun</span>


<span class="k">def</span> <span class="nf">extract_independent_noise_cov</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    When computing laplace approximations we need a covariance matrix that</span>
<span class="sd">    treats each observation independent even when indices are the same,</span>
<span class="sd">    that is we have two or more observations for the same observation matrix</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">nindices</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">nindices</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cov</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ix_</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="n">indices</span><span class="p">)]</span>
    <span class="n">new_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">cov</span><span class="p">)[</span><span class="n">indices</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">new_cov</span>


<span class="k">def</span> <span class="nf">sequential_oed_synthetic_observation_process</span><span class="p">(</span>
        <span class="n">obs_fun</span><span class="p">,</span> <span class="n">true_sample</span><span class="p">,</span> <span class="n">noise_fun</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use obs_model to generate all observations then downselect. For true</span>
<span class="sd">    observation processes this defeats the purpose of experimental design</span>
<span class="sd">    In these cases a custom obs_model must takes design indices as an</span>
<span class="sd">    argument.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    obs_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `obs_fun() -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">        That returns the synethic truth for all design candidates.</span>

<span class="sd">    true_sample : np.ndaray (nvars, 1)</span>
<span class="sd">        The true sample used to generate the synthetic truth</span>

<span class="sd">    new_design_indices : np.ndarray (nnew_obs)</span>
<span class="sd">        The indices into the qoi vector associated with new design locations</span>
<span class="sd">        under consideration</span>

<span class="sd">    noise_fun : callable</span>
<span class="sd">        Function with signature</span>

<span class="sd">        `noise_fun(values, new_design_indices) -&gt; np.ndarray (values.shape[0], new_design_indices.shape)`</span>

<span class="sd">         that returns noise for the new observations. Here</span>
<span class="sd">         values : np.ndarray (1, nobs) and</span>
<span class="sd">         new_design_indices : np.ndarary (nindices) where nindices&lt;=nobs</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">all_obs</span> <span class="o">=</span> <span class="n">obs_fun</span><span class="p">(</span><span class="n">true_sample</span><span class="p">)</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">noise_fun</span><span class="p">(</span><span class="n">all_obs</span><span class="p">,</span> <span class="n">new_design_indices</span><span class="p">)</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">all_obs</span><span class="p">[:,</span> <span class="n">new_design_indices</span><span class="p">]</span><span class="o">+</span><span class="n">noise</span>
    <span class="k">return</span> <span class="n">obs</span>


<span class="k">def</span> <span class="nf">gaussian_noise_fun</span><span class="p">(</span><span class="n">noise_std</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">active_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate gaussian possibly heteroscedastic random noise</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    noise_std : float or np.ndarray (nobs)</span>
<span class="sd">        The standard deviation of the noise at each observation</span>

<span class="sd">    values : np.ndarray (nsamples, nobs)</span>
<span class="sd">        The observations at variour realizations of the random parameters</span>

<span class="sd">    active_indices :np.ndarray (nindices)</span>
<span class="sd">        The indices of the active observations with nindices &lt;= nobs</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    noise : np.ndarray (nsamples, nindices)</span>
<span class="sd">        The noise at the active observations nindices=nobs if</span>
<span class="sd">        active_indices is None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">noise_std</span> <span class="o">=</span> <span class="n">noise_std</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">active_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">active_indices</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
        <span class="mi">0</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">[</span><span class="n">active_indices</span><span class="p">],</span> <span class="n">shape</span><span class="p">)</span>


<div class="viewcode-block" id="get_bayesian_oed_optimizer"><a class="viewcode-back" href="../../../api/pyapprox.expdesign.get_bayesian_oed_optimizer.html#pyapprox.expdesign.get_bayesian_oed_optimizer">[docs]</a><span class="k">def</span> <span class="nf">get_bayesian_oed_optimizer</span><span class="p">(</span>
        <span class="n">short_oed_type</span><span class="p">,</span> <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span>
        <span class="n">prior_variable</span><span class="p">,</span> <span class="n">nouter_loop_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">ninner_loop_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">quad_method</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">pre_collected_design_indices</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialize a Bayesian OED optimizer.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    short_oed_type : string</span>
<span class="sd">        The type of experimental design strategy</span>

<span class="sd">    design_candidates : np.ndarray (nvars, nsamples)</span>
<span class="sd">        The location of all design sample candidates</span>

<span class="sd">    obs_fun : callable</span>
<span class="sd">        Function with the signature</span>

<span class="sd">        `obs_fun(samples) -&gt; np.ndarray(nsamples, nqoi)`</span>

<span class="sd">        That returns noiseless evaluations of the forward model.</span>

<span class="sd">    noise_std : float or np.ndarray (nobs, 1)</span>
<span class="sd">        The standard deviation of the mean zero Gaussian noise added to each</span>
<span class="sd">        observation</span>

<span class="sd">    ninner_loop_samples : integer</span>
<span class="sd">        The number of quadrature samples used for the inner integral that</span>
<span class="sd">        computes the evidence for each realiaztion of the predicted</span>
<span class="sd">        observations</span>

<span class="sd">    nouter_loop_samples : integer</span>
<span class="sd">        The number of Monte Carlo samples used to compute the outer integral</span>
<span class="sd">        over all possible observations</span>

<span class="sd">    quad_method : string</span>
<span class="sd">        The method used to compute the inner loop integral needed to</span>
<span class="sd">        evaluate the evidence for an outer loop sample. Options are</span>
<span class="sd">        [&quot;linear&quot;, &quot;quadratic&quot;, &quot;gaussian&quot;, &quot;monte_carlo&quot;]</span>
<span class="sd">        The first 3 construct tensor product quadrature rules from univariate</span>
<span class="sd">        rules that are respectively piecewise linear, piecewise quadratic</span>
<span class="sd">        or Gauss-quadrature.</span>

<span class="sd">    pre_collected_design_indices : np.ndarray (nobs)</span>
<span class="sd">        The indices into the qoi vector associated with the</span>
<span class="sd">        collected observations</span>

<span class="sd">    kwargs : kwargs</span>
<span class="sd">        Key word arguments specific to the OED type</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    oed : pyapprox.expdesign.AbstractBayesianOED</span>
<span class="sd">        Bayesian OED optimizer object</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="s2">&quot;obs_process&quot;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">oed_type</span> <span class="o">=</span> <span class="s2">&quot;closed_loop_&quot;</span> <span class="o">+</span> <span class="n">short_oed_type</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">oed_type</span> <span class="o">=</span> <span class="s2">&quot;open_loop_&quot;</span> <span class="o">+</span> <span class="n">short_oed_type</span>

    <span class="n">oed_types</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;open_loop_kl_params&quot;</span><span class="p">:</span> <span class="n">BayesianBatchKLOED</span><span class="p">,</span>
                 <span class="s2">&quot;closed_loop_kl_params&quot;</span><span class="p">:</span> <span class="n">BayesianSequentialKLOED</span><span class="p">,</span>
                 <span class="s2">&quot;open_loop_dev_pred&quot;</span><span class="p">:</span> <span class="n">BayesianBatchDeviationOED</span><span class="p">,</span>
                 <span class="s2">&quot;closed_loop_dev_pred&quot;</span><span class="p">:</span> <span class="n">BayesianSequentialDeviationOED</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">oed_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">oed_types</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;oed_type </span><span class="si">{</span><span class="n">short_oed_type</span><span class="si">}</span><span class="s2"> not supported.&quot;</span>
        <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;Select from [kl_params, dev_pred]&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="ow">and</span>
            <span class="n">noise_std</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">design_candidates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;noise_std must be specified for each design candiate&quot;</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">quad_method</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">prior_variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">quad_method</span> <span class="o">=</span> <span class="s2">&quot;quadratic&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">quad_method</span> <span class="o">==</span> <span class="s2">&quot;monte_carlo&quot;</span>

    <span class="k">if</span> <span class="n">nouter_loop_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nouter_loop_samples</span> <span class="o">=</span> <span class="mi">1000</span>

    <span class="k">if</span> <span class="n">quad_method</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;gauss&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">,</span> <span class="s2">&quot;quadratic&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">ninner_loop_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="mi">20</span>
        <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span> <span class="o">=</span> <span class="n">get_oed_inner_quadrature_rule</span><span class="p">(</span>
            <span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span> <span class="n">quad_method</span><span class="p">)</span>
        <span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="n">x_quad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">generate_inner_prior_samples</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">generate_inner_prior_samples_fixed</span><span class="p">,</span> <span class="n">x_quad</span><span class="p">,</span> <span class="n">w_quad</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">quad_method</span> <span class="o">==</span> <span class="s2">&quot;monte_carlo&quot;</span><span class="p">:</span>
        <span class="c1"># use default Monte Carlo sampling</span>
        <span class="k">if</span> <span class="n">ninner_loop_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ninner_loop_samples</span> <span class="o">=</span> <span class="mi">1000</span>
        <span class="n">generate_inner_prior_samples</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Incorrect quad_method </span><span class="si">{</span><span class="n">quad_method</span><span class="si">}</span><span class="s2"> specified&quot;</span><span class="p">)</span>
    <span class="n">econ</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">oed</span> <span class="o">=</span> <span class="n">oed_types</span><span class="p">[</span><span class="n">oed_type</span><span class="p">](</span>
        <span class="n">design_candidates</span><span class="p">,</span> <span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_std</span><span class="p">,</span> <span class="n">prior_variable</span><span class="p">,</span>
        <span class="n">nouter_loop_samples</span><span class="o">=</span><span class="n">nouter_loop_samples</span><span class="p">,</span>
        <span class="n">ninner_loop_samples</span><span class="o">=</span><span class="n">ninner_loop_samples</span><span class="p">,</span> <span class="n">econ</span><span class="o">=</span><span class="n">econ</span><span class="p">,</span>
        <span class="n">generate_inner_prior_samples</span><span class="o">=</span><span class="n">generate_inner_prior_samples</span><span class="p">,</span>
        <span class="n">max_eval_concurrency</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">oed</span><span class="o">.</span><span class="n">populate</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">pre_collected_design_indices</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">oed</span><span class="o">.</span><span class="n">set_collected_design_indices</span><span class="p">(</span><span class="n">pre_collected_design_indices</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">oed</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>