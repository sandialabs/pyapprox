

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Control Variate Monte Carlo &mdash; PyApprox 1.0.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"V": ["{\\boldsymbol{#1}}", 1], "mean": ["{\\mathbb{E}\\left[#1\\right]}", 1], "var": ["{\\mathbb{V}\\left[#1\\right]}", 1], "argmin": "{\\mathrm{argmin}}", "rv": "z", "reals": "\\mathbb{R}", "pdf": "\\rho", "rvdom": "\\Gamma", "coloneqq": "\\colon=", "norm": ["\\lVert #1 \\rVert", 1], "argmax": ["\\operatorname{argmax}"], "covar": ["\\mathbb{C}\\text{ov}\\left[#1,#2\\right]", 2], "corr": ["\\mathbb{C}\\text{or}\\left[#1,#2\\right]", 2], "ai": "\\alpha", "bi": "\\beta", "dx": ["\\;\\mathrm{d}#1", 1]}}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Approximate Control Variate Monte Carlo" href="plot_approximate_control_variate_monte_carlo.html" />
    <link rel="prev" title="Sensitivity Analysis" href="../foundations/plot_sensitivity_analysis.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> PyApprox
          

          
            
            <img src="../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">PyApprox Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#foundations">Foundations</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#multi-fidelity-monte-carlo-methods">Multi-Fidelity Monte Carlo Methods</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Control Variate Monte Carlo</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_approximate_control_variate_monte_carlo.html">Approximate Control Variate Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multi_level_monte_carlo.html">Multi-level Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multi_fidelity_monte_carlo.html">Multi-fidelity Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_many_model_approximate_control_variate_monte_carlo.html">Generalized Approximate Control Variate Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multi_index_collocation.html">Multi-index Stochastic Collocation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#polynomial-chaos-expansions">Polynomial Chaos Expansions</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PyApprox</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">PyApprox Tutorials</a> &raquo;</li>
        
      <li>Control Variate Monte Carlo</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/auto_tutorials/multi_fidelity/plot_control_variate_monte_carlo.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-tutorials-multi-fidelity-plot-control-variate-monte-carlo-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="control-variate-monte-carlo">
<span id="sphx-glr-auto-tutorials-multi-fidelity-plot-control-variate-monte-carlo-py"></span><h1>Control Variate Monte Carlo<a class="headerlink" href="#control-variate-monte-carlo" title="Permalink to this headline">¶</a></h1>
<p>This tutorial describes how to implement and deploy control variate Monte Carlo sampling to compute the expectations of the output of a high-fidelity model using a lower-fidelity model with a known mean. The information presented here builds upon the tutorial <a class="reference internal" href="../foundations/plot_monte_carlo.html#sphx-glr-auto-tutorials-foundations-plot-monte-carlo-py"><span class="std std-ref">Monte Carlo Quadrature</span></a>.</p>
<p>Let us introduce a model <span class="math notranslate nohighlight">\(Q_\V{\kappa}\)</span> with known mean <span class="math notranslate nohighlight">\(\mu_{\V{\kappa}}\)</span>. We can use this model to estimate the mean of <span class="math notranslate nohighlight">\(Q_{\V{\alpha}}\)</span> via <a class="reference internal" href="#lmwor1982" id="id1"><span>[LMWOR1982]</span></a></p>
<div class="math notranslate nohighlight">
\[\begin{split}Q_{\V{\alpha},N}^{\text{CV}} &amp;= Q_{\V{\alpha},N} + \eta \left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}} \right) \\\end{split}\]</div>
<p>Here <span class="math notranslate nohighlight">\(\eta\)</span> is a free parameter which can be optimized to the reduce the variance of this so called control variate estimator, which is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}\var{Q_{\V{\alpha},N}^{\text{CV}}} &amp;= \var{Q_{\V{\alpha},N} + \eta \left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}\\
 &amp;=\var{Q_{\V{\alpha},N}} + \eta^2\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}+ 2\eta^2\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}\\
 &amp;=\var{Q_{\V{\alpha},N}}\left(1+\eta^2\frac{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{Q_{\V{\alpha},N}}}+ 2\eta^2\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{Q_{\V{\alpha},N}}}\right).\end{split}\]</div>
<p>The first line follows from the variance of sums of random variables.</p>
<p>We can measure the change in MSE bys using the control variate estimator, by looking at the ratio of the CVMC and MC estimator variances. The variance reduction ratio is</p>
<div class="math notranslate nohighlight">
\[\gamma=\frac{\var{Q_{\V{\alpha},N}^{\text{CV}}}}{\var{Q_{\V{\alpha},N}}}=\left(1+\eta^2\frac{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{Q_{\V{\alpha},N}}}+ 2\eta\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{Q_{\V{\alpha},N}}}\right)\]</div>
<p>The variance reduction can be minimized by setting its gradient to zero and solving for <span class="math notranslate nohighlight">\(\eta\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[\begin{split} \frac{d}{d\eta}\gamma  &amp;= 2\eta\frac{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{Q_{\V{\alpha},N}}}+ 2\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{Q_{\V{\alpha},N}}} = 0\\
&amp;\implies \eta\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}+ \covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)} = 0\\
&amp;\implies \eta=-\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}\\
&amp;=-\frac{\covar{Q_{\V{\alpha},N}}{Q_{\V{\kappa},N}}}{\var{Q_{\V{\kappa},N}}}\end{split}\]</div>
<p>With this choice</p>
<div class="math notranslate nohighlight">
\[\begin{split}\gamma &amp;= 1+\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}^2}{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}^2}\frac{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{Q_{\V{\alpha},N}}}-2\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}}{\var{Q_{\V{\alpha},N}}}\\
&amp;= 1+\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}^2}{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}\var{Q_{\V{\alpha},N}}}-2\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}^2}{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}\var{Q_{\V{\alpha},N}}}\\
 &amp;= 1-\corr{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa}}\right)}^2\\
 &amp;= 1-\corr{Q_{\V{\alpha},N}}{Q_{\V{\kappa},N}}^2\end{split}\]</div>
<p>Thus if a two highly correlated models (one with a known mean) are available then we can drastically reduce the MSE of our estimate of the unknown mean.</p>
<p>Again consider the tunable model ensemble. The correlation between the models <span class="math notranslate nohighlight">\(f_0\)</span> and <span class="math notranslate nohighlight">\(f_1\)</span> can be tuned by varying <span class="math notranslate nohighlight">\(\theta_1\)</span>. For a given choice of theta lets compute a single relization of the CVMC estimate of <span class="math notranslate nohighlight">\(\mean{f_0}\)</span></p>
<p>First let us setup the problem and compute a single estimate using CVMC</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyapprox</span> <span class="k">as</span> <span class="nn">pya</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">pyapprox.tests.test_control_variate_monte_carlo</span> <span class="kn">import</span> <span class="n">TunableModelEnsemble</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">uniform</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">shifts</span><span class="o">=</span><span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span><span class="o">.</span><span class="mi">2</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TunableModelEnsemble</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="o">*.</span><span class="mi">95</span><span class="p">,</span><span class="n">shifts</span><span class="o">=</span><span class="n">shifts</span><span class="p">)</span>

<span class="n">nsamples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e2</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span>
<span class="n">values0</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">m0</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">values1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">m1</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_covariance_matrix</span><span class="p">()</span>
<span class="n">eta</span> <span class="o">=</span> <span class="o">-</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="c1">#cov_mc = np.cov(values0,values1)</span>
<span class="c1">#eta_mc = -cov_mc[0,1]/cov_mc[0,0]</span>
<span class="n">exact_integral_f0</span><span class="p">,</span><span class="n">exact_integral_f1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">shifts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">cv_mean</span> <span class="o">=</span> <span class="n">values0</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">+</span><span class="n">eta</span><span class="o">*</span><span class="p">(</span><span class="n">values1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">-</span><span class="n">exact_integral_f1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MC difference squared =&#39;</span><span class="p">,(</span><span class="n">values0</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">-</span><span class="n">exact_integral_f0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CVMC difference squared =&#39;</span><span class="p">,(</span><span class="n">cv_mean</span><span class="o">-</span><span class="n">exact_integral_f0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>MC difference squared = 0.01473604359753749
CVMC difference squared = 5.954528881712521e-05
</pre></div>
</div>
<p>Now lets look at the statistical properties of the CVMC estimator</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ntrials</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">ntrials</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ntrials</span><span class="p">):</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span>
    <span class="n">values0</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">m0</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">values1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">m1</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">means</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">values0</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">means</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">values0</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">+</span><span class="n">eta</span><span class="o">*</span><span class="p">(</span><span class="n">values1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">-</span><span class="n">exact_integral_f1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Theoretical variance reduction&quot;</span><span class="p">,</span>
      <span class="mi">1</span><span class="o">-</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Achieved variance reduction&quot;</span><span class="p">,</span>
      <span class="n">means</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="n">means</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Theoretical variance reduction 0.055234554161570304
Achieved variance reduction 0.05749985629263281
</pre></div>
</div>
<p>The following plot shows that unlike the <a class="reference internal" href="../foundations/plot_monte_carlo.html#estimator-histogram"><span class="std std-ref">Monte Carlo estimator</span></a>. <span class="math notranslate nohighlight">\(\mean{f_1}\)</span> the CVMC estimator is unbiased and has a smaller variance.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">textstr</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">r</span><span class="s1">&#39;$E[Q_{0,N}]=\mathrm{</span><span class="si">%.2e</span><span class="s1">}$&#39;</span><span class="o">%</span><span class="n">means</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                     <span class="sa">r</span><span class="s1">&#39;$V[Q_{0,N}]=\mathrm{</span><span class="si">%.2e</span><span class="s1">}$&#39;</span><span class="o">%</span><span class="n">means</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">(),</span>
                     <span class="sa">r</span><span class="s1">&#39;$E[Q_{0,N}^\mathrm</span><span class="si">{CV}</span><span class="s1">]=\mathrm{</span><span class="si">%.2e</span><span class="s1">}$&#39;</span><span class="o">%</span><span class="n">means</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
                     <span class="sa">r</span><span class="s1">&#39;$V[Q_{0,N}^\mathrm</span><span class="si">{CV}</span><span class="s1">]=\mathrm{</span><span class="si">%.2e</span><span class="s1">}$&#39;</span><span class="o">%</span><span class="n">means</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">()])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">means</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="n">ntrials</span><span class="o">//</span><span class="mi">100</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$Q_{0,N}$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">means</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="n">ntrials</span><span class="o">//</span><span class="mi">100</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$Q_{0,N}^\mathrm</span><span class="si">{CV}</span><span class="s1">$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$E[Q_0]$&#39;</span><span class="p">)</span>
<span class="n">props</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;boxstyle&#39;</span><span class="p">:</span><span class="s1">&#39;round&#39;</span><span class="p">,</span><span class="s1">&#39;facecolor&#39;</span><span class="p">:</span><span class="s1">&#39;white&#39;</span><span class="p">,</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.75</span><span class="p">,</span><span class="n">textstr</span><span class="p">,</span><span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span><span class="n">bbox</span><span class="o">=</span><span class="n">props</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../../_images/sphx_glr_plot_control_variate_monte_carlo_001.png" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_control_variate_monte_carlo_001.png" />
<p>Change <code class="docutils literal notranslate"><span class="pre">eta</span></code> to <code class="docutils literal notranslate"><span class="pre">eta_mc</span></code> to see how the variance reduction changes when the covariance between models is approximated</p>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<dl class="citation">
<dt class="label" id="lmwor1982"><span class="brackets"><a class="fn-backref" href="#id1">LMWOR1982</a></span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1287/opre.30.1.182">S.S. Lavenberg, T.L. Moeller, P.D. Welch, Statistical results on control variables with application to queueing network simulation, Oper. Res., 30, 45, 182-202, 1982.</a></p>
</dd>
</dl>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.404 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-multi-fidelity-plot-control-variate-monte-carlo-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/16e8ce5475de2150eca560fa5b8e2b4a/plot_control_variate_monte_carlo.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_control_variate_monte_carlo.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4ec9683a34cdddf2defc8ab87430f6ef/plot_control_variate_monte_carlo.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_control_variate_monte_carlo.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="plot_approximate_control_variate_monte_carlo.html" class="btn btn-neutral float-right" title="Approximate Control Variate Monte Carlo" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../foundations/plot_sensitivity_analysis.html" class="btn btn-neutral float-left" title="Sensitivity Analysis" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>