<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Parametrically Defined Approximate Control Variates &mdash; PyApprox 1.0.3 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script>window.MathJax = {"tex": {"macros": {"V": ["{\\boldsymbol{#1}}", 1], "mean": ["{\\mathbb{E}\\left[#1\\right]}", 1], "var": ["{\\mathbb{V}\\left[#1\\right]}", 1], "rv": "{z}", "rvset": "{\\mathcal{Z}}", "reals": "\\mathbb{R}", "pdf": "\\rho", "rvdom": "\\Gamma", "coloneqq": "\\colon=", "norm": ["{\\lVert #1 \\rVert}", 1], "argmax": ["\\operatorname{argmax}"], "argmin": ["\\operatorname{argmin}"], "covar": ["\\mathbb{C}\\text{ov}\\left[#1,#2\\right]", 2], "corr": ["\\mathbb{C}\\text{or}\\left[#1,#2\\right]", 2], "ai": "\\alpha", "bi": "\\beta", "dx": ["\\;\\text{d}#1", 1], "mat": ["{\\boldsymbol{\\mathrm{#1}}}", 1]}}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Multioutput Approximate Control Variates" href="plot_multioutput_acv.html" />
    <link rel="prev" title="Multi-fidelity Monte Carlo" href="plot_multi_fidelity_monte_carlo.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            PyApprox
              <img src="../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Software Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Theoretical Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#model-analysis">Model Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#inference">Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#experimental-design">Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#surrogates">Surrogates</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#multi-fidelity-methods">Multi-Fidelity Methods</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_monte_carlo.html">Monte Carlo Quadrature</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multioutput_monte_carlo.html">Monte Carlo Quadrature: Beyond Mean Estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_control_variate_monte_carlo.html">Two Model Control Variate Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_approximate_control_variates.html">Two model Approximate Control Variate Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_many_model_acv.html">Approximate Control Variate Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="acv_covariances.html">Delta-Based Covariance Formulas For Approximate Control Variates</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_allocation_matrices.html">Approximate Control Variate Allocation Matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multi_level_monte_carlo.html">Multi-level Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multi_fidelity_monte_carlo.html">Multi-fidelity Monte Carlo</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Parametrically Defined Approximate Control Variates</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#generalized-multi-fidelity-estimators">Generalized Multi-fidelity Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generalized-recursive-difference-estimators">Generalized Recursive Difference Estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generalized-independent-sample-estimators">Generalized Independent Sample Estimators</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_multioutput_acv.html">Multioutput Approximate Control Variates</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_pilot_studies.html">Pilot Studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_ensemble_selection.html">Model Ensemble Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multilevel_blue.html">Multilevel Best Linear Unbiased estimators (MLBLUE)</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multiindex_collocation.html">Multi-level and Multi-index Collocation</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multifidelity_gp.html">Multifidelity Gaussian processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_gaussian_mfnets.html">MFNets: Multi-fidelity networks</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../user_reference_guide.html">User Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PyApprox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Theoretical Tutorials</a></li>
      <li class="breadcrumb-item active">Parametrically Defined Approximate Control Variates</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/auto_tutorials/multi_fidelity/plot_pacv.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-tutorials-multi-fidelity-plot-pacv-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="parametrically-defined-approximate-control-variates">
<span id="sphx-glr-auto-tutorials-multi-fidelity-plot-pacv-py"></span><h1>Parametrically Defined Approximate Control Variates<a class="headerlink" href="#parametrically-defined-approximate-control-variates" title="Permalink to this heading"></a></h1>
<p>MLMC and MFMC are just two possible ACV estimators derived from two different allocation matrices. This tutorial presents Numerous other ACV estimators which can be constructed by utilizing different allocation matrices.</p>
<p><a class="reference internal" href="plot_multi_fidelity_monte_carlo.html#sphx-glr-auto-tutorials-multi-fidelity-plot-multi-fidelity-monte-carlo-py"><span class="std std-ref">Multi-fidelity Monte Carlo</span></a>) demonstrates that MFMC and MLMC are incapable of achieving the variance reduction of CV estimators with known statistics because model <span class="math notranslate nohighlight">\(m\)</span> as a contol variate to help estimate the statistic of model <span class="math notranslate nohighlight">\(m-1\)</span>. ormally, a model <span class="math notranslate nohighlight">\(f_\beta\)</span> acts as a control variate for model <span class="math notranslate nohighlight">\(f_\alpha\)</span> if <span class="math notranslate nohighlight">\(\rvset_\beta^*=\rvset_\alpha\)</span>. Consequently, <a class="reference internal" href="plot_approximate_control_variates.html#ggejjcp2020" id="id1"><span>[GGEJJCP2020]</span></a> introduced the ACVMF and the ACVIS estimators which use the <span class="math notranslate nohighlight">\(m\)</span> th model as a control variate for the high-fidelity 0th-model. The allocation matrices of ACVMF and ACCVIS estimators, for three models, are given respectively by</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mat{A}_\text{ACVMF}=\begin{bmatrix}
 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\\
 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1\\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 1\\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
 \end{bmatrix}, \qquad \mat{A}_\text{ACVIS}=\begin{bmatrix}
 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1\\
 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1
 \end{bmatrix}, \qquad\end{split}\]</div>
<p>These were shown to outperform MLMC and MFMC for certain problems, however none of the allocation matrices associated with these four estimators is provably optimal for all problems. Consequently, <a class="reference internal" href="#blwljcp2022" id="id2"><span>[BLWLJCP2022]</span></a> formulated a large class of so-called parameterically defined ACV (PACV) estimators that can be enumerated and used to choose the best allocation matrix for a given problem.</p>
<p>PACV estimators are derived from a so called based allocation matrix and a recursion index <span class="math notranslate nohighlight">\(\gamma=[\gamma_1, \ldots, \gamma_M]^\top\)</span> that defines a zero-rooted directed acyclic graph (DAG) that controls which models are used for control variates for other models. Specifically, if the jth recursion index entry <span class="math notranslate nohighlight">\(\gamma_j=i\)</span>, then the jth model acts as a control variate for the ith model such that <span class="math notranslate nohighlight">\(\rvset_j^*=\rvset_i\)</span>. For example, the recusion indices of the MLMC and MFMC estimators are both <span class="math notranslate nohighlight">\([0, 1, \ldots, M]\)</span> and the recursion indices of the ACVIS and ACVMF estimators are both <span class="math notranslate nohighlight">\([0, 0, \ldots, 0]\)</span>.</p>
<p>To date three classes of PACV estimators, derived from three different base allocation matrices. These three classes of PACV estimators are presented below.</p>
<section id="generalized-multi-fidelity-estimators">
<h2>Generalized Multi-fidelity Estimators<a class="headerlink" href="#generalized-multi-fidelity-estimators" title="Permalink to this heading"></a></h2>
<p>Generalized multi-fidelity (GMF) estimators are derived from the MFMC allocation matrix presented in <a class="reference internal" href="plot_multi_fidelity_monte_carlo.html#sphx-glr-auto-tutorials-multi-fidelity-plot-multi-fidelity-monte-carlo-py"><span class="std std-ref">Multi-fidelity Monte Carlo</span></a>. GMF allocation matrices assume that if <cite>gamma_j=i</cite> then <span class="math notranslate nohighlight">\(\rvset_j^*=\rvset_i\)</span> and <span class="math notranslate nohighlight">\(\rvset_i\subset =\rvset_j\)</span>.
Note ACVMF estimators are GMF estimators that use the recursion index <span class="math notranslate nohighlight">\([0, 0, \ldots, 0]\)</span>. Futhermore,  MFMC estimators are GMF estimators that use the recursion index <span class="math notranslate nohighlight">\([0, 1, \ldots, M]\)</span>. The following code plots the allocation matrices of all four model GMF esimators and the associated DAGs.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">pyapprox.util.visualization</span> <span class="kn">import</span> <span class="n">mathrm_labels</span>
<span class="kn">from</span> <span class="nn">pyapprox.benchmarks</span> <span class="kn">import</span> <span class="n">setup_benchmark</span>
<span class="kn">from</span> <span class="nn">pyapprox.multifidelity.factory</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">get_estimator</span><span class="p">,</span> <span class="n">compare_estimator_variances</span><span class="p">,</span> <span class="n">compute_variance_reductions</span><span class="p">,</span>
    <span class="n">multioutput_stats</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.multifidelity.visualize</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">plot_estimator_variance_reductions</span><span class="p">)</span>

<span class="n">nmodels</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">benchmark</span> <span class="o">=</span> <span class="n">setup_benchmark</span><span class="p">(</span><span class="s2">&quot;polynomial_ensemble&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">fun</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">covariance</span><span class="p">[:</span><span class="n">nmodels</span><span class="p">,</span> <span class="p">:</span><span class="n">nmodels</span><span class="p">]</span>
<span class="n">costs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">10</span><span class="o">**-</span><span class="n">ii</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nmodels</span><span class="p">)])</span>

<span class="n">stat</span> <span class="o">=</span> <span class="n">multioutput_stats</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">](</span><span class="n">benchmark</span><span class="o">.</span><span class="n">nqoi</span><span class="p">)</span>
<span class="n">stat</span><span class="o">.</span><span class="n">set_pilot_quantities</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
<span class="n">gmf_est</span> <span class="o">=</span> <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;gmf&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">tree_depth</span><span class="o">=</span><span class="n">nmodels</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">recursion_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">gmf_est</span><span class="o">.</span><span class="n">get_all_recursion_indices</span><span class="p">())</span>
<span class="n">axs_mats</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="n">axs_graphs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">recursion_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">recursion_indices</span><span class="p">):</span>
    <span class="n">gmf_est</span><span class="o">.</span><span class="n">_set_recursion_index</span><span class="p">(</span><span class="n">recursion_index</span><span class="p">)</span>
    <span class="n">gmf_est</span><span class="o">.</span><span class="n">plot_allocation</span><span class="p">(</span><span class="n">axs_mats</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">gmf_est</span><span class="o">.</span><span class="n">plot_recursion_dag</span><span class="p">(</span><span class="n">axs_graphs</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_plot_pacv_001.png" srcset="../../_images/sphx_glr_plot_pacv_001.png" alt="plot pacv" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_plot_pacv_002.png" srcset="../../_images/sphx_glr_plot_pacv_002.png" alt="plot pacv" class = "sphx-glr-multi-img"/></li>
</ul>
</section>
<section id="generalized-recursive-difference-estimators">
<h2>Generalized Recursive Difference Estimators<a class="headerlink" href="#generalized-recursive-difference-estimators" title="Permalink to this heading"></a></h2>
<p>Generalized recursive difference (GRD) estimators are derived from the MLMC allocation matrix presented in <a class="reference internal" href="plot_multi_level_monte_carlo.html#sphx-glr-auto-tutorials-multi-fidelity-plot-multi-level-monte-carlo-py"><span class="std std-ref">Multi-level Monte Carlo</span></a>. The assume that if <span class="math notranslate nohighlight">\(\gamma_j=i\)</span> then <span class="math notranslate nohighlight">\(\rvset_j^*=\rvset_i\)</span> and if i!=j <span class="math notranslate nohighlight">\(\rvset_i\cap\rvset_j\neq\emptyset\)</span>.
Note MLMC estimators are GRD estimators that use the recursion index <span class="math notranslate nohighlight">\([0, 1, \ldots, M]\)</span>.
The following code plots the allocation matrices of all four model GRD esimators. The DAGs are not plotted because they are independent of the base allocation matrix and thus are the same as those plotted for the GMF estimators.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grd_est</span> <span class="o">=</span> <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;grd&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">tree_depth</span><span class="o">=</span><span class="n">nmodels</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">recursion_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">gmf_est</span><span class="o">.</span><span class="n">get_all_recursion_indices</span><span class="p">())</span>
<span class="n">axs_mats</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">recursion_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">recursion_indices</span><span class="p">):</span>
    <span class="n">grd_est</span><span class="o">.</span><span class="n">_set_recursion_index</span><span class="p">(</span><span class="n">recursion_index</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">grd_est</span><span class="o">.</span><span class="n">plot_allocation</span><span class="p">(</span><span class="n">axs_mats</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_pacv_003.png" srcset="../../_images/sphx_glr_plot_pacv_003.png" alt="plot pacv" class = "sphx-glr-single-img"/></section>
<section id="generalized-independent-sample-estimators">
<h2>Generalized Independent Sample Estimators<a class="headerlink" href="#generalized-independent-sample-estimators" title="Permalink to this heading"></a></h2>
<p>Generalized indepedent sample (GIS) estimators are derived from the ACVIS allocation matrix. The assume that if <cite>gamma_j=i</cite> then <span class="math notranslate nohighlight">\(\rvset_j^*=\rvset_i\)</span> and <span class="math notranslate nohighlight">\(\rvset_i^*\subset\rvset_i\)</span>. Note ACVIS estimators are GIS estimators that use the recursion index <span class="math notranslate nohighlight">\([0, 0, \ldots, 0]\)</span>.
The following code plots the allocation matrices of all four model GIS esimators.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">gis_est</span> <span class="o">=</span> <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;gis&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">tree_depth</span><span class="o">=</span><span class="n">nmodels</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">recursion_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">gmf_est</span><span class="o">.</span><span class="n">get_all_recursion_indices</span><span class="p">())</span>
<span class="n">axs_mats</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="o">*</span><span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">recursion_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">recursion_indices</span><span class="p">):</span>
    <span class="n">gis_est</span><span class="o">.</span><span class="n">_set_recursion_index</span><span class="p">(</span><span class="n">recursion_index</span><span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">gis_est</span><span class="o">.</span><span class="n">plot_allocation</span><span class="p">(</span><span class="n">axs_mats</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_pacv_004.png" srcset="../../_images/sphx_glr_plot_pacv_004.png" alt="plot pacv" class = "sphx-glr-single-img"/><p>The following code shows the benefit of using all models as control variates for the highest fidelity model, such as is enforced by ACVMF estimators. Specifically, it shows that as the number of low-fideliy samples increases, but the number of high-fidelity samples is fixed, the ACVMF estiamtor variance converges to the estiamtor variance of the CV estimator that uses all 5 models. In contrast the  MLMC and MFMC estimators only converge to the CV estimator CV that uses 1 low-fidelity model. However, these two approaches reduce the variance of the estimator more quickly than the ACV estimator, but cannot obtain the optimal variance reduction.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nmodels</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">covariance</span>
<span class="n">costs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">10</span><span class="o">**-</span><span class="n">ii</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nmodels</span><span class="p">)])</span>
<span class="n">nhf_samples</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">cv_stats</span><span class="p">,</span> <span class="n">cv_ests</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nmodels</span><span class="p">):</span>
    <span class="n">cv_stats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">multioutput_stats</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">](</span><span class="n">benchmark</span><span class="o">.</span><span class="n">nqoi</span><span class="p">))</span>
    <span class="n">cv_stats</span><span class="p">[</span><span class="n">ii</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_pilot_quantities</span><span class="p">(</span><span class="n">cov</span><span class="p">[:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">cv_ests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">get_estimator</span><span class="p">(</span>
        <span class="s2">&quot;cv&quot;</span><span class="p">,</span> <span class="n">cv_stats</span><span class="p">[</span><span class="n">ii</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">costs</span><span class="p">[:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">lowfi_stats</span><span class="o">=</span><span class="n">benchmark</span><span class="o">.</span><span class="n">mean</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">cv_labels</span> <span class="o">=</span> <span class="n">mathrm_labels</span><span class="p">([</span><span class="s2">&quot;CV-{</span><span class="si">%d</span><span class="s2">}&quot;</span> <span class="o">%</span> <span class="n">ii</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nmodels</span><span class="p">)])</span>
<span class="n">target_cost</span> <span class="o">=</span> <span class="n">nhf_samples</span><span class="o">*</span><span class="nb">sum</span><span class="p">(</span><span class="n">costs</span><span class="p">)</span>
<span class="p">[</span><span class="n">est</span><span class="o">.</span><span class="n">allocate_samples</span><span class="p">(</span><span class="n">target_cost</span><span class="p">)</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">cv_ests</span><span class="p">]</span>
<span class="n">cv_variance_reductions</span> <span class="o">=</span> <span class="n">compute_variance_reductions</span><span class="p">(</span><span class="n">cv_ests</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="kn">from</span> <span class="nn">util</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">plot_control_variate_variance_ratios</span><span class="p">,</span>
    <span class="n">plot_estimator_variance_ratios_for_polynomial_ensemble</span><span class="p">)</span>

<span class="n">stat</span> <span class="o">=</span> <span class="n">multioutput_stats</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">](</span><span class="n">benchmark</span><span class="o">.</span><span class="n">nqoi</span><span class="p">)</span>
<span class="n">stat</span><span class="o">.</span><span class="n">set_pilot_quantities</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;mlmc&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;mfmc&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;gmf&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span>
                  <span class="n">recursion_index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nmodels</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">))]</span>
<span class="n">est_labels</span> <span class="o">=</span> <span class="n">est_labels</span> <span class="o">=</span> <span class="n">mathrm_labels</span><span class="p">([</span><span class="s2">&quot;MLMC&quot;</span><span class="p">,</span> <span class="s2">&quot;MFMC&quot;</span><span class="p">,</span> <span class="s2">&quot;ACVMF&quot;</span><span class="p">])</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plot_control_variate_variance_ratios</span><span class="p">(</span><span class="n">cv_variance_reductions</span><span class="p">,</span> <span class="n">cv_labels</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plot_estimator_variance_ratios_for_polynomial_ensemble</span><span class="p">(</span>
    <span class="n">estimators</span><span class="p">,</span> <span class="n">est_labels</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_pacv_005.png" srcset="../../_images/sphx_glr_plot_pacv_005.png" alt="plot pacv" class = "sphx-glr-single-img"/><p>PACV estimators can be used to find the best estimator for a given problem. Given estimates of covariance (when estimating the mean, and the other stats needed to estimate other statistics), we can enumerate all PACV estimators, optimize theier sample allocaiton, and choose the best PACV estimator with the smallest estimator variance.</p>
<p>The following code compares the best GMF, GRD and GIS estimators with the MLMC, MFMC and ACVMF estimators.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;mlmc&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;mfmc&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;gmf&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span>
                  <span class="n">recursion_index</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nmodels</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;gmf&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">tree_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;grd&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">tree_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;gis&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">tree_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">)]</span>
<span class="n">est_labels</span> <span class="o">=</span> <span class="n">est_labels</span> <span class="o">=</span> <span class="n">mathrm_labels</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;MLMC&quot;</span><span class="p">,</span> <span class="s2">&quot;MFMC&quot;</span><span class="p">,</span> <span class="s2">&quot;ACVMF&quot;</span><span class="p">,</span> <span class="s2">&quot;GMF&quot;</span><span class="p">,</span> <span class="s2">&quot;GRD&quot;</span><span class="p">,</span> <span class="s2">&quot;GIS&quot;</span><span class="p">])</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plot_control_variate_variance_ratios</span><span class="p">(</span><span class="n">cv_variance_reductions</span><span class="p">,</span> <span class="n">cv_labels</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plot_estimator_variance_ratios_for_polynomial_ensemble</span><span class="p">(</span>
    <span class="n">estimators</span><span class="p">,</span> <span class="n">est_labels</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_pacv_006.png" srcset="../../_images/sphx_glr_plot_pacv_006.png" alt="plot pacv" class = "sphx-glr-single-img"/><p>Enumerating the PACV estimators allows one to choose the best estimator for any estimator cost. The recursion indices used by MLMC and MFMC are chosen for small numbers of low-fidelity samples and alternative estimators are chosen as the number of low-fidelity sampes is increased. The following compares the best GMF estimamtor against MLMC and MFMC.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">target_costs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">2e1</span><span class="p">,</span> <span class="mf">1e2</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;mc&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;mlmc&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;mfmc&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">),</span>
    <span class="n">get_estimator</span><span class="p">(</span><span class="s2">&quot;gmf&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">costs</span><span class="p">,</span> <span class="n">tree_depth</span><span class="o">=</span><span class="n">nmodels</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">allow_failures</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span>
<span class="n">est_labels</span> <span class="o">=</span> <span class="n">mathrm_labels</span><span class="p">([</span><span class="s2">&quot;MC&quot;</span><span class="p">,</span> <span class="s2">&quot;MLMC&quot;</span><span class="p">,</span> <span class="s2">&quot;MFMC&quot;</span><span class="p">,</span> <span class="s2">&quot;GMF&quot;</span><span class="p">])</span>
<span class="n">optim_opts</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;ftol&#39;</span><span class="p">:</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="s1">&#39;maxiter&#39;</span><span class="p">:</span> <span class="mi">10000</span><span class="p">,</span> <span class="s2">&quot;iprint&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;scaling&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
              <span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="s2">&quot;SLSQP&quot;</span><span class="p">,</span> <span class="s2">&quot;verbosity&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">optimized_estimators</span> <span class="o">=</span> <span class="n">compare_estimator_variances</span><span class="p">(</span>
    <span class="n">target_costs</span><span class="p">,</span> <span class="n">estimators</span><span class="p">,</span> <span class="n">optim_opts</span><span class="p">)</span>

<span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">gmf_est</span> <span class="o">=</span> <span class="n">optimized_estimators</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">idx</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GMF best estimator&quot;</span><span class="p">,</span> <span class="n">gmf_est</span><span class="p">)</span>

<span class="n">model_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;$f_</span><span class="si">{0}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ii</span><span class="p">)</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nmodels</span><span class="p">)]</span>
<span class="n">est_labels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="s2">&quot; $</span><span class="si">{0}</span><span class="s2">$&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gmf_est</span><span class="o">.</span><span class="n">_recursion_index</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">pyapprox.multifidelity.visualize</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">plot_estimator_sample_allocation_comparison</span><span class="p">,</span> <span class="n">plot_estimator_variances</span><span class="p">)</span>
<span class="n">plot_estimator_sample_allocation_comparison</span><span class="p">(</span>
    <span class="p">[</span><span class="n">est</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">est</span> <span class="ow">in</span> <span class="n">optimized_estimators</span><span class="p">[</span><span class="mi">1</span><span class="p">:]],</span> <span class="n">model_labels</span><span class="p">,</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">xlabels</span><span class="o">=</span><span class="n">est_labels</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plot_estimator_variances</span><span class="p">(</span>
    <span class="n">optimized_estimators</span><span class="p">,</span> <span class="n">est_labels</span><span class="p">,</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">relative_id</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">cost_normalization</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">gmf_est</span><span class="o">.</span><span class="n">plot_recursion_dag</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img src="../../_images/sphx_glr_plot_pacv_007.png" srcset="../../_images/sphx_glr_plot_pacv_007.png" alt="plot pacv" class = "sphx-glr-multi-img"/></li>
<li><img src="../../_images/sphx_glr_plot_pacv_008.png" srcset="../../_images/sphx_glr_plot_pacv_008.png" alt="plot pacv" class = "sphx-glr-multi-img"/></li>
</ul>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>GMF best estimator GMFEstimator(stat=MultiOutputMean, recursion_index=[0 1 0 1], criteria=-10 target_cost=19.645, ratios=[   0.          135.57142857    0.         1904.85714286], nsamples=[    7     7   956   956 14290])
</pre></div>
</div>
<p>Here we optimized the sample allocation for multiple target costs. This checks if optimization is sensitive to target cost. However, one can simply compute the optimal allocation for one target cost then linearly scale by the ratio with it and the other target costs of interest.</p>
<section id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this heading"></a></h3>
<div role="list" class="citation-list">
<div class="citation" id="blwljcp2022" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">BLWLJCP2022</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://doi.org/10.1016/j.jcp.2021.110882">On the optimization of approximate control variates with parametrically defined estimators, Journal of Computational Physics,451:110882, 2022</a></p>
</div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 2 minutes  41.823 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-multi-fidelity-plot-pacv-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/82e3d290c57da703b349f8accd2422ab/plot_pacv.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_pacv.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/14e55feb77bcb3d2a1fe94a4786c4f23/plot_pacv.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_pacv.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plot_multi_fidelity_monte_carlo.html" class="btn btn-neutral float-left" title="Multi-fidelity Monte Carlo" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plot_multioutput_acv.html" class="btn btn-neutral float-right" title="Multioutput Approximate Control Variates" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>