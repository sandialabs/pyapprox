<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Monte Carlo Quadrature &mdash; PyApprox 1.0.3 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script>window.MathJax = {"tex": {"macros": {"V": ["{\\boldsymbol{#1}}", 1], "mean": ["{\\mathbb{E}\\left[#1\\right]}", 1], "var": ["{\\mathbb{V}\\left[#1\\right]}", 1], "rv": "{z}", "rvset": "{\\mathcal{Z}}", "reals": "\\mathbb{R}", "pdf": "\\rho", "rvdom": "\\Gamma", "coloneqq": "\\colon=", "norm": ["{\\lVert #1 \\rVert}", 1], "argmax": ["\\operatorname{argmax}"], "argmin": ["\\operatorname{argmin}"], "covar": ["\\mathbb{C}\\text{ov}\\left[#1,#2\\right]", 2], "corr": ["\\mathbb{C}\\text{or}\\left[#1,#2\\right]", 2], "ai": "\\alpha", "bi": "\\beta", "dx": ["\\;\\text{d}#1", 1], "mat": ["{\\boldsymbol{\\mathrm{#1}}}", 1]}}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Monte Carlo Quadrature: Beyond Mean Estimation" href="plot_multioutput_monte_carlo.html" />
    <link rel="prev" title="Gaussian processes" href="../surrogates/plot_gaussian_processes.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            PyApprox
              <img src="../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Software Tutorial</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Theoretical Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#model-analysis">Model Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#inference">Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#experimental-design">Experimental Design</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#surrogates">Surrogates</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#multi-fidelity-methods">Multi-Fidelity Methods</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Monte Carlo Quadrature</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#video">Video</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plot_multioutput_monte_carlo.html">Monte Carlo Quadrature: Beyond Mean Estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_control_variate_monte_carlo.html">Two Model Control Variate Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_approximate_control_variates.html">Two model Approximate Control Variate Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_many_model_acv.html">Approximate Control Variate Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="acv_covariances.html">Delta-Based Covariance Formulas For Approximate Control Variates</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_allocation_matrices.html">Approximate Control Variate Allocation Matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multi_level_monte_carlo.html">Multi-level Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multi_fidelity_monte_carlo.html">Multi-fidelity Monte Carlo</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_pacv.html">Parametrically Defined Approximate Control Variates</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multioutput_acv.html">Multioutput Approximate Control Variates</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_pilot_studies.html">Pilot Studies</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_ensemble_selection.html">Model Ensemble Selection</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multilevel_blue.html">Multilevel Best Linear Unbiased estimators (MLBLUE)</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multiindex_collocation.html">Multi-level and Multi-index Collocation</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_multifidelity_gp.html">Multifidelity Gaussian processes</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_gaussian_mfnets.html">MFNets: Multi-fidelity networks</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../user_reference_guide.html">User Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PyApprox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Theoretical Tutorials</a></li>
      <li class="breadcrumb-item active">Monte Carlo Quadrature</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/auto_tutorials/multi_fidelity/plot_monte_carlo.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-tutorials-multi-fidelity-plot-monte-carlo-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="monte-carlo-quadrature">
<span id="sphx-glr-auto-tutorials-multi-fidelity-plot-monte-carlo-py"></span><h1>Monte Carlo Quadrature<a class="headerlink" href="#monte-carlo-quadrature" title="Permalink to this heading"></a></h1>
<p>This tutorial describes how to use Monte Carlo sampling to compute the expectations of the output of a model <span class="math notranslate nohighlight">\(f(\rv):\reals^{D}\to\reals\)</span> parameterized by a set of variables <span class="math notranslate nohighlight">\(\rv=[\rv_1,\ldots,\rv_D]^\top\)</span> with joint density given by <span class="math notranslate nohighlight">\(\rho(\rv):\reals^{d}\to\reals\)</span>. Specifically,  our goal is to approximate the integral</p>
<div class="math notranslate nohighlight">
\[Q=\int_\rvdom f(\rv)\pdf(\rv)\dx{\rv}\]</div>
<p>using Monte Carlo quadrature applied to an approximation <span class="math notranslate nohighlight">\(f_\alpha\)</span> of the function <span class="math notranslate nohighlight">\(f\)</span>, e.g. a representing a finite element approximation to the solution of a set of governing equations, where <span class="math notranslate nohighlight">\(\alpha\)</span> is contols the accuracy of the approximation.</p>
<p>Monte Carlo quadrature approximates the integral</p>
<div class="math notranslate nohighlight">
\[Q_\alpha=\int_\rvdom f_\alpha(\rv)\pdf(\rv)\dx{\rv}\approx Q\]</div>
<p>by drawing <span class="math notranslate nohighlight">\(N\)</span> random samples <span class="math notranslate nohighlight">\(\rvset_N\)</span> of <span class="math notranslate nohighlight">\(\rv\)</span> from <span class="math notranslate nohighlight">\(\pdf\)</span> and evaluating the function at each of these samples to obtain the data pairs <span class="math notranslate nohighlight">\(\{(\rv^{(n)},f^{(n)}_\alpha)\}_{n=1}^N\)</span>, where <span class="math notranslate nohighlight">\(f^{(n)}_\alpha=f_\alpha(\rv^{(n)})\)</span> and computing</p>
<div class="math notranslate nohighlight">
\[Q_{\alpha}(\rvset_N)=N^{-1}\sum_{n=1}^N f^{(n)}_\alpha\]</div>
<p>This estimate of the mean,is itself a random quantity, which we call an estimator, because its value depends on the <span class="math notranslate nohighlight">\(\rvset_N\)</span> realizations of the inputs <span class="math notranslate nohighlight">\(\rvset_N\)</span> used to compute <span class="math notranslate nohighlight">\(Q_{\alpha}(\rvset_N)\)</span>. Specifically, using two different sets <span class="math notranslate nohighlight">\(\rvset_N\)</span> will produce to different values.</p>
<p>To demonstrate this phenomenon, we will estimate the mean of a simple algebraic function <span class="math notranslate nohighlight">\(f_0\)</span> which belongs to an ensemble of models</p>
<div class="math notranslate nohighlight">
\[\begin{split}f_0(\rv) &amp;= A_0 \left(\rv_1^5\cos\theta_0 +\rv_2^5\sin\theta_0\right), \\
f_1(\rv) &amp;= A_1 \left(\rv_1^3\cos\theta_1 +\rv_2^3\sin\theta_1\right)+s_1,\\
f_2(\rv) &amp;= A_2 \left(\rv_1  \cos\theta_2 +\rv_2  \sin\theta_2\right)+s_2\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\rv_1,\rv_2\sim\mathcal{U}(-1,1)\)</span> and all <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(\theta\)</span> coefficients are real. We choose to set <span class="math notranslate nohighlight">\(A=\sqrt{11}\)</span>, <span class="math notranslate nohighlight">\(A_1=\sqrt{7}\)</span> and <span class="math notranslate nohighlight">\(A_2=\sqrt{3}\)</span> to obtain unitary variance for each model. The parameters <span class="math notranslate nohighlight">\(s_1,s_2\)</span> control the bias between the models. Here we set <span class="math notranslate nohighlight">\(s_1=1/10,s_2=1/5\)</span>. Similarly we can change the correlation between the models in a systematic way (by varying <span class="math notranslate nohighlight">\(\theta_1\)</span>. We will levarage this later in the tutorial.</p>
<p>First setup the example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">pyapprox.benchmarks</span> <span class="kn">import</span> <span class="n">setup_benchmark</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">shifts</span> <span class="o">=</span> <span class="p">[</span><span class="mf">.1</span><span class="p">,</span> <span class="mf">.2</span><span class="p">]</span>
<span class="n">benchmark</span> <span class="o">=</span> <span class="n">setup_benchmark</span><span class="p">(</span>
    <span class="s2">&quot;tunable_model_ensemble&quot;</span><span class="p">,</span> <span class="n">theta1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="mi">2</span><span class="o">*</span><span class="mf">.95</span><span class="p">,</span> <span class="n">shifts</span><span class="o">=</span><span class="n">shifts</span><span class="p">)</span>
</pre></div>
</div>
<p>Now define a function that computes MC estimates of the mean using different sample sets <span class="math notranslate nohighlight">\(\rvset_N\)</span> and plots the distribution the MC estimator <span class="math notranslate nohighlight">\(Q_{\alpha}(\rvset_N)\)</span>, computed from 1000 different sets, and the exact value of the mean <span class="math notranslate nohighlight">\(Q_{\alpha}\)</span></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_estimator_histrogram</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">ntrials</span> <span class="o">=</span> <span class="mi">1000</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">ntrials</span><span class="p">))</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">funs</span><span class="p">[</span><span class="n">model_id</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ntrials</span><span class="p">):</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
        <span class="n">means</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">values</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">ntrials</span><span class="o">//</span><span class="mi">100</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                 <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$Q_{</span><span class="si">%d</span><span class="s1">}(\mathcal</span><span class="si">{Z}</span><span class="s1">_{</span><span class="si">%d</span><span class="s1">})$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">nsamples</span><span class="p">))[</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">benchmark</span><span class="o">.</span><span class="n">fun</span><span class="o">.</span><span class="n">get_means</span><span class="p">()[</span><span class="n">model_id</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$Q_{</span><span class="si">%d</span><span class="s1">}$&#39;</span> <span class="o">%</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">im</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_facecolor</span><span class="p">())</span>
</pre></div>
</div>
<p>Now lets plot the historgram of the MC estimator <span class="math notranslate nohighlight">\(Q_{0}(\rvset_N)\)</span> using <span class="math notranslate nohighlight">\(N=100\)</span> samples</p>
<span class="target" id="estimator-histogram"></span><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nsamples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e2</span><span class="p">)</span>
<span class="n">model_id</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plot_estimator_histrogram</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_monte_carlo_001.png" srcset="../../_images/sphx_glr_plot_monte_carlo_001.png" alt="plot monte carlo" class = "sphx-glr-single-img"/><p>The variability of the MC estimator as we change <span class="math notranslate nohighlight">\(\rvset_N\)</span> decreases as we increase <span class="math notranslate nohighlight">\(N\)</span>. To see this, plot the estimator historgram using <span class="math notranslate nohighlight">\(N=1000\)</span> samples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_id</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">nsamples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e2</span><span class="p">)</span>
<span class="n">plot_estimator_histrogram</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">nsamples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">)</span>
<span class="n">plot_estimator_histrogram</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_monte_carlo_002.png" srcset="../../_images/sphx_glr_plot_monte_carlo_002.png" alt="plot monte carlo" class = "sphx-glr-single-img"/><p>Regardless of the value of <span class="math notranslate nohighlight">\(N\)</span> the estimator <span class="math notranslate nohighlight">\(Q_{0}(\rvset_N)\)</span> is an unbiased estimate of <span class="math notranslate nohighlight">\(Q_{0}\)</span>, that is</p>
<div class="math notranslate nohighlight">
\[\mean{Q_{0}(\rvset_N)}-Q_0 = 0\]</div>
<p>Unfortunately, if the computational cost of evaluating a model is high, then one may not be able to make <span class="math notranslate nohighlight">\(N\)</span> large using that model. Consequently, one will not be able to trust the MC estimate of the mean much because any one realization of the estimator, computed using a single sample set, may obtain a value that is very far from the truth. So often a cheaper less accurate model is used so that <span class="math notranslate nohighlight">\(N\)</span> can be increased to reduce the variability of the estimator. The following compares the histograms of <span class="math notranslate nohighlight">\(Q_0(\rvset_{100})\)</span> and <span class="math notranslate nohighlight">\(Q_1(\rvset_{1000})\)</span> which uses the model <span class="math notranslate nohighlight">\(f_1\)</span> which we assume is a cheap approximation of <span class="math notranslate nohighlight">\(f_0\)</span></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_id</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">nsamples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e2</span><span class="p">)</span>
<span class="n">plot_estimator_histrogram</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">model_id</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">nsamples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">)</span>
<span class="n">plot_estimator_histrogram</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">model_id</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img src="../../_images/sphx_glr_plot_monte_carlo_003.png" srcset="../../_images/sphx_glr_plot_monte_carlo_003.png" alt="plot monte carlo" class = "sphx-glr-single-img"/><p>However, using an approximate model means that the MC estimator is no longer unbiased. The mean of the histogram of <span class="math notranslate nohighlight">\(Q_1(\rvset_{1000})\)</span> is no longer the mean of <span class="math notranslate nohighlight">\(Q_0\)</span></p>
<p>Letting <span class="math notranslate nohighlight">\(Q\)</span> denote the true mean we want to estimate, e.g. <span class="math notranslate nohighlight">\(Q=Q_0\)</span> in the example we have used so far, the mean squared error (MSE) is typically used to quantify the quality of a MC  estimator. The MSE can be expressed as</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mean{\left(Q_{\alpha}(\rvset_N)-Q\right)^2}&amp;=\mean{\left(Q_{\alpha}(\rvset_N)-\mean{Q_{\alpha}(\rvset_N)}+\mean{Q_{\alpha}(\rvset_N)}-Q\right)^2}\\
&amp;=\mean{\left(Q_{\alpha}(\rvset_N)-\mean{Q_{\alpha}(\rvset_N)}\right)^2}+\mean{\left(\mean{Q_{\alpha}(\rvset_N)}-Q\right)^2}\\
&amp;\qquad\qquad+\mean{2\left(Q_{\alpha}(\rvset_N)-\mean{Q_{\alpha}(\rvset_N)}\right)\left(\mean{Q_{\alpha}(\rvset_N)}-Q\right)}\\
&amp;=\var{Q_{\alpha}(\rvset_N)}+\left(\mean{Q_{\alpha}(\rvset_N)}-Q\right)^2\\
&amp;=\var{Q_{\alpha}(\rvset_N)}+\left(Q_{\alpha}-Q\right)^2\end{split}\]</div>
<p>where the expectation <span class="math notranslate nohighlight">\(\mathbb{E}\)</span> and variance <span class="math notranslate nohighlight">\(\mathbb{V}\)</span> are taken over different realization of the sample set <span class="math notranslate nohighlight">\(\rvset_N\)</span>, we used that <span class="math notranslate nohighlight">\(\mean{\left(Q_{\alpha}(\rvset_N)-\mean{Q_{\alpha}(\rvset_N)}\right)}=0\)</span> so the third term on the second line is zero, and we used <span class="math notranslate nohighlight">\(\mean{Q_{\alpha}(\rvset_N)}=Q_{\alpha}\)</span> to get the final equality.</p>
<p>Now using the well known result that for random variable <span class="math notranslate nohighlight">\(X_n\)</span></p>
<div class="math notranslate nohighlight">
\[\var{\sum_{n=1}^N X_n} = \sum_{n=1}^N \var{X_n} + \sum_{n\neq p}\covar{X_n}{X_p}\]</div>
<p>and the result for a scalar <span class="math notranslate nohighlight">\(a\)</span></p>
<div class="math notranslate nohighlight">
\[\var{aX_n} =a^2\var{X_n}\]</div>
<p>yields</p>
<div class="math notranslate nohighlight">
\[\var{Q_{\alpha}(\rvset_N)}=\var{N^{-1}\sum_{n=1}^N f^{(n)}_\alpha}=N^{-2}\sum_{n=1}^N \var{f^{(n)}_\alpha}=N^{-1}\var{f_\alpha}\]</div>
<p>where <span class="math notranslate nohighlight">\(\covar{f^{(n)}}{f^{(p)}}=0, n\neq p\)</span> because the samples are drawn independently.</p>
<p>Finally, substituting <span class="math notranslate nohighlight">\(\var{Q_{\alpha}(\rvset_N)}\)</span> into the expression for MSE yields</p>
<div class="math notranslate nohighlight">
\[\mean{\left(Q_{\alpha}(\rvset_N)-\mean{Q}\right)^2}=\underbrace{N^{-1}\var{f_\alpha}}_{I}+\underbrace{\left(Q_{\alpha}-Q\right)^2}_{II}\]</div>
<p>From this expression we can see that the MSE can be decomposed into two terms; a so called stochastic error (I) and a deterministic bias (II). The first term is the variance of the Monte Carlo estimator which comes from using a finite number of samples. The second term is due to using an approximation of <span class="math notranslate nohighlight">\(f_0\)</span>. These two errors should be balanced, however in the vast majority of all MC analyses a single model <span class="math notranslate nohighlight">\(f_\alpha\)</span> is used and the choice of <span class="math notranslate nohighlight">\(\alpha\)</span>, e.g. mesh resolution, is made a priori without much concern for the balancing bias and variance.</p>
<section id="video">
<h2>Video<a class="headerlink" href="#video" title="Permalink to this heading"></a></h2>
<p>Click on the image below to view a video tutorial on Monte Carlo quadrature</p>
<a class="reference external image-reference" href="https://youtu.be/OrLsYo11kvY?si=chAXN6UqssXY8pxh"><img alt="../../_images/mc.png" src="../../_images/mc.png" /></a>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.332 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-tutorials-multi-fidelity-plot-monte-carlo-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/30eb96755241ed28302cd3119dee8cce/plot_monte_carlo.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_monte_carlo.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/ebc97cde520953924e8000cb9708579d/plot_monte_carlo.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_monte_carlo.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../surrogates/plot_gaussian_processes.html" class="btn btn-neutral float-left" title="Gaussian processes" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plot_multioutput_monte_carlo.html" class="btn btn-neutral float-right" title="Monte Carlo Quadrature: Beyond Mean Estimation" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>