<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>End-to-End Model Analysis &mdash; PyApprox 1.0.3 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script>window.MathJax = {"tex": {"macros": {"V": ["{\\boldsymbol{#1}}", 1], "mean": ["{\\mathbb{E}\\left[#1\\right]}", 1], "var": ["{\\mathbb{V}\\left[#1\\right]}", 1], "rv": "{z}", "rvset": "{\\mathcal{Z}}", "reals": "\\mathbb{R}", "pdf": "\\rho", "rvdom": "\\Gamma", "coloneqq": "\\colon=", "norm": ["{\\lVert #1 \\rVert}", 1], "argmax": ["\\operatorname{argmax}"], "argmin": ["\\operatorname{argmin}"], "covar": ["\\mathbb{C}\\text{ov}\\left[#1,#2\\right]", 2], "corr": ["\\mathbb{C}\\text{or}\\left[#1,#2\\right]", 2], "ai": "\\alpha", "bi": "\\beta", "dx": ["\\;\\text{d}#1", 1], "mat": ["{\\boldsymbol{\\mathrm{#1}}}", 1]}}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Multi-fidelity Quadrature" href="plot_multifidelity_quadrature.html" />
    <link rel="prev" title="Sparse Grid Interpolation" href="plot_sparse_grid_uq.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            PyApprox
              <img src="../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Software Tutorial</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="plot_variables.html">Random Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_setup_model.html">Model Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_interface.html">Model interfacing</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_parameter_sweeps.html">Parameter Sweeps</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_low_discrepancy_quadrature.html">Low-discrepancy quadrature</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_gaussian_quadrature.html">Univariate Gaussian Quadrature</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_barycentric_interpolation.html">Multivariate Lagrange Interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_multivariate_piecewise_polynomial_interpolation.html">Multivariate Piecewise Polynomial Interpolation</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_pde_convergence.html">Convergence studies</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_sparse_grid_uq.html">Sparse Grid Interpolation</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">End-to-End Model Analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plot_multifidelity_quadrature.html">Multi-fidelity Quadrature</a></li>
<li class="toctree-l2"><a class="reference internal" href="plot_multiindex_collocation_ex.html">Multi-index Collocation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../auto_tutorials/index.html">Theoretical Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../user_reference_guide.html">User Reference Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PyApprox</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Software Tutorial</a></li>
      <li class="breadcrumb-item active">End-to-End Model Analysis</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/auto_examples/plot_paper_demo.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-plot-paper-demo-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="end-to-end-model-analysis">
<span id="sphx-glr-auto-examples-plot-paper-demo-py"></span><h1>End-to-End Model Analysis<a class="headerlink" href="#end-to-end-model-analysis" title="Permalink to this heading"></a></h1>
<p>This tutorial describes how to use each of the major model analyses in Pyapprox
following the exposition in <a class="reference internal" href="#pyapprox2023" id="id1"><span>[PYAPPROX2023]</span></a>.</p>
<p>First lets load all the necessary modules and set the random seeds for reproducibility.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">pyapprox.util.visualization</span> <span class="kn">import</span> <span class="n">mathrm_label</span>
<span class="kn">from</span> <span class="nn">pyapprox.variables</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">IndependentMarginalsVariable</span><span class="p">,</span> <span class="n">print_statistics</span><span class="p">,</span> <span class="n">AffineTransform</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.benchmarks</span> <span class="kn">import</span> <span class="n">setup_benchmark</span><span class="p">,</span> <span class="n">list_benchmarks</span>
<span class="kn">from</span> <span class="nn">pyapprox.interface.wrappers</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">TimerModel</span><span class="p">,</span> <span class="n">WorkTrackingModel</span><span class="p">,</span>
    <span class="n">evaluate_1darray_function_on_2d_array</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.surrogates</span> <span class="kn">import</span> <span class="n">adaptive_approximate</span>
<span class="kn">from</span> <span class="nn">pyapprox.analysis.sensitivity_analysis</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">run_sensitivity_analysis</span><span class="p">,</span> <span class="n">plot_sensitivity_indices</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.bayes.metropolis</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">loglike_from_negloglike</span><span class="p">,</span> <span class="n">plot_unnormalized_2d_marginals</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">pyapprox.bayes.metropolis</span> <span class="kn">import</span> <span class="n">MetropolisMCMCVariable</span>
<span class="kn">from</span> <span class="nn">pyapprox.expdesign.bayesian_oed</span> <span class="kn">import</span> <span class="n">get_bayesian_oed_optimizer</span>
<span class="kn">from</span> <span class="nn">pyapprox</span> <span class="kn">import</span> <span class="n">multifidelity</span>
<span class="c1"># import warnings</span>
<span class="c1"># warnings.filterwarnings(&quot;ignore&quot;, category=DeprecationWarning)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2023</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2023</span><span class="p">)</span>
</pre></div>
</div>
<p>The tutorial can save the figures to file if desired. If you do want the plots
set savefig=True</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># savefig = True</span>
<span class="n">savefig</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>The following code shows how to create and sample from two independent uniform random variables defined on <span class="math notranslate nohighlight">\([-2, 2]\)</span>. We use uniform variables here, but any marginal from the scipy.stats module can be used.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nsamples</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">univariate_variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)]</span>
<span class="n">variable</span> <span class="o">=</span> <span class="n">IndependentMarginalsVariable</span><span class="p">(</span><span class="n">univariate_variables</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">variable</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nsamples</span><span class="p">)</span>
<span class="n">print_statistics</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>           z0         z1
count   30.000000  30.000000
mean    -0.528053   0.197078
std      0.905072   1.114676
min     -1.911641  -1.684959
max      1.722128   1.922229
</pre></div>
</div>
<p>PyApprox supports various types of variable transformations. The following code
shows how to use an affinte transformation to map samples from variables
to samples from the variable’s canonical form.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">var_trans</span> <span class="o">=</span> <span class="n">AffineTransform</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
<span class="n">canonical_samples</span> <span class="o">=</span> <span class="n">var_trans</span><span class="o">.</span><span class="n">map_to_canonical</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">print_statistics</span><span class="p">(</span><span class="n">canonical_samples</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>           z0         z1
count   30.000000  30.000000
mean    -0.264027   0.098539
std      0.452536   0.557338
min     -0.955821  -0.842480
max      0.861064   0.961114
</pre></div>
</div>
<p>Pyapprox provides many utilities for interfacing with complex numerical codes.
The following shows how to wrap a model and store the wall time required
to evaluate each sample in a set. First define a function
with a random execution time that takes in one sample at a time, i.e. a
1D array. Then wrap that model so that multiple samples can be evaluated at
once.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fun_pause_1</span><span class="p">(</span><span class="n">sample</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">sample</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">.05</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sample</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">pyapprox_fun_1</span><span class="p">(</span><span class="n">samples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">evaluate_1darray_function_on_2d_array</span><span class="p">(</span><span class="n">fun_pause_1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
<p>Now wrap the latter function and run it while tracking
their execution times. The last print statement
prints the median execution time of the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">timer_model</span> <span class="o">=</span> <span class="n">TimerModel</span><span class="p">(</span><span class="n">pyapprox_fun_1</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">WorkTrackingModel</span><span class="p">(</span><span class="n">timer_model</span><span class="p">)</span>
<span class="n">values</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">work_tracker</span><span class="p">())</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[0.03189158]
</pre></div>
</div>
<p>Other wrappers available in PyApprox include those for running multiple models
at once, useful for multi-fidelity methods, wrappers that fix a subset of inputs
to user specified values, wrappers that only return a subset of all
possible model ouputs, and wrappers for evaluating samples in parallel.</p>
<p>Pyapprox provide numerous benchmarks for verifying, validating and comparing
model analysis algorithms. The following list the names of all benchmarks and
then creates a benchmark that can be used to test the creation of surrogates,
Bayesian inference, and optimal experimental design. This benchmark requires
determining the true coefficients of the Karhunene Loeve expansion (KLE)
used to characterize the uncertain diffusivity field of an advection
diffusion equation. See documentation of the benchmark for more details).</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">list_benchmarks</span><span class="p">())</span>
<span class="n">noise_stdev</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># 1e-1</span>
<span class="n">inv_benchmark</span> <span class="o">=</span> <span class="n">setup_benchmark</span><span class="p">(</span>
    <span class="s2">&quot;advection_diffusion_kle_inversion&quot;</span><span class="p">,</span> <span class="n">kle_nvars</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">noise_stdev</span><span class="o">=</span><span class="n">noise_stdev</span><span class="p">,</span> <span class="n">nobs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">kle_length_scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">inv_benchmark</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;sobol_g&#39;, &#39;ishigami&#39;, &#39;oakley&#39;, &#39;rosenbrock&#39;, &#39;genz&#39;, &#39;cantilever_beam&#39;, &#39;wing_weight&#39;, &#39;piston&#39;, &#39;chemical_reaction&#39;, &#39;random_oscillator&#39;, &#39;coupled_springs&#39;, &#39;hastings_ecology&#39;, &#39;multi_index_advection_diffusion&#39;, &#39;advection_diffusion_kle_inversion&#39;, &#39;polynomial_ensemble&#39;, &#39;tunable_model_ensemble&#39;, &#39;multioutput_model_ensemble&#39;, &#39;short_column_ensemble&#39;, &#39;parameterized_nonlinear_model&#39;]
Benchmark(negloglike, variable, noiseless_obs, obs, true_sample, obs_indices, obs_fun, KLE, mesh)
</pre></div>
</div>
<p>The following plots the modes of the KLE</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">KLE</span><span class="o">.</span><span class="n">nterms</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="o">*</span><span class="n">inv_benchmark</span><span class="o">.</span><span class="n">KLE</span><span class="o">.</span><span class="n">nterms</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">inv_benchmark</span><span class="o">.</span><span class="n">KLE</span><span class="o">.</span><span class="n">nterms</span><span class="p">):</span>
    <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">mesh</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">inv_benchmark</span><span class="o">.</span><span class="n">KLE</span><span class="o">.</span><span class="n">eig_vecs</span><span class="p">[:,</span> <span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="mi">50</span><span class="p">,</span>
                            <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="n">ii</span><span class="p">])</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_paper_demo_001.png" srcset="../_images/sphx_glr_plot_paper_demo_001.png" alt="plot paper demo" class = "sphx-glr-single-img"/><p>PyApprox provides many popular methods for constructing surrogates
that once constructed can be evaluated in place of a computaionally
expensive simulation model in model analyses. The following code creates
a Gaussian process (GP) surrogate. The function used to construct the surrogate
takes a callback which is evaluated each time the adaptive surrogate is refined.
Here we use to compute the error of the surrogate as it is constructed using
validation data. Uncomment the code to use a polynomial based surrogate instead
of a GP. The user does not have to change any subsequent code</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">validation_samples</span> <span class="o">=</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">validation_values</span> <span class="o">=</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">negloglike</span><span class="p">(</span><span class="n">validation_samples</span><span class="p">)</span>
<span class="n">nsamples</span><span class="p">,</span> <span class="n">errors</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="k">def</span> <span class="nf">callback</span><span class="p">(</span><span class="n">approx</span><span class="p">):</span>
    <span class="n">nsamples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">approx</span><span class="o">.</span><span class="n">num_training_samples</span><span class="p">())</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
        <span class="n">approx</span><span class="p">(</span><span class="n">validation_samples</span><span class="p">)</span><span class="o">-</span><span class="n">validation_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">validation_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

<span class="n">approx_result</span> <span class="o">=</span> <span class="n">adaptive_approximate</span><span class="p">(</span>
    <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">negloglike</span><span class="p">,</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="s2">&quot;gaussian_process&quot;</span><span class="p">,</span>
    <span class="p">{</span><span class="s2">&quot;max_nsamples&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;ncandidate_samples&quot;</span><span class="p">:</span> <span class="mf">2e3</span><span class="p">,</span> <span class="s2">&quot;verbose&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
     <span class="s2">&quot;callback&quot;</span><span class="p">:</span> <span class="n">callback</span><span class="p">,</span> <span class="s2">&quot;kernel_variance&quot;</span><span class="p">:</span> <span class="mi">400</span><span class="p">})</span>

<span class="c1"># approx_result = adaptive_approximate(</span>
<span class="c1">#     inv_benchmark.negloglike, inv_benchmark.variable, &quot;polynomial_chaos&quot;,</span>
<span class="c1">#     {&quot;method&quot;: &quot;leja&quot;, &quot;options&quot;: {</span>
<span class="c1">#         &quot;max_nsamples&quot;: 100, &quot;ncandidate_samples&quot;: 3e3, &quot;verbose&quot;: 0,</span>
<span class="c1">#         &quot;callback&quot;: callback}})</span>
<span class="n">approx</span> <span class="o">=</span> <span class="n">approx_result</span><span class="o">.</span><span class="n">approx</span>
</pre></div>
</div>
<p>We can plot the errors obtained from the callback with</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">loglog</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">errors</span><span class="p">,</span> <span class="s2">&quot;o-&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">mathrm_label</span><span class="p">(</span><span class="s2">&quot;No. Samples&quot;</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">mathrm_label</span><span class="p">(</span><span class="s2">&quot;Error&quot;</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">get_xaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">ticker</span><span class="o">.</span><span class="n">ScalarFormatter</span><span class="p">())</span>
<span class="n">ax</span><span class="o">.</span><span class="n">minorticks_off</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">get_yaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">ticker</span><span class="o">.</span><span class="n">ScalarFormatter</span><span class="p">())</span>
<span class="c1">#ax.tick_params(axis=&#39;y&#39;, which=&#39;minor&#39;, bottom=False)</span>
<span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;gp-error-plot.pdf&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_paper_demo_002.png" srcset="../_images/sphx_glr_plot_paper_demo_002.png" alt="plot paper demo" class = "sphx-glr-single-img"/><p>Now we will perform a sensitivity analysis. Specifically we compute
variance based sensitivity indices that measure the impact of each KLE mode
on the mismatch between the observed data and the model predictions.
We use the negative log likelihood to characterize this mismatch.
Here we have used the surrogate to speed up the computation of the sensitivity
indices. Uncomment the commented code to use the numerical model. Note
the drastic increase in computational cost. Warning: using the numerical model
will take many minutes. The plots in the figure, generated from
left to right are: main effect, largest Sobol indices and total effect indices.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sa_result</span> <span class="o">=</span> <span class="n">run_sensitivity_analysis</span><span class="p">(</span>
    <span class="s2">&quot;surrogate_sobol&quot;</span><span class="p">,</span> <span class="n">approx</span><span class="p">,</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">variable</span><span class="p">)</span>
<span class="c1"># sa_result = run_sensitivity_analysis(</span>
<span class="c1">#     &quot;sobol&quot;, benchmark.negloglike, inv_benchmark.variable)</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">plot_sensitivity_indices</span><span class="p">(</span>
    <span class="n">sa_result</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;gp-sa-indices.pdf&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_paper_demo_003.png" srcset="../_images/sphx_glr_plot_paper_demo_003.png" alt="plot paper demo" class = "sphx-glr-single-img"/><p>Now we will use the surrogate with Bayesian inference to learn the
coefficients of the KL. Specifically we will draw a set of samples from
the posterior distribution of the KLE given the observed data provided
in the benchmark.</p>
<p>But First we will improve the accuracy of the surrogate
and print out the error which can be compared to the errors previously plotted.
The error of the original surrogate was kept low to demonstrate the ability
to quantify error in the sensitivity indices from using a surrogate.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">approx</span><span class="o">.</span><span class="n">refine</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span>
    <span class="n">approx</span><span class="p">(</span><span class="n">validation_samples</span><span class="p">)</span><span class="o">-</span><span class="n">validation_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">error</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">validation_values</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Surrogate&quot;</span><span class="p">,</span> <span class="n">error</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Surrogate [0.06476258]
</pre></div>
</div>
<p>Now create a MCMCVariable to sample from the posterior. The benchmark
has already formulated the negative log likelihood that is needed. Here
we will use PyApprox’s native delayed rejection adaptive metropolis (DRAM)
sampler.</p>
<p>Uncomment the commented code to use the numerical model instead of the surrogate
with the MCMC algorithm. Again note the significant increase in computational
time</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">npost_samples</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">loglike</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">loglike_from_negloglike</span><span class="p">,</span> <span class="n">approx</span><span class="p">)</span>
<span class="c1"># loglike = partial(loglike_from_negloglike, inv_benchmark.negloglike)</span>
<span class="n">mcmc_variable</span> <span class="o">=</span> <span class="n">MetropolisMCMCVariable</span><span class="p">(</span>
    <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="n">loglike</span><span class="p">,</span> <span class="n">method_opts</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;cov_scaling&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="n">mcmc_variable</span><span class="p">)</span>
<span class="n">map_sample</span> <span class="o">=</span> <span class="n">mcmc_variable</span><span class="o">.</span><span class="n">maximum_aposteriori_point</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computed Map Point&quot;</span><span class="p">,</span> <span class="n">map_sample</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">post_samples</span> <span class="o">=</span> <span class="n">mcmc_variable</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">npost_samples</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Acceptance rate&quot;</span><span class="p">,</span> <span class="n">mcmc_variable</span><span class="o">.</span><span class="n">_acceptance_rate</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>JointVariable
Computed Map Point [0.28587284 0.73868579 0.99888313]
Acceptance rate 0.43
</pre></div>
</div>
<p>Now plot the posterior samples with the 2D Marginals of the posterior. Note
do not do this with the numerical model as this would take an eternity due
to the cost of evaluating the numerical model, which is much higher relative
to the cost of running the surrogate.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot_unnormalized_2d_marginals</span><span class="p">(</span>
    <span class="n">mcmc_variable</span><span class="o">.</span><span class="n">_variable</span><span class="p">,</span> <span class="n">mcmc_variable</span><span class="o">.</span><span class="n">_loglike</span><span class="p">,</span> <span class="n">nsamples_1d</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">plot_samples</span><span class="o">=</span><span class="p">[</span>
        <span class="p">[</span><span class="n">post_samples</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">:</span> <span class="s2">&quot;orange&quot;</span><span class="p">}],</span>
        <span class="p">[</span><span class="n">map_sample</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;c&quot;</span><span class="p">:</span> <span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="s2">&quot;s&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">}]],</span>
    <span class="n">unbounded_alpha</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>
<span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;posterior-samples.pdf&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_paper_demo_004.png" srcset="../_images/sphx_glr_plot_paper_demo_004.png" alt="plot paper demo" class = "sphx-glr-single-img"/><p>In the Bayesian inference above we used a fixed number of observations
at randomly chosen spatial locations. However choosing observation locations
is usually a poor idea. Not all observations can reduce the uncertainty
in the parameters equally. Here we use Bayesian optimal experimental design
to choose the 3 best design locations from the previously observed 10 pretending
that we do not know the value of the observations.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="c1">#plot a single solution to the PDE before overlaying the designs</span>
<span class="n">inv_benchmark</span><span class="o">.</span><span class="n">mesh</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">obs_fun</span><span class="o">.</span><span class="n">_fwd_solver</span><span class="o">.</span><span class="n">solve</span><span class="p">()[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">50</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">ndesign</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">design_candidates</span> <span class="o">=</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">mesh</span><span class="o">.</span><span class="n">mesh_pts</span><span class="p">[:,</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">obs_indices</span><span class="p">]</span>
<span class="n">ndesign_candidates</span> <span class="o">=</span> <span class="n">design_candidates</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">oed</span> <span class="o">=</span> <span class="n">get_bayesian_oed_optimizer</span><span class="p">(</span>
    <span class="s2">&quot;kl_params&quot;</span><span class="p">,</span> <span class="n">ndesign_candidates</span><span class="p">,</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">obs_fun</span><span class="p">,</span> <span class="n">noise_stdev</span><span class="p">,</span>
    <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">variable</span><span class="p">,</span> <span class="n">max_ncollected_obs</span><span class="o">=</span><span class="n">ndesign</span><span class="p">)</span>
<span class="n">oed_results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ndesign</span><span class="p">):</span>
    <span class="n">results_step</span> <span class="o">=</span> <span class="n">oed</span><span class="o">.</span><span class="n">update_design</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">oed_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">results_step</span><span class="p">)</span>
<span class="n">selected_candidates</span> <span class="o">=</span> <span class="n">design_candidates</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">oed_results</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">selected_candidates</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">design_candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">design_candidates</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="s2">&quot;rs&quot;</span><span class="p">,</span> <span class="n">ms</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">selected_candidates</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">selected_candidates</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="s2">&quot;ko&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;oed-selected-design.pdf&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_paper_demo_005.png" srcset="../_images/sphx_glr_plot_paper_demo_005.png" alt="plot paper demo" class = "sphx-glr-single-img"/><div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Running 1000 outer model evaluations
Predicted observation bounds 14.477297168295355 1.1388690449350853
Evaluations took 11.687622785568237
Running 1000 inner model evaluations
Evaluations took 11.680644989013672
Computing utilities in serial took 0.23905682563781738
Computing utilities in serial took 0.023679018020629883
Computing utilities in serial took 0.03215909004211426
[[0.0954915  0.42178277 0.42178277]
 [0.05449674 0.85355339 0.85355339]]
</pre></div>
</div>
<p>Note that typically optimal
experimental design (OED) would be used before conducting Bayesian inference.
However, because understanding of Bayesian inference is needed to understand
Bayesian OED we reversed the order. OED is much more expensive than a single
Bayesian calibration because it requires solving many calibration problems.
So typically we do not solve the calibration problems in the OED procedure
to the same degree of accuracy as a final calibration. The accuracy of the
calibrations used by OED must only be sufficient to distinguish between designs.
This accuracy is typically much lower than the accuracy required in
estimates of uncertainty in the parameters or predictions needed for decision making tasks such as risk assessment.</p>
<p>Here we will set up a related benchmark to the one we have been using,
which can be used to demonstrate the forward propagation of uncertainty.
This benchmark uses the steady state solution of the advection diffusion,
obtained with a constant addition of a tracer into the domain at a single
source model as initial condition. A pump at another locations is then activated
to extract the tracer from the domain. The benchmark quantity of interest
measures the change of the tracer concentration in a subomain.
The benchmark provides models of varying cost
and accuracy that use different discretizations of the spatial PDE mesh
and number of time steps which can be used with multi-fideilty methods.
To setup the benchmark use the following</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fwd_benchmark</span> <span class="o">=</span> <span class="n">setup_benchmark</span><span class="p">(</span>
    <span class="s2">&quot;multi_index_advection_diffusion&quot;</span><span class="p">,</span>
    <span class="n">kle_nvars</span><span class="o">=</span><span class="n">inv_benchmark</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">num_vars</span><span class="p">(),</span> <span class="n">kle_length_scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">time_scenario</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">WorkTrackingModel</span><span class="p">(</span>
    <span class="n">TimerModel</span><span class="p">(</span><span class="n">fwd_benchmark</span><span class="o">.</span><span class="n">model_ensemble</span><span class="p">),</span> <span class="n">num_config_vars</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Here we will use Multi-fidelity statistical estimation to compute the
mean value of the QoI to account for the uncertainty in the KLE cofficients.
So first we must compute the covariance between the QoI returned by
each of our models. We use samples from the posterior. But uncommenting
the code below will use samples from the prior.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">npilot_samples</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">generate_samples</span> <span class="o">=</span> <span class="n">inv_benchmark</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">rvs</span>  <span class="c1"># for sampling from prior</span>
<span class="c1"># generate_samples = post_samples</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">multifidelity</span><span class="o">.</span><span class="n">estimate_model_ensemble_covariance</span><span class="p">(</span>
    <span class="n">npilot_samples</span><span class="p">,</span> <span class="n">generate_samples</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
    <span class="n">fwd_benchmark</span><span class="o">.</span><span class="n">model_ensemble</span><span class="o">.</span><span class="n">nmodels</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>By using a WorkTrackingModel we can extract the median costs
of evaluatin each model which is needed to predict the
error of the multi-fidelity estimate of the mean which we can
compare to a prediction of the single fidelity estimate that only uses
the highest fidelity model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">fwd_benchmark</span><span class="o">.</span><span class="n">model_ensemble</span><span class="o">.</span><span class="n">nmodels</span><span class="p">)])</span>
<span class="n">model_costs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">work_tracker</span><span class="p">(</span><span class="n">model_ids</span><span class="p">)</span>
<span class="c1"># make costs in terms of fraction of cost of high-fidelity evaluation</span>
<span class="n">model_costs</span> <span class="o">/=</span> <span class="n">model_costs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Now visualize the correlation between the models and their computational
cost relative to the highest-fidelity model cost</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">multifidelity</span><span class="o">.</span><span class="n">plot_correlation_matrix</span><span class="p">(</span>
    <span class="n">multifidelity</span><span class="o">.</span><span class="n">get_correlation_from_covariance</span><span class="p">(</span><span class="n">cov</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">multifidelity</span><span class="o">.</span><span class="n">plot_model_costs</span><span class="p">(</span><span class="n">model_costs</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">mathrm_label</span><span class="p">(</span><span class="s2">&quot;Model covariances&quot;</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">mathrm_label</span><span class="p">(</span><span class="s2">&quot;Relative model costs&quot;</span><span class="p">))</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_paper_demo_006.png" srcset="../_images/sphx_glr_plot_paper_demo_006.png" alt="$\mathrm{Model\;covariances}$, $\mathrm{Relative\;model\;costs}$" class = "sphx-glr-single-img"/><p>Now find the best multi-fidelity estimator among all available options
Note, the exact predicted variance will change from run to run even with the
same seed because the computational time measured will change slightly
for each run</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">stat</span> <span class="o">=</span> <span class="n">multifidelity</span><span class="o">.</span><span class="n">multioutput_stats</span><span class="p">[</span><span class="s2">&quot;mean&quot;</span><span class="p">](</span><span class="mi">1</span><span class="p">)</span>
<span class="n">stat</span><span class="o">.</span><span class="n">set_pilot_quantities</span><span class="p">(</span><span class="n">cov</span><span class="p">)</span>

<span class="n">best_est</span> <span class="o">=</span> <span class="n">multifidelity</span><span class="o">.</span><span class="n">get_estimator</span><span class="p">(</span>
    <span class="s2">&quot;gmf&quot;</span><span class="p">,</span> <span class="n">stat</span><span class="p">,</span> <span class="n">model_costs</span><span class="p">,</span> <span class="n">tree_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">allow_failures</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">max_nmodels</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="n">target_cost</span> <span class="o">=</span> <span class="mf">1e2</span>
<span class="n">best_est</span><span class="o">.</span><span class="n">allocate_samples</span><span class="p">(</span><span class="n">target_cost</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predicted variance&quot;</span><span class="p">,</span>
      <span class="n">best_est</span><span class="o">.</span><span class="n">_covariance_from_npartition_samples</span><span class="p">(</span>
          <span class="n">best_est</span><span class="o">.</span><span class="n">_rounded_npartition_samples</span><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Predicted variance tensor([[7.5268e-06]])
</pre></div>
</div>
<p>Now we can plot the relative performance of the single and multi-fidelity
estimates of the mean before requiring any additional model evaluations</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">multifidelity</span><span class="o">.</span><span class="n">plot_estimator_variance_reductions</span><span class="p">([</span><span class="n">best_est</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Best&quot;</span><span class="p">],</span> <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">model_labels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="sa">r</span><span class="s2">&quot;$f_{</span><span class="si">%d</span><span class="s2">}$&quot;</span> <span class="o">%</span> <span class="n">ii</span> <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">fwd_benchmark</span><span class="o">.</span><span class="n">model_ensemble</span><span class="o">.</span><span class="n">nmodels</span><span class="p">)]</span>
<span class="n">multifidelity</span><span class="o">.</span><span class="n">plot_estimator_sample_allocation_comparison</span><span class="p">(</span>
    <span class="p">[</span><span class="n">best_est</span><span class="p">],</span> <span class="n">model_labels</span><span class="p">,</span> <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;acv-variance-reduction.pdf&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img src="../_images/sphx_glr_plot_paper_demo_007.png" srcset="../_images/sphx_glr_plot_paper_demo_007.png" alt="plot paper demo" class = "sphx-glr-single-img"/><p>It is clear that the multi-fidelity estimator will be more computationally
efficient. Once the user
is ready to actually estimate the mean QoI they can use</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">fwd_benchmark</span><span class="p">)</span>
<span class="n">samples_per_model</span> <span class="o">=</span> <span class="n">best_est</span><span class="o">.</span><span class="n">generate_samples_per_model</span><span class="p">(</span>
    <span class="n">fwd_benchmark</span><span class="o">.</span><span class="n">variable</span><span class="o">.</span><span class="n">rvs</span><span class="p">)</span>
<span class="n">best_models</span> <span class="o">=</span> <span class="p">[</span><span class="n">fwd_benchmark</span><span class="o">.</span><span class="n">model_ensemble</span><span class="o">.</span><span class="n">functions</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span>
               <span class="n">idx</span> <span class="ow">in</span> <span class="n">best_est</span><span class="o">.</span><span class="n">_best_model_indices</span><span class="p">]</span>
<span class="n">values_per_model</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">fun</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span> <span class="k">for</span> <span class="n">fun</span><span class="p">,</span> <span class="n">samples</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">best_models</span><span class="p">,</span> <span class="n">samples_per_model</span><span class="p">)]</span>
<span class="n">mean</span> <span class="o">=</span> <span class="n">best_est</span><span class="p">(</span><span class="n">values_per_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean QoI&quot;</span><span class="p">,</span> <span class="n">mean</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Benchmark(fun, variable, get_num_degrees_of_freedom, config_var_trans, model_ensemble, funs)
Mean QoI [0.50175498]
</pre></div>
</div>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading"></a></h2>
<div role="list" class="citation-list">
<div class="citation" id="pyapprox2023" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">PYAPPROX2023</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://doi.org/10.1016/j.envsoft.2023.105825">Jakeman J.D., PyApprox: A software package for sensitivity analysis, Bayesian inference, optimal experimental design, and multi-fidelity uncertainty quantification and surrogate modeling. (2023)</a></p>
</div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 2 minutes  6.828 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-plot-paper-demo-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/4231eb2cab42df6435f116bfe8f5e15a/plot_paper_demo.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_paper_demo.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/14c24109089ff96a7df80573d0f0ca37/plot_paper_demo.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_paper_demo.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plot_sparse_grid_uq.html" class="btn btn-neutral float-left" title="Sparse Grid Interpolation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="plot_multifidelity_quadrature.html" class="btn btn-neutral float-right" title="Multi-fidelity Quadrature" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>