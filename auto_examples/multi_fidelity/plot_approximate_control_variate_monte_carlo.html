

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Approximate Control Variate Monte Carlo &mdash; PyApprox 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/graphviz.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"Macros": {"V": ["{\\boldsymbol{#1}}", 1], "mean": ["{\\mathbb{E}\\left[#1\\right]}", 1], "var": ["{\\mathbb{V}\\left[#1\\right]}", 1], "argmin": "{\\mathrm{argmin}}", "rv": "z", "reals": "\\mathbb{R}", "pdf": "\\rho", "rvdom": "\\Gamma", "coloneqq": "\\colon=", "norm": ["{\\lVert #1 \\rVert}", 1], "argmax": ["\\operatorname{argmax}"], "covar": ["\\mathbb{C}\\text{ov}\\left[#1,#2\\right]", 2], "corr": ["\\mathbb{C}\\text{or}\\left[#1,#2\\right]", 2], "ai": "\\alpha", "bi": "\\beta", "dx": ["\\;\\mathrm{d}#1", 1]}}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home" alt="Documentation Home"> PyApprox
          

          
            
            <img src="../../_static/pyapprox-logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../auto_tutorials/index.html">PyApprox Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../benchmarks.html">Benchmarks</a></li>
</ul>
<p class="caption"><span class="caption-text">User Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../user_reference_guide.html">User Reference Guide</a></li>
</ul>
<p class="caption"><span class="caption-text">Developer Reference Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">Developer Reference Guide</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">PyApprox</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Approximate Control Variate Monte Carlo</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/auto_examples/multi_fidelity/plot_approximate_control_variate_monte_carlo.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-multi-fidelity-plot-approximate-control-variate-monte-carlo-py"><span class="std std-ref">here</span></a>     to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="approximate-control-variate-monte-carlo">
<span id="sphx-glr-auto-examples-multi-fidelity-plot-approximate-control-variate-monte-carlo-py"></span><h1>Approximate Control Variate Monte Carlo<a class="headerlink" href="#approximate-control-variate-monte-carlo" title="Permalink to this headline">¶</a></h1>
<p>This tutorial builds upon <a class="reference internal" href="../../auto_tutorials/multi_fidelity/plot_control_variate_monte_carlo.html#sphx-glr-auto-tutorials-multi-fidelity-plot-control-variate-monte-carlo-py"><span class="std std-ref">Control Variate Monte Carlo</span></a> and describes how to implement and deploy <em>approximate</em> control variate Monte Carlo (ACVMC) sampling to compute expectations of model output from multiple low-fidelity models with unknown means.</p>
<p>CVMC is often not useful for practical analysis of numerical models because typically the mean of the lower fidelity model, i.e. <span class="math notranslate nohighlight">\(\mu_\V{\kappa}\)</span>, is unknown and the cost of the lower fidelity model is non trivial. These two issues can be overcome by using approximate control variate Monte Carlo.</p>
<p>Let the cost of the high fidelity model per sample be <span class="math notranslate nohighlight">\(C_\alpha\)</span> and let the cost of the low fidelity model be <span class="math notranslate nohighlight">\(C_\kappa\)</span>. Now lets use <span class="math notranslate nohighlight">\(N\)</span> samples to estimate <span class="math notranslate nohighlight">\(Q_{\V{\alpha},N}\)</span> and <span class="math notranslate nohighlight">\(Q_{\V{\kappa},N}\)</span> and these  <span class="math notranslate nohighlight">\(N\)</span> samples plus another <span class="math notranslate nohighlight">\((r-1)N\)</span> samples to estimate <span class="math notranslate nohighlight">\(\mu_{\V{\kappa}}\)</span> so that</p>
<div class="math notranslate nohighlight">
\[Q_{\V{\alpha},N,r}^{\text{ACV}}=Q_{\V{\alpha},N} + \eta \left( Q_{\V{\kappa},N} - \mu_{\V{\kappa},N,r} \right)\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\mu_{\V{\kappa},N,r}=\frac{1}{rN}\sum_{i=1}^{rN}Q_\V{\kappa}\]</div>
<p>With this sampling scheme we have</p>
<div class="math notranslate nohighlight">
\[\begin{split}Q_{\V{\kappa},N} - \mu_{\V{\kappa},N,r}&amp;=\frac{1}{N}\sum_{i=1}^N f_\V{\kappa}^{(i)}-\frac{1}{rN}\sum_{i=1}^{rN}f_\V{\kappa}^{(i)}\\
&amp;=\frac{1}{N}\sum_{i=1}^N f_\V{\kappa}^{(i)}-\frac{1}{rN}\sum_{i=1}^{N}f_\V{\kappa}^{(i)}-\frac{1}{rN}\sum_{i=N}^{rN}f_\V{\kappa}^{(i)}\\
&amp;=\frac{r-1}{rN}\sum_{i=1}^N f_\V{\kappa}^{(i)}-\frac{1}{rN}\sum_{i=N}^{rN}f_\V{\kappa}^{(i)}\\\end{split}\]</div>
<p>where for ease of notation we write <span class="math notranslate nohighlight">\(r_\V{\kappa}N\)</span> and <span class="math notranslate nohighlight">\(\lfloor r_\V{\kappa}N\rfloor\)</span> interchangibly.
Using the above expression yields</p>
<div class="math notranslate nohighlight">
\[\begin{split}\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa},N,r}\right)}&amp;=\mean{\left(\frac{r-1}{rN}\sum_{i=1}^N f_\V{\kappa}^{(i)}-\frac{1}{rN}\sum_{i=N}^{rN}f_\V{\kappa}^{(i)}\right)^2}\\
&amp;=\frac{(r-1)^2}{r^2N^2}\sum_{i=1}^N \var{f_\V{\kappa}^{(i)}}+\frac{1}{r^2N^2}\sum_{i=N}^{rN}\var{f_\V{\kappa}^{(i)}}\\
&amp;=\frac{(r-1)^2}{r^2N^2}N\var{f_\V{\kappa}}+\frac{1}{r^2N^2}(r-1)N\var{f_\V{\kappa}}\\
%&amp;=\left(\frac{(r-1)^2}{r^2N}+\frac{(r-1)}{r^2N}\right)\var{f_\V{\kappa}}\\
&amp;=\frac{r-1}{r}\frac{\var{f_\V{\kappa}}}{N}\end{split}\]</div>
<p>where we have used the fact that since the samples used in the first and second term on the first line are not shared, the covariance between these terms is zero. Also we have</p>
<div class="math notranslate nohighlight">
\[\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa},N,r}\right)}=\covar{\frac{1}{N}\sum_{i=1}^N f_\V{\alpha}^{(i)}}{\frac{r-1}{rN}\sum_{i=1}^N f_\V{\kappa}^{(i)}-\frac{1}{rN}\sum_{i=N}^{rN}f_\V{\kappa}^{(i)}}\]</div>
<p>The correlation between the estimators <span class="math notranslate nohighlight">\(\frac{1}{N}\sum_{i=1}^{N}Q_\V{\alpha}\)</span> and <span class="math notranslate nohighlight">\(\frac{1}{rN}\sum_{i=N}^{rN}Q_\V{\kappa}\)</span> is zero because the samples used in these estimators are different for each model. Thus</p>
<div class="math notranslate nohighlight">
\[\begin{split} \covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa},N,r}\right)} &amp;=\covar{\frac{1}{N}\sum_{i=1}^N f_\V{\alpha}^{(i)}}{\frac{r-1}{rN}\sum_{i=1}^N f_\V{\kappa}^{(i)}}\\
&amp;=\frac{r-1}{r}\frac{\covar{f_\V{\alpha}}{f_\V{\kappa}}}{N}\end{split}\]</div>
<p>Recalling the variance reduction of the CV estimator using the optimal <span class="math notranslate nohighlight">\(\eta\)</span> is</p>
<div class="math notranslate nohighlight">
\[\begin{split}\gamma &amp;= 1-\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{ \V{\kappa},N,r}\right)}^2}{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa},N,r}\right)}\var{Q_{\V{\alpha},N}}}\\
&amp;=1-\frac{N^{-2}\frac{(r-1)^2}{r^2}\covar{f_\V{\alpha}}{f_\V{\kappa}}}{N^{-1}\frac{r-1}{r}\var{f_\V{\kappa}}N^{-1}\var{f_\V{\alpha}}}\\
&amp;=1-\frac{r-1}{r}\corr{f_\V{\alpha}}{f_\V{\kappa}}^2\end{split}\]</div>
<p>which is found when</p>
<div class="math notranslate nohighlight">
\[\begin{split} \eta&amp;=-\frac{\covar{Q_{\V{\alpha},N}}{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa},N,r}\right)}}{\var{\left( Q_{\V{\kappa},N} - \mu_{\V{\kappa},N,r}\right)}}\\
&amp;=-\frac{N^{-1}\frac{r-1}{r}\covar{f_\V{\alpha}}{f_\V{\kappa}}}{N^{-1}\frac{r-1}{r}\var{f_\V{\kappa}}}\\
&amp;=-\frac{\covar{f_\V{\alpha}}{f_\V{\kappa}}}{\var{f_\V{\kappa}}}\end{split}\]</div>
<p>Lets setup the problem and compute an ACV estimate of <span class="math notranslate nohighlight">\(\mean{f_0}\)</span></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pyapprox</span> <span class="k">as</span> <span class="nn">pya</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">pyapprox.tests.test_control_variate_monte_carlo</span> <span class="kn">import</span> <span class="n">TunableModelEnsemble</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">uniform</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">shifts</span><span class="o">=</span> <span class="p">[</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span><span class="o">.</span><span class="mi">2</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">TunableModelEnsemble</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">shifts</span><span class="o">=</span><span class="n">shifts</span><span class="p">)</span>
<span class="n">exact_integral_f0</span><span class="o">=</span><span class="mi">0</span>
</pre></div>
</div>
<p>Before proceeding to estimate the mean using ACVMV we must first define how to generate samples to estimate <span class="math notranslate nohighlight">\(Q_{\V{\alpha},N}\)</span> and <span class="math notranslate nohighlight">\(\mu_{\V{\kappa},N,r}\)</span>. To do so clearly we must first introduce some additional notation. Let <span class="math notranslate nohighlight">\(\mathcal{Z}_0\)</span> be the set of samples used to evaluate the high-fidelity model and let <span class="math notranslate nohighlight">\(\mathcal{Z}_\alpha=\mathcal{Z}_{\alpha,1}\cup\mathcal{Z}_{\alpha,2}\)</span> be the samples used to evaluate the low fidelity model. Using this notation we can rewrite the ACV estimator as</p>
<div class="math notranslate nohighlight">
\[Q_{\V{\alpha},\mathcal{Z}}^{\text{ACV}}=Q_{\V{\alpha},\mathcal{Z}_0} + \eta \left( Q_{\V{\kappa},\mathcal{Z}_{\alpha,1}} - \mu_{\V{\kappa},\mathcal{Z}_{\alpha,2}} \right)\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{Z}=\bigcup_{\alpha=0}^M Z_\alpha\)</span>. The nature of these samples can be changed to produce different ACV estimators. Here we choose  <span class="math notranslate nohighlight">\(\mathcal{Z}_{\alpha,1}\cap\mathcal{Z}_{\alpha,2}=\emptyset\)</span> and <span class="math notranslate nohighlight">\(\mathcal{Z}_{\alpha,1}=\mathcal{Z_0}\)</span>. That is we use the set a common set of samples to compute the covariance between all the models and a second independent set to estimate the lower fidelity mean. The sample partitioning for <span class="math notranslate nohighlight">\(M\)</span> models is  shown in the following Figure. We call this scheme the ACV IS sampling stratecy where IS indicates that the second sample set <span class="math notranslate nohighlight">\(\mathcal{Z}_{\alpha,2}\)</span> assigned to each model are not shared.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><div class="figure align-center" id="id1">
<span id="acv-is-sample-allocation"></span><a class="reference internal image-reference" href="../../_images/acv_is.png"><img alt="../../_images/acv_is.png" src="../../_images/acv_is.png" style="width: 50%;" /></a>
<p class="caption"><span class="caption-text">ACV IS sampling strategy</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</td>
</tr>
</tbody>
</table>
<p>The following code generates samples according to this strategy</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nhf_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">1e1</span><span class="p">)</span>
<span class="n">nsample_ratio</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">samples_shared</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="n">nhf_samples</span><span class="p">)</span>
<span class="n">samples_lf_only</span> <span class="o">=</span>  <span class="n">model</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="n">nhf_samples</span><span class="o">*</span><span class="n">nsample_ratio</span><span class="o">-</span><span class="n">nhf_samples</span><span class="p">)</span>
<span class="n">values0</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">m0</span><span class="p">(</span><span class="n">samples_shared</span><span class="p">)</span>
<span class="n">values1_shared</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">m1</span><span class="p">(</span><span class="n">samples_shared</span><span class="p">)</span>
<span class="n">values1_lf_only</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">m1</span><span class="p">(</span><span class="n">samples_lf_only</span><span class="p">)</span>
</pre></div>
</div>
<p>Now lets plot the samples assigned to each model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples_shared</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="n">samples_shared</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span><span class="s1">&#39;ro&#39;</span><span class="p">,</span><span class="n">ms</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\mathrm{Low\ and\  high\  fidelity\  models}$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples_lf_only</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span><span class="n">samples_lf_only</span><span class="p">[</span><span class="mi">1</span><span class="p">,:],</span><span class="s1">&#39;ks&#39;</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\mathrm{Low\  fidelity\  model\ only}$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$z_1$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$z_2$&#39;</span><span class="p">,</span><span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="plot approximate control variate monte carlo" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_approximate_control_variate_monte_carlo_001.png" />
<p>The high-fidelity model is only evaluated on the red dots. Now lets use these samples to estimate the mean of <span class="math notranslate nohighlight">\(f_0\)</span>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cov</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_covariance_matrix</span><span class="p">()</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="n">nsample_ratio</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">nsample_ratio</span><span class="o">*</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">eta</span> <span class="o">=</span> <span class="o">-</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">values1_shared</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="n">values1_lf_only</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">acv_mean</span> <span class="o">=</span> <span class="n">values0</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">+</span><span class="n">eta</span><span class="o">*</span><span class="p">(</span><span class="n">values1_shared</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
    <span class="p">[</span><span class="n">values1_shared</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">values1_lf_only</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;MC difference squared =&#39;</span><span class="p">,(</span><span class="n">values0</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">-</span><span class="n">exact_integral_f0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;ACVMC difference squared =&#39;</span><span class="p">,(</span><span class="n">acv_mean</span><span class="o">-</span><span class="n">exact_integral_f0</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(10, 1) (90, 1)
MC difference squared = 0.07774335081518696
ACVMC difference squared = 0.00290404014205232
</pre></div>
</div>
<p>Note here we have arbitrarily set the number of high fidelity samples <span class="math notranslate nohighlight">\(N\)</span> and the ratio <span class="math notranslate nohighlight">\(r\)</span>. In practice one should choose these in one of two ways: (i) for a fixed budget choose the free parameters to minimize the variance of the estimator; or (ii) choose the free parameters to achieve a desired MSE (variance) with the smallest computational cost. Note the cost of computing the two model ACV estimator is</p>
<div class="math notranslate nohighlight">
\[C_\mathrm{cv} = NC_\alpha + r_\V{\kappa}NC_\kappa\]</div>
<p>Now lets compute the variance reduction for different sample sizes</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">compute_acv_two_model_variance_reduction</span><span class="p">(</span><span class="n">nsample_ratios</span><span class="p">,</span><span class="n">functions</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nsample_ratios</span><span class="p">)</span> <span class="c1"># number of lower fidelity models</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">functions</span><span class="p">)</span><span class="o">==</span><span class="n">M</span><span class="o">+</span><span class="mi">1</span>

    <span class="n">ntrials</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e3</span><span class="p">)</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">ntrials</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ntrials</span><span class="p">):</span>
        <span class="n">samples_shared</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="n">nhf_samples</span><span class="p">)</span>
        <span class="c1"># length M</span>
        <span class="n">samples_lf_only</span> <span class="o">=</span><span class="p">[</span>
            <span class="n">model</span><span class="o">.</span><span class="n">generate_samples</span><span class="p">(</span><span class="n">nhf_samples</span><span class="o">*</span><span class="n">r</span><span class="o">-</span><span class="n">nhf_samples</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">nsample_ratios</span><span class="p">]</span>
        <span class="n">values_lf_only</span>  <span class="o">=</span>  <span class="p">[</span>
            <span class="n">f</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">functions</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span><span class="n">samples_lf_only</span><span class="p">)]</span>
        <span class="c1"># length M+1</span>
        <span class="n">values_shared</span>  <span class="o">=</span> <span class="p">[</span><span class="n">f</span><span class="p">(</span><span class="n">samples_shared</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">functions</span><span class="p">]</span>
        <span class="c1">#cov_mc  = np.cov(values_shared,rowvar=False)</span>
        <span class="c1"># compute mean using only hf data</span>
        <span class="n">hf_mean</span> <span class="o">=</span> <span class="n">values_shared</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">means</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">=</span> <span class="n">hf_mean</span>
        <span class="c1"># compute ACV mean</span>
        <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="n">nsample_ratios</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">nsample_ratios</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span>
            <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">eta</span> <span class="o">=</span> <span class="o">-</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">means</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">=</span><span class="n">hf_mean</span><span class="o">+</span><span class="n">eta</span><span class="o">*</span><span class="p">(</span><span class="n">values_shared</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">-</span>
            <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">values_shared</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">values_lf_only</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Theoretical ACV variance reduction&quot;</span><span class="p">,</span>
          <span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="n">nsample_ratios</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">nsample_ratios</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span>
              <span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Achieved ACV variance reduction&quot;</span><span class="p">,</span>
         <span class="n">means</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">/</span><span class="n">means</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">means</span>

<span class="n">r1</span><span class="p">,</span><span class="n">r2</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Two model: r=</span><span class="si">{</span><span class="n">r1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">means1</span> <span class="o">=</span> <span class="n">compute_acv_two_model_variance_reduction</span><span class="p">([</span><span class="n">r1</span><span class="p">],[</span><span class="n">model</span><span class="o">.</span><span class="n">m0</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">m1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Three model: r=</span><span class="si">{</span><span class="n">r2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">means2</span> <span class="o">=</span> <span class="n">compute_acv_two_model_variance_reduction</span><span class="p">([</span><span class="n">r2</span><span class="p">],[</span><span class="n">model</span><span class="o">.</span><span class="n">m0</span><span class="p">,</span><span class="n">model</span><span class="o">.</span><span class="n">m1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Theoretical CV variance reduction&quot;</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">cov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">cov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Two model: r=10
Theoretical ACV variance reduction 0.3942038532548334
Achieved ACV variance reduction 0.39668418003519357
Three model: r=100
Theoretical ACV variance reduction 0.33362423858031676
Achieved ACV variance reduction 0.369982660649872
Theoretical CV variance reduction 0.32689317028314824
</pre></div>
</div>
<p>Let us also plot the distribution of these estimators</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ntrials</span> <span class="o">=</span> <span class="n">means1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">means1</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="n">ntrials</span><span class="o">//</span><span class="mi">100</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$Q_{0,N}$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">means1</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="n">ntrials</span><span class="o">//</span><span class="mi">100</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$Q_{0,N,</span><span class="si">%d</span><span class="s1">}^\mathrm</span><span class="si">{CV}</span><span class="s1">$&#39;</span><span class="o">%</span><span class="n">r1</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">means2</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span><span class="n">bins</span><span class="o">=</span><span class="n">ntrials</span><span class="o">//</span><span class="mi">100</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$Q_{0,N,</span><span class="si">%d</span><span class="s1">}^\mathrm</span><span class="si">{CV}</span><span class="s1">$&#39;</span><span class="o">%</span><span class="n">r2</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$E[Q_0]$&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="plot approximate control variate monte carlo" class="sphx-glr-single-img" src="../../_images/sphx_glr_plot_approximate_control_variate_monte_carlo_002.png" />
<p>For a fixed number of high-fidelity evaluations <span class="math notranslate nohighlight">\(N\)</span> the ACVMC variance reduction will converge to the CVMC variance reduction. Try changing <span class="math notranslate nohighlight">\(N\)</span>.</p>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<dl class="citation">
<dt class="label" id="ggejjcp2020"><span class="brackets">GGEJJCP2020</span></dt>
<dd><p><a class="reference external" href="https://doi.org/10.1016/j.jcp.2020.109257">A generalized approximate control variate framework for multifidelity uncertainty quantification, Journal of Computational Physics, 408:109257, 2020.</a></p>
</dd>
</dl>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.803 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-multi-fidelity-plot-approximate-control-variate-monte-carlo-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/9d3fea535bcd2609bbba2620b81314c0/plot_approximate_control_variate_monte_carlo.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_approximate_control_variate_monte_carlo.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/443d4837feb1dfeab2ef3139f8b9b333/plot_approximate_control_variate_monte_carlo.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_approximate_control_variate_monte_carlo.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2019 National Technology &amp; Engineering Solutions of Sandia, LLC (NTESS). Under the terms of Contract DE-NA0003525 with NTESS, the U.S. Government retains certain rights in this software.

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>